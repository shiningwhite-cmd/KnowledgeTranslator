2024-04-22 15:19:37.274 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:19:37.285 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:19:37.285 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 15:19:37.285 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 15:19:54.100 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:19:54.100 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.550 s.
2024-04-22 15:19:54.110 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:19:54.110 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:19:54.126 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:19:54.131 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:19:54.150 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:19:54.152 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:28:45.769 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:28:45.769 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.866 s.
2024-04-22 15:28:45.769 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:28:45.769 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:28:45.784 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:28:45.784 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:28:45.799 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:28:45.799 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:09.287 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:29:09.287 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.864 s.
2024-04-22 15:29:09.287 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:29:09.288 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:09.297 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:29:09.297 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.840 s.
2024-04-22 15:29:09.297 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:29:09.298 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:09.305 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:29:09.306 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:09.315 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:29:09.316 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:09.321 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:29:09.323 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:09.331 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:29:09.332 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:29:18.277 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:29:18.283 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B80141BD50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:29:24.744 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 15:29:30.664 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:29:30.664 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B80141BD50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:29:32.142 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:29:32.144 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B80141BD50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:29:47.674 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 15:29:54.093 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:29:54.094 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B80141BD50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:29:56.258 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:29:56.258 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B80141BD50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:30:07.074 | INFO     | __main__:collect_video_concept:79 - {'Python programming fundamentals': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Setting up Python environment': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Data types and variables': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Control flow with if statements and loops': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Working with lists and tuples': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Utilizing built-in functions and operators': ['kqtD5dpn9C8', 'Gm72cIo9_58'], "Python's popularity and attributes": ['Gm72cIo9_58'], 'Multiple programming paradigms in Python': ['Gm72cIo9_58'], 'Functional and imperative programming in machine learning': ['Gm72cIo9_58'], 'Functional programming in deep learning': ['Gm72cIo9_58'], 'Data manipulation with functional and object-oriented programming': ['Gm72cIo9_58']}
2024-04-22 15:31:25.876 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:31:25.876 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.573 s.
2024-04-22 15:31:25.876 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:31:25.876 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:31:25.893 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:31:25.894 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:31:25.909 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:31:25.910 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:18.974 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:32:18.974 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.294 s.
2024-04-22 15:32:18.974 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:18.974 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:18.987 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:18.987 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:19.004 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:19.004 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:27.975 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:32:27.975 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.619 s.
2024-04-22 15:32:27.976 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:27.978 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:27.991 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:32:27.991 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.575 s.
2024-04-22 15:32:27.991 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:27.992 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:27.994 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:27.995 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:28.008 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:28.009 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:28.012 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:28.015 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:28.031 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:32:28.032 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:32:32.654 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:32:32.654 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B87F4A5FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:32:39.118 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 15:32:47.505 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:32:47.505 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B87F4A5FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:32:48.977 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:32:48.980 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B87F4A5FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:33:02.027 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 15:33:06.343 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:33:06.345 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B87F4A5FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:33:08.176 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:33:08.180 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B87F4A5FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:33:18.916 | INFO     | __main__:collect_video_concept:79 - {'**Introduction to Python Programming**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Setting Up Python Environment**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Variables and Basic Syntax**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Control Structures**': ['kqtD5dpn9C8'], '**Lists and Tuples**': ['kqtD5dpn9C8'], "Python's popularity and dominance in programming": ['Gm72cIo9_58'], 'Programming paradigms in Python: imperative, functional, procedural, object-oriented': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms for optimal solutions': ['Gm72cIo9_58']}
2024-04-22 15:36:28.306 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:36:28.306 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.399 s.
2024-04-22 15:36:28.306 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:28.310 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:28.323 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:28.323 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:28.338 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:28.338 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:39.884 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:36:39.884 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.553 s.
2024-04-22 15:36:39.884 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:39.885 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:39.901 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:39.902 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:39.906 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:36:39.906 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.541 s.
2024-04-22 15:36:39.906 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:39.907 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:39.918 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:39.918 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:39.921 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:39.922 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:40.128 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:36:40.132 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:36:44.485 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:36:44.488 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6E8E80AD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:36:52.042 | INFO     | Action.SearchVideo:download_video_srt:134 - <class 'Exception'>
2024-04-22 15:37:45.520 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:37:45.520 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.485 s.
2024-04-22 15:37:45.520 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:45.525 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:45.537 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:45.537 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:45.555 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:45.555 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:52.059 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:37:52.059 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.635 s.
2024-04-22 15:37:52.059 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:52.060 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:52.080 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:52.083 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:52.085 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:37:52.085 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.593 s.
2024-04-22 15:37:52.085 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:52.085 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:52.103 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:52.104 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:52.105 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:52.107 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:52.320 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:37:52.322 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:37:56.852 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:37:56.856 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B842693150>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:39:46.015 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:39:46.015 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:39:46.015 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 15:39:46.015 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 15:39:52.435 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:39:52.435 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.686 s.
2024-04-22 15:39:52.449 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:39:52.449 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:39:52.466 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:39:52.466 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:39:52.485 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:39:52.485 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:06.863 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:40:06.863 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.588 s.
2024-04-22 15:40:06.863 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:40:06.866 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:06.881 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:40:06.881 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.579 s.
2024-04-22 15:40:06.881 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:40:06.883 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:06.884 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:40:06.885 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:06.900 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:40:06.901 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:40:06.902 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:06.903 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:06.918 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:40:07.104 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:40:11.735 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:40:11.745 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002298540F950>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:41:50.479 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:41:50.482 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:41:50.484 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 15:41:50.484 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 15:43:06.605 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:43:06.605 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:43:06.605 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 15:43:06.605 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 15:43:12.265 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:43:12.265 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.610 s.
2024-04-22 15:43:12.275 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:43:12.275 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:43:12.295 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:43:12.295 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:43:12.315 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:43:12.318 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:49:38.725 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:49:38.725 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:49:38.735 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 15:49:38.735 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 15:49:43.880 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:49:43.880 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.335 s.
2024-04-22 15:49:43.885 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:49:43.885 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:49:43.915 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:49:43.915 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:49:43.925 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:49:43.925 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:05.048 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:50:05.048 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.315 s.
2024-04-22 15:50:05.048 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:05.050 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:05.065 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:05.070 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:05.085 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:05.085 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:11.587 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:50:11.587 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.612 s.
2024-04-22 15:50:11.587 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:11.589 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:11.604 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:11.606 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:11.622 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:11.623 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:12.860 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:50:12.860 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.319 s.
2024-04-22 15:50:12.860 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:12.861 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:12.875 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:12.876 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:12.890 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:12.891 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:13.152 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:50:13.152 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.547 s.
2024-04-22 15:50:13.152 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:13.154 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:13.168 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:13.170 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:13.183 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:50:13.184 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:50:18.685 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:50:18.705 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269DDF50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:50:23.915 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 15:50:29.825 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:50:29.825 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269DDF50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:50:31.110 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:50:31.114 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269DDF50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:50:44.116 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 15:50:47.305 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:50:47.305 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DD815B3410>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:50:47.405 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:50:47.406 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269DDF50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:50:49.105 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:50:49.110 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269DDF50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:50:54.619 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 6767
2024-04-22 15:50:59.864 | INFO     | __main__:collect_video_concept:79 - {'Python programming basics': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Data types and operations': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Functions and methods': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Control flow statements': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Sequences and data structures': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Popularity of Python in the programming world': ['Gm72cIo9_58'], 'Different programming paradigms in Python': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-22 15:51:00.807 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:51:00.811 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DD815B3410>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:51:02.877 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:51:02.877 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DD815B3410>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:51:12.886 | INFO     | __main__:collect_video_concept:79 - {'Linear regression for pattern learning': ['z18nw4adsx4'], 'Decision tree for rule-based predictions': ['z18nw4adsx4'], 'Random Forest for reducing overfitting': ['z18nw4adsx4'], 'Ada boost for adaptive boosting': ['z18nw4adsx4'], 'Gradient boost for sequential learning': ['z18nw4adsx4'], 'Logistic regression for probability prediction': ['z18nw4adsx4'], 'K-nearest neighbor algorithm for neighbor-based prediction': ['z18nw4adsx4'], 'Support Vector Machines (SVM) for creating decision boundaries': ['z18nw4adsx4'], 'Collaborative filtering for recommendation systems': ['z18nw4adsx4']}
2024-04-22 15:56:03.574 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:56:03.574 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.293 s.
2024-04-22 15:56:03.574 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:03.580 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:03.596 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:03.596 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:03.606 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:03.606 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:08.520 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:56:08.520 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.529 s.
2024-04-22 15:56:08.520 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:08.522 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:08.538 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:08.539 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:08.543 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 15:56:08.543 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.400 s.
2024-04-22 15:56:08.543 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:08.544 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:08.555 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:08.556 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:08.559 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:08.560 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:08.753 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 15:56:08.761 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 15:56:13.061 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:56:13.063 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269EF450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:56:19.507 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 15:56:26.365 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:56:26.368 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269EF450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:56:27.887 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:56:27.891 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269EF450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:56:40.857 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 15:56:44.987 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:56:44.987 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269EF450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:56:46.906 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 15:56:46.906 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE269EF450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 15:56:57.391 | INFO     | __main__:collect_video_concept:79 - {'Python programming fundamentals': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Data types and variables in Python': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'User input and basic program building': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Conditional statements and decision-making': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Working with lists and loops in Python': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Popularity and dominance of Python as a programming language': ['Gm72cIo9_58'], 'Versatility in supporting various programming paradigms': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms based on the problem at hand': ['Gm72cIo9_58'], 'Applying different programming paradigms in machine learning, deep learning, and data manipulation': ['Gm72cIo9_58']}
2024-04-22 16:00:37.595 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:00:37.595 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.550 s.
2024-04-22 16:00:37.595 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:37.598 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:37.614 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:37.614 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:37.628 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:37.628 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:47.803 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:00:47.803 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.643 s.
2024-04-22 16:00:47.803 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:47.805 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:47.820 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:47.820 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:47.832 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:00:47.832 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.511 s.
2024-04-22 16:00:47.832 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:47.834 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:47.835 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:47.837 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:47.851 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:48.045 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:48.064 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:00:48.066 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:00:53.159 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:00:53.162 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD962E90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:01:03.281 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 16:01:09.951 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:01:09.954 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD962E90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:01:11.696 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:01:11.700 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD962E90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:01:25.252 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 16:01:29.336 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:01:29.339 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD962E90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:01:30.840 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:01:30.845 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD962E90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:01:41.333 | INFO     | __main__:collect_video_concept:79 - {'Python programming fundamentals': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Data types and variables': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Functions and methods': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Control flow structures': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Loops and iterations': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Tuples as immutable data structures': ['kqtD5dpn9C8', 'Gm72cIo9_58'], "Python's programming paradigms: imperative, functional, procedural, and object-oriented": ['Gm72cIo9_58']}
2024-04-22 16:06:44.717 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:06:44.717 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.686 s.
2024-04-22 16:06:44.718 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:06:44.718 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:06:44.726 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:06:44.726 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.694 s.
2024-04-22 16:06:44.726 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:06:44.727 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:06:44.745 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:06:44.747 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:06:44.748 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:06:44.749 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:06:44.770 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:06:44.771 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:06:44.772 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:06:44.772 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:53.434 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:07:53.434 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.298 s.
2024-04-22 16:07:53.434 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:53.437 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:53.448 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:53.453 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:53.464 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:53.468 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:58.887 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:07:58.887 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.627 s.
2024-04-22 16:07:58.887 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:58.888 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:58.898 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:07:58.898 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.561 s.
2024-04-22 16:07:58.898 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:58.899 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:58.903 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:58.903 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:58.913 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:58.915 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:58.919 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:58.920 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:07:58.929 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:07:58.930 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:08:07.111 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:08:07.114 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DF04E23150>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:08:15.064 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 16:08:24.318 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:08:24.320 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DF04E23150>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:08:25.364 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:08:25.364 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DF04E23150>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:08:40.308 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 16:08:44.465 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:08:44.465 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DF04E23150>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:08:45.984 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:08:45.984 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DF04E23150>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:08:56.684 | INFO     | __main__:collect_video_concept:79 - {'Variables and Data Types': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Control Structures': ['kqtD5dpn9C8'], 'Lists and Tuples': ['kqtD5dpn9C8'], 'Loops and Range Function': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Practical Applications': ['kqtD5dpn9C8'], "Python's popularity and dominance in various domains": ['Gm72cIo9_58'], 'Four main programming paradigms in Python': ['Gm72cIo9_58'], 'Importance of mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-22 16:10:06.041 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:10:06.041 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.479 s.
2024-04-22 16:10:06.041 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:10:06.042 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:10:06.058 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:10:06.058 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:10:06.072 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:10:06.074 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:10:06.960 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:10:06.960 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 1.397 s.
2024-04-22 16:10:06.960 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:10:06.961 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:10:06.979 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:10:06.984 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:10:07.000 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:10:07.004 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:33:59.380 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:33:59.380 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.608 s.
2024-04-22 16:33:59.380 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:33:59.383 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:33:59.397 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:33:59.398 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:33:59.414 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:33:59.415 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:34:03.486 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:34:03.492 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD97DFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:34:09.230 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 16:34:16.275 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:34:16.275 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD97DFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:34:21.571 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:34:21.575 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD97DFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:34:33.863 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 16:34:42.654 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:34:42.660 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD97DFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:34:43.816 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:34:43.820 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DEDD97DFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:34:54.231 | INFO     | __main__:collect_video_concept:79 - {'Python programming basics': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Variables and data types': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Conditional statements': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Lists and loops': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Programming paradigms in Python': ['Gm72cIo9_58'], 'Mixing and matching paradigms': ['Gm72cIo9_58'], 'Real-world application examples': ['Gm72cIo9_58']}
2024-04-22 16:35:07.615 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:35:07.615 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.557 s.
2024-04-22 16:35:07.616 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:35:07.616 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:35:07.624 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:35:07.624 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.534 s.
2024-04-22 16:35:07.625 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:35:07.625 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:35:07.631 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:35:07.632 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:35:07.641 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:35:07.642 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:35:07.647 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:35:07.649 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:35:07.658 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:35:07.658 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:13.580 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:44:13.580 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.553 s.
2024-04-22 16:44:13.580 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:13.580 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:13.599 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:13.599 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:13.613 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:13.613 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:19.442 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:44:19.443 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.609 s.
2024-04-22 16:44:19.443 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:19.444 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:19.453 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:44:19.453 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.553 s.
2024-04-22 16:44:19.453 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:19.454 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:19.460 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:19.460 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:19.469 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:19.470 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:19.475 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:19.476 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:19.485 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:44:19.486 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:44:26.052 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:44:26.052 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE422AAFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:44:36.480 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 16:44:48.542 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:44:48.547 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE422AAFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:44:49.980 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:44:49.990 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE422AAFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:45:03.650 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 16:45:07.534 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:45:07.534 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE422AAFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:45:09.131 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:45:09.131 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001DE422AAFD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:45:19.505 | INFO     | __main__:collect_video_concept:79 - {'Variables and data types': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Functions and type conversion': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Operators and control structures': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Lists, tuples, and loops': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Python programming paradigms': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58'], 'Application of programming paradigms in machine learning and data manipulation': ['Gm72cIo9_58']}
2024-04-22 16:46:28.355 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:46:28.355 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.578 s.
2024-04-22 16:46:28.355 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:28.356 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:28.370 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:28.372 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:28.386 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:28.387 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:29.888 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:46:29.888 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.339 s.
2024-04-22 16:46:29.888 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:29.889 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:29.904 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:29.904 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:29.920 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:29.921 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:30.156 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:46:30.156 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.553 s.
2024-04-22 16:46:30.156 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:30.158 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:30.171 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:30.172 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:46:30.186 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:46:30.187 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:30.020 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:30.024 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:30.028 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 16:54:30.028 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 16:54:36.384 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:54:36.384 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.334 s.
2024-04-22 16:54:36.391 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:36.391 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:36.419 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:36.420 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:36.434 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:36.434 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:52.229 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:54:52.229 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.519 s.
2024-04-22 16:54:52.230 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:52.230 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:52.244 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:52.245 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:54:52.259 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:54:52.259 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:00.587 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:55:00.587 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.362 s.
2024-04-22 16:55:00.587 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:55:00.590 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:00.607 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:55:00.608 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:00.622 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:55:00.625 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:05.425 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:55:05.425 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.437 s.
2024-04-22 16:55:05.425 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:55:05.427 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:05.441 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:55:05.442 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:05.456 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:55:05.457 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:55:06.885 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:55:06.902 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001AA8E2253D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:55:16.685 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:55:16.689 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ABA4BA7510>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:56:17.874 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:56:17.879 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:56:17.879 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 16:56:17.879 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 16:56:22.680 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:56:22.680 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.308 s.
2024-04-22 16:56:22.689 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:56:22.689 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:56:22.699 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:56:22.709 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:56:22.720 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:56:22.720 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:05.551 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:58:05.551 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.522 s.
2024-04-22 16:58:05.551 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:05.551 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:05.569 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:05.569 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:05.589 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:05.591 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:53.541 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:58:53.541 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.532 s.
2024-04-22 16:58:53.541 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:53.541 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:53.559 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:53.559 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:53.575 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:53.575 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:57.047 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:58:57.047 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.516 s.
2024-04-22 16:58:57.047 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:57.048 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:57.062 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:57.063 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:58:57.076 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:58:57.079 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:10.670 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 16:59:10.679 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002E084802250>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 16:59:43.298 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:59:43.298 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.299 s.
2024-04-22 16:59:43.298 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:43.298 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:43.309 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:43.315 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:43.329 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:43.329 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:48.099 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:59:48.099 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.543 s.
2024-04-22 16:59:48.100 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:48.102 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:48.115 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:48.117 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:48.131 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:48.132 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:55.936 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 16:59:55.937 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.277 s.
2024-04-22 16:59:55.937 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:55.938 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:55.952 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:55.953 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 16:59:55.967 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 16:59:55.968 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:07.330 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:00:07.330 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.520 s.
2024-04-22 17:00:07.330 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:00:07.332 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:07.346 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:00:07.348 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:07.361 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:00:07.364 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:09.363 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:00:09.364 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.404 s.
2024-04-22 17:00:09.364 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:00:09.367 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:09.380 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:00:09.384 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:09.397 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:00:09.398 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:00:42.389 | INFO     | Action.SearchVideo:download_video_srt:134 - <class 'Exception'>
2024-04-22 17:00:48.605 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 17:00:48.605 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002E0C14C1810>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 17:12:17.029 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:12:17.029 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:12:17.029 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 17:12:17.029 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 17:12:21.968 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:12:21.968 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.318 s.
2024-04-22 17:12:21.977 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:12:21.977 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:12:22.000 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:12:22.000 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:12:22.017 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:12:22.017 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:01.850 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:13:01.850 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.330 s.
2024-04-22 17:13:01.850 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:01.850 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:01.868 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:01.874 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:01.893 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:01.894 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:39.680 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:13:39.680 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.562 s.
2024-04-22 17:13:39.680 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:39.682 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:39.697 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:39.698 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:39.716 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:39.719 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:40.310 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:13:40.310 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 1.192 s.
2024-04-22 17:13:40.310 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:40.311 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:40.326 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:40.328 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:13:40.337 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:13:40.337 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:49.224 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:49.224 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:49.224 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 17:14:49.224 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 17:14:54.087 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:14:54.087 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.300 s.
2024-04-22 17:14:54.094 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:54.094 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:54.121 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:54.121 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:54.138 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:54.138 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:59.938 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:14:59.938 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.522 s.
2024-04-22 17:14:59.938 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:59.942 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:59.957 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:59.960 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:14:59.974 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:14:59.978 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:04.211 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:15:04.211 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.600 s.
2024-04-22 17:15:04.212 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:04.215 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:04.232 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:04.236 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:04.250 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:04.253 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:11.647 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:15:11.647 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.479 s.
2024-04-22 17:15:11.647 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:11.648 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:11.663 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:11.664 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:11.678 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:11.679 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:14.999 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:15:15.000 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.413 s.
2024-04-22 17:15:15.000 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:15.001 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:15.014 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:15.016 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:15:15.028 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:15:15.029 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:16:18.442 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:16:18.442 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.294 s.
2024-04-22 17:16:18.442 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:16:18.442 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:16:18.458 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:16:18.458 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:16:18.476 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:16:18.482 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:16:43.303 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:16:43.303 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.299 s.
2024-04-22 17:16:43.303 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:16:43.303 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:16:43.319 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:16:43.319 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:16:43.319 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:16:43.335 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:17:06.497 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:17:06.497 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.303 s.
2024-04-22 17:17:06.497 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:17:06.498 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:17:06.507 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:17:06.507 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:17:06.522 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:17:06.522 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:17:18.634 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:17:18.635 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.303 s.
2024-04-22 17:17:18.635 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:17:18.635 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:17:18.648 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:17:18.648 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:17:18.648 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:17:18.663 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:19.216 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:18:19.216 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.284 s.
2024-04-22 17:18:19.216 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:19.220 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:19.231 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:19.231 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:19.251 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:19.251 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:21.211 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:18:21.211 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.282 s.
2024-04-22 17:18:21.211 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:21.212 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:21.226 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:21.228 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:21.242 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:21.243 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:24.768 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 17:18:24.769 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.673 s.
2024-04-22 17:18:24.769 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:24.772 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:24.785 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:24.787 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 17:18:24.800 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 17:18:24.801 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:06.313 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:06.321 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:06.321 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 22:08:06.321 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 22:08:12.272 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:08:12.272 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.317 s.
2024-04-22 22:08:12.280 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:12.284 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:12.300 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:12.305 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:12.320 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:12.323 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:27.847 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:08:27.847 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.978 s.
2024-04-22 22:08:27.847 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:27.848 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:27.861 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:08:27.862 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.965 s.
2024-04-22 22:08:27.862 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:27.862 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:27.863 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:27.864 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:27.878 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:27.879 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:27.881 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:27.881 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:27.896 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:08:28.078 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:08:33.311 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:08:33.315 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:08:43.431 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 164028
2024-04-22 22:08:48.351 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:08:48.351 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:08:50.790 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:08:50.791 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:08:54.441 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:08:54.441 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:08:56.721 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:08:56.721 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:01.881 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:01.887 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:03.623 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:03.625 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:06.741 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:06.745 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:14.744 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:14.745 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:17.303 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:17.303 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:21.844 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:21.850 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:24.552 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:24.552 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:31.531 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:31.531 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:34.391 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:34.395 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:38.533 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:38.535 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:42.667 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:42.671 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:44.294 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:09:44.294 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:09:57.241 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 22:10:01.951 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:10:01.951 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:10:03.153 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:10:03.159 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000023ABEE57E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:10:13.591 | INFO     | __main__:collect_video_concept:79 - {'Python programming basics': ['nLRL_NcnK-4', 'Gm72cIo9_58'], 'Data manipulation using Pandas': ['nLRL_NcnK-4', 'Gm72cIo9_58'], 'Data visualization with Matplotlib': ['nLRL_NcnK-4', 'Gm72cIo9_58'], 'Statistical analysis in Python': ['nLRL_NcnK-4', 'Gm72cIo9_58'], 'Web scraping fundamentals': ['nLRL_NcnK-4', 'Gm72cIo9_58'], 'Python programming paradigms': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-22 22:10:53.247 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:10:53.247 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.604 s.
2024-04-22 22:10:53.248 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:10:53.249 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:10:53.266 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:10:53.267 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:10:53.269 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:10:53.269 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.626 s.
2024-04-22 22:10:53.269 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:10:53.270 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:10:53.282 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:10:53.283 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:10:53.284 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:10:53.285 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:10:53.479 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:10:53.483 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:36.801 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:36.801 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:36.801 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 22:14:36.801 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 22:14:41.771 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:14:41.772 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.317 s.
2024-04-22 22:14:41.772 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:41.781 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:41.799 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:41.799 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:41.815 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:41.815 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:46.612 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:14:46.613 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.519 s.
2024-04-22 22:14:46.613 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:46.615 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:46.631 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:46.633 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:46.648 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:46.649 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:47.058 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:14:47.058 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.886 s.
2024-04-22 22:14:47.059 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:47.062 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:47.076 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:47.079 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:47.092 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:14:47.094 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:14:53.770 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:14:53.773 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6140EED50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:14:59.431 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 22:15:07.615 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:15:07.617 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6140EED50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:15:09.856 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:15:09.861 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6140EED50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:15:21.904 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 22:15:26.023 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:15:26.026 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6140EED50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:15:28.132 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:15:28.134 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6140EED50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:15:38.648 | INFO     | __main__:collect_video_concept:79 - {'Python basics': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Variable manipulation': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'String manipulation': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Type conversion': ['kqtD5dpn9C8'], 'Decision-making with if statements': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Loops in Python': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Lists and tuples': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Range function and immutability': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Popularity of Python in the programming world': ['Gm72cIo9_58'], 'Programming paradigms in Python (imperative, functional, procedural, object-oriented)': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58'], 'Combining paradigms for tasks like machine learning, deep learning, and data manipulation': ['Gm72cIo9_58']}
2024-04-22 22:16:04.125 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:16:04.125 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.598 s.
2024-04-22 22:16:04.125 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:16:04.126 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:16:04.141 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:16:04.142 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:16:04.142 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:16:04.158 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:16:04.601 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:16:04.601 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 1.074 s.
2024-04-22 22:16:04.601 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:16:04.602 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:16:04.615 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:16:04.616 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:16:04.632 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:16:04.633 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:17:00.297 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:17:00.297 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.503 s.
2024-04-22 22:17:00.298 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:17:00.298 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:17:00.314 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:17:00.315 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:17:00.330 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:17:00.331 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:17:00.345 | INFO     | __main__:APP:240 - refresh!
2024-04-22 22:17:04.818 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:17:04.818 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDB3B010>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:17:10.250 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 22:17:19.710 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:17:19.710 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDB3B010>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:17:21.167 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:17:21.170 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDB3B010>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:17:33.439 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 22:17:38.672 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:17:38.674 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDB3B010>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:17:40.697 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:17:40.697 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDB3B010>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:17:51.104 | INFO     | __main__:collect_video_concept:79 - {'Variables and Data Types': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Input and Output': ['kqtD5dpn9C8'], 'Arithmetic and Logical Operators': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Conditional Statements': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Lists and Loops': ['kqtD5dpn9C8', 'Gm72cIo9_58'], "Python's popularity in various domains": ['Gm72cIo9_58'], 'Flexibility in supporting multiple programming paradigms': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms for efficient solutions': ['Gm72cIo9_58']}
2024-04-22 22:18:14.283 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:18:14.284 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.513 s.
2024-04-22 22:18:14.284 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:18:14.285 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:18:14.299 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:18:14.300 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:18:14.313 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:18:14.315 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:18:14.330 | INFO     | __main__:APP:240 - refresh!None
2024-04-22 22:19:38.460 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:19:38.460 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.451 s.
2024-04-22 22:19:38.460 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:19:38.461 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:19:38.475 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:19:38.476 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:19:38.490 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:19:38.494 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:19:42.753 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:19:42.757 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDA74FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:19:48.178 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 8531
2024-04-22 22:19:54.629 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:19:54.629 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDA74FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:19:56.488 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:19:56.488 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDA74FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:20:08.633 | INFO     | Action.SearchVideo:truncate_text_by_token_count:246 - 3461
2024-04-22 22:20:14.213 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:20:14.213 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDA74FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:20:15.350 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-22 22:20:15.356 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001B6FDA74FD0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-22 22:20:25.735 | INFO     | __main__:collect_video_concept:79 - {'**Python programming basics**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Variables, data types, and operators**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Decision-making with if statements**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Programming paradigms in Python': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-22 22:20:25.735 | INFO     | __main__:collect_video_concept:82 - A refresh!{'**Python programming basics**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Variables, data types, and operators**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Decision-making with if statements**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Programming paradigms in Python': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-22 22:20:28.528 | INFO     | __main__:multi_video_learning:176 - B refresh!{'**Python programming basics**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Variables, data types, and operators**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], '**Decision-making with if statements**': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Programming paradigms in Python': ['Gm72cIo9_58'], 'Mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-22 22:21:01.653 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:21:01.653 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.682 s.
2024-04-22 22:21:01.653 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:21:01.655 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:21:01.665 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:21:01.665 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.694 s.
2024-04-22 22:21:01.665 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:21:01.665 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:21:01.675 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:21:01.682 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:21:01.682 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:21:01.682 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:21:01.697 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:21:01.698 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:21:01.699 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:21:01.699 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:55:16.283 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:55:16.293 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:55:16.293 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-22 22:55:16.293 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-22 22:55:21.496 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-22 22:55:21.496 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.327 s.
2024-04-22 22:55:21.503 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:55:21.509 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:55:21.533 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:55:21.536 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-22 22:55:21.554 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-22 22:55:21.554 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
