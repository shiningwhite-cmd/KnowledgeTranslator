2024-04-23 09:29:33.119 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:29:33.120 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:29:33.121 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 09:29:33.121 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 09:30:21.509 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:21.510 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:21.522 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 09:30:21.522 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 09:30:29.375 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:30:29.375 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.583 s.
2024-04-23 09:30:29.383 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:29.384 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:29.404 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:29.405 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:29.419 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:29.420 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:54.499 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:30:54.499 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.585 s.
2024-04-23 09:30:54.499 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:54.500 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:54.514 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:54.515 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:54.530 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:54.530 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:55.234 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:30:55.234 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.258 s.
2024-04-23 09:30:55.234 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:55.235 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:55.249 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:55.249 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:30:55.262 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:30:55.262 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:45.245 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:31:45.246 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.291 s.
2024-04-23 09:31:45.246 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:45.246 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:45.262 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:45.262 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:45.277 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:45.278 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:50.928 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:31:50.928 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.833 s.
2024-04-23 09:31:50.928 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:50.929 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:50.937 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:31:50.937 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.688 s.
2024-04-23 09:31:50.937 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:50.938 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:50.944 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:50.945 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:50.952 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:50.953 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:50.959 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:50.960 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:50.967 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:31:50.968 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:31:57.561 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:31:57.566 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8523BE290>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:32:06.239 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 09:32:12.666 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:32:12.668 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8523BE290>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:32:13.720 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:32:13.723 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8523BE290>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:32:16.025 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 09:32:19.841 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:32:19.842 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8523BE290>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:32:21.183 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:32:21.184 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8523BE290>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:32:21.943 | INFO     | __main__:multi_video_learning:152 - B refresh!{'Python programming basics': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Variables, data types, and operators': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Control structures: if statements and loops': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Data structures: lists and tuples': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Programming paradigms in Python': ['Gm72cIo9_58'], 'Imperative, functional, procedural, and object-oriented programming in Python': ['Gm72cIo9_58'], 'Application of programming paradigms in machine learning, deep learning, and data manipulation': ['Gm72cIo9_58']}
2024-04-23 09:37:51.351 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:37:51.352 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.507 s.
2024-04-23 09:37:51.352 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:51.352 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:51.379 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:51.380 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:51.395 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:51.396 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:55.346 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:37:55.346 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.651 s.
2024-04-23 09:37:55.346 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:55.347 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:55.363 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:55.363 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:55.365 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:37:55.365 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.607 s.
2024-04-23 09:37:55.365 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:55.365 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:55.378 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:55.379 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:55.380 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:55.382 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:37:55.578 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:37:55.594 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:00.208 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:38:00.209 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8FA0EB750>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:38:36.220 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:38:36.220 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.298 s.
2024-04-23 09:38:36.220 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:36.221 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:36.235 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:36.236 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:36.250 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:36.251 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:40.169 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:38:40.169 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.623 s.
2024-04-23 09:38:40.170 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:40.170 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:40.185 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:40.186 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:40.189 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:38:40.189 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.578 s.
2024-04-23 09:38:40.189 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:40.189 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:40.200 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:40.201 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:40.204 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:40.205 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:40.407 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:38:40.409 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:38:44.279 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:38:44.280 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8A36AC310>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:38:48.971 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 09:38:58.786 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:38:58.789 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8A36AC310>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:39:00.046 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:39:00.048 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8A36AC310>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:39:03.107 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 09:39:06.044 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:39:06.045 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8A36AC310>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:39:07.580 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:39:07.582 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D8A36AC310>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:39:08.298 | INFO     | __main__:multi_video_learning:154 - B refresh!{'Python programming basics': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Variables and data types': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Input and output functions': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'String manipulation': ['kqtD5dpn9C8'], 'Arithmetic and comparison operators': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Logical operators and conditions': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Loops and iteration': ['kqtD5dpn9C8', 'Gm72cIo9_58'], 'Lists and list manipulation': ['kqtD5dpn9C8', 'Gm72cIo9_58'], "Python's popularity and dominance in various domains": ['Gm72cIo9_58'], 'Programming paradigms in Python: imperative, functional, procedural, and object-oriented': ['Gm72cIo9_58']}
2024-04-23 09:39:36.439 | INFO     | Action.SearchVideo:download_video_srt:135 - <class 'Exception'>
2024-04-23 09:43:04.463 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:43:04.463 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.555 s.
2024-04-23 09:43:04.463 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:43:04.465 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:43:04.480 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:43:04.482 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:43:04.496 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:43:04.498 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:43:05.161 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:43:05.162 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 1.254 s.
2024-04-23 09:43:05.162 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:43:05.162 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:43:05.176 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:43:05.177 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:43:05.191 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:43:05.192 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:46:40.443 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:46:40.445 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:46:40.445 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 09:46:40.445 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 09:46:46.029 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:46:46.029 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.303 s.
2024-04-23 09:46:46.037 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:46:46.038 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:46:46.056 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:46:46.056 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:46:46.071 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:46:46.071 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:48:36.972 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:48:36.973 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.596 s.
2024-04-23 09:48:37.255 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:48:37.255 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.465 s.
2024-04-23 09:48:37.256 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:48:37.258 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:48:37.274 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:48:37.283 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:48:37.298 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:48:37.298 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:48:41.307 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:48:41.321 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000202926B1350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:48:45.820 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 09:48:54.453 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:48:54.453 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000202926B1350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:48:55.901 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:48:55.903 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000202926B1350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:48:57.930 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 09:49:02.193 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:49:02.196 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000202926B1350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:49:03.727 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:49:03.728 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000202926B1350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:49:04.161 | INFO     | __main__:multi_video_learning:155 - B refresh!{'Python programming basics': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Variable manipulation and data types': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Conditional statements and decision-making': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Looping structures for repetitive tasks': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Working with lists and tuples': ['Gm72cIo9_58', 'kqtD5dpn9C8'], "Python's popularity and dominance in the programming world": ['Gm72cIo9_58'], 'Different programming paradigms in Python': ['Gm72cIo9_58'], 'Importance of mixing and matching programming paradigms': ['Gm72cIo9_58']}
2024-04-23 09:49:49.000 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:49:49.000 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.640 s.
2024-04-23 09:49:49.188 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:49:49.188 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.795 s.
2024-04-23 09:49:49.188 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:49:49.189 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:49:49.206 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:49:49.207 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:49:49.221 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:49:49.222 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:11.407 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:52:11.408 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.294 s.
2024-04-23 09:52:11.408 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:11.408 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:11.422 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:11.422 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:11.435 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:11.437 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:16.478 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:52:16.478 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.531 s.
2024-04-23 09:52:16.478 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:16.479 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:16.494 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:16.495 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:16.510 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:16.512 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:19.657 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:52:19.657 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.548 s.
2024-04-23 09:52:19.657 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:19.658 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:19.672 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:19.673 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:19.689 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:19.691 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:33.461 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:52:33.461 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.580 s.
2024-04-23 09:52:33.461 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:33.462 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:33.476 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:33.476 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:33.490 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:33.491 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:40.495 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:52:40.495 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.558 s.
2024-04-23 09:52:40.698 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:52:40.698 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.618 s.
2024-04-23 09:52:40.698 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:40.699 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:40.713 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:40.714 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:40.727 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:52:40.728 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:52:44.527 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:52:44.528 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000020376B16450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:52:49.114 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 09:52:58.425 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:52:58.427 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000020376B16450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:52:59.377 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:52:59.379 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000020376B16450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:53:01.508 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 09:53:04.701 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:53:04.703 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000020376B16450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:53:06.035 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 09:53:06.037 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000020376B16450>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 09:53:06.382 | INFO     | __main__:multi_video_learning:155 - B refresh!{'Introduction to Python Programming': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Setting Up Python Environment': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Getting Started with Python Programming': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'User Input and Conditional Statements': ['Gm72cIo9_58', 'kqtD5dpn9C8'], 'Loops and Iteration': ['Gm72cIo9_58', 'kqtD5dpn9C8'], "Python's popularity and dominance in programming": ['Gm72cIo9_58'], 'Four main programming paradigms in Python': ['Gm72cIo9_58']}
2024-04-23 09:54:25.768 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:54:25.769 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.284 s.
2024-04-23 09:54:25.769 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:54:25.769 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:54:25.783 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:54:25.784 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:54:25.798 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:54:25.798 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:13.958 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:13.960 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:13.961 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 09:57:13.961 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 09:57:15.734 | INFO     | Module.Intermediary:__init__:24 - init!
2024-04-23 09:57:18.656 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:57:18.656 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.334 s.
2024-04-23 09:57:18.665 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:18.666 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:18.687 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:18.687 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:18.703 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:18.703 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:24.734 | INFO     | Module.Intermediary:__init__:24 - init!
2024-04-23 09:57:25.371 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:57:25.371 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.556 s.
2024-04-23 09:57:25.371 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:25.372 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:25.387 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:25.388 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:25.403 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:25.404 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:34.353 | INFO     | Module.Intermediary:__init__:24 - init!
2024-04-23 09:57:34.710 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 09:57:34.711 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.301 s.
2024-04-23 09:57:34.711 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:34.711 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:34.727 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:34.728 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 09:57:34.743 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 09:57:34.744 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:28:58.776 | INFO     | Module.Intermediary:__init__:24 - init!
2024-04-23 10:28:59.436 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:28:59.437 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.403 s.
2024-04-23 10:28:59.437 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:28:59.437 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:28:59.453 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:28:59.453 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:28:59.468 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:28:59.469 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:29:01.252 | INFO     | Module.Intermediary:__init__:24 - init!
2024-04-23 10:29:01.334 | INFO     | Module.Intermediary:__init__:24 - init!
2024-04-23 10:29:02.002 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:29:02.003 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.687 s.
2024-04-23 10:29:02.206 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:29:02.206 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.813 s.
2024-04-23 10:29:02.206 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:29:02.207 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:29:02.221 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:29:02.222 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:29:02.236 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:29:02.237 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:29:06.518 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:29:06.522 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000125814ED2D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:29:15.702 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 10:29:25.951 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:29:25.953 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000125814ED2D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:29:28.969 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:29:28.971 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000125814ED2D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:29:37.133 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 10:29:40.594 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:29:40.595 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000125814ED2D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:29:41.772 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:29:41.773 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000125814ED2D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:30:29.685 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:30:29.687 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:30:29.689 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 10:30:29.690 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 10:30:32.799 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:30:32.799 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:31:58.010 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:32:35.463 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:33:56.791 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:34:01.638 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:34:30.919 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:34:30.920 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:34:30.921 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 10:34:30.921 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 10:34:36.318 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:35:36.652 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:35:36.652 | INFO     | Module.Intermediary:read_from_txt:46 - <_io.TextIOWrapper name='Data/Intermediary/search_video_match.txt' mode='r' encoding='cp936'>
2024-04-23 10:36:32.483 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:36:35.298 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:36:35.298 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.340 s.
2024-04-23 10:36:35.302 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:36:35.304 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:36:35.324 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:36:35.325 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:36:35.341 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:36:35.343 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:36:35.364 | INFO     | __main__:multi_video_learning:154 - B refresh!None
2024-04-23 10:39:08.696 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:39:09.403 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:39:09.403 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.464 s.
2024-04-23 10:39:09.403 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:39:09.404 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:39:09.418 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:39:09.419 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:39:09.433 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:39:09.434 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:39:13.094 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:39:13.153 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:39:13.817 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:39:13.818 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.657 s.
2024-04-23 10:39:14.025 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:39:14.025 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.816 s.
2024-04-23 10:39:14.025 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:39:14.026 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:39:14.041 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:39:14.042 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:39:14.056 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:39:14.057 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:39:25.443 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:39:25.446 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000011326EF3350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:39:29.864 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 10:39:34.939 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:39:34.943 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000011326EF3350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:39:36.231 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:39:36.233 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000011326EF3350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:39:39.667 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 10:39:44.308 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:39:44.309 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000011326EF3350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:39:45.649 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:39:45.651 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000011326EF3350>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:40:26.742 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:40:30.529 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:44:25.984 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:44:35.570 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:45:26.954 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:45:26.954 | INFO     | Module.Intermediary:read_from_txt:48 - 
2024-04-23 10:46:13.039 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:46:13.040 | INFO     | Module.Intermediary:read_from_txt:48 - <_io.TextIOWrapper name='Data/Intermediary/search_video_match.txt' mode='r' encoding='utf-8'>
2024-04-23 10:46:39.910 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:46:39.911 | INFO     | Module.Intermediary:read_from_txt:49 - 
2024-04-23 10:47:14.110 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:47:14.112 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:47:14.112 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 10:47:14.112 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 10:47:16.502 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:47:16.704 | INFO     | Module.Intermediary:read_from_txt:49 - 
2024-04-23 10:49:34.653 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:49:34.653 | INFO     | Module.Intermediary:read_from_txt:49 - 
2024-04-23 10:50:17.012 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:50:17.012 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:50:17.012 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 10:50:17.012 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 10:50:26.535 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:50:26.535 | INFO     | Module.Intermediary:read_from_txt:49 - 
2024-04-23 10:50:59.490 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:51:48.266 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:51:48.267 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:51:48.268 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 10:51:48.268 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 10:51:50.248 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:51:53.053 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:51:53.053 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.310 s.
2024-04-23 10:51:53.061 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:51:53.061 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:51:53.080 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:51:53.081 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:51:53.095 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:51:53.097 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:51:59.466 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:51:59.533 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:52:00.199 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:52:00.199 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.665 s.
2024-04-23 10:52:00.389 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:52:00.389 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.792 s.
2024-04-23 10:52:00.389 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:52:00.391 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:52:00.406 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:52:00.407 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:52:00.421 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:52:00.423 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:52:06.442 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:52:06.456 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ED80EC1C90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:52:13.199 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 10:52:19.678 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:52:19.680 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ED80EC1C90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:52:20.973 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:52:20.975 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ED80EC1C90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:52:33.215 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 10:52:36.421 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:52:36.423 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ED80EC1C90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:52:37.977 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:52:37.979 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ED80EC1C90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:55:03.579 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 10:55:04.480 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 10:55:04.480 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.547 s.
2024-04-23 10:55:04.480 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:55:04.481 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:55:04.494 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:55:04.496 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:55:04.508 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 10:55:04.510 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 10:55:08.043 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:55:08.045 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ECF550B810>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:55:14.759 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 10:55:23.022 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:55:23.025 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ECF550B810>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:55:24.177 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:55:24.179 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ECF550B810>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:55:40.757 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 10:55:44.416 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:55:44.417 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ECF550B810>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 10:55:46.093 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 10:55:46.095 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001ECF550B810>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:23:22.378 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:23:22.381 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:23:22.383 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 14:23:22.383 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 14:23:25.639 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:23:31.431 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:25:08.911 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:26:06.935 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:26:12.406 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:26:12.406 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.553 s.
2024-04-23 14:26:12.410 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:26:12.410 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:26:12.438 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:26:12.440 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:26:12.453 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:26:12.455 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:26:54.618 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:26:55.409 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:26:55.410 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.554 s.
2024-04-23 14:26:55.410 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:26:55.411 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:26:55.426 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:26:55.426 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:26:55.444 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:26:55.445 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:27:11.642 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:27:12.399 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:27:12.399 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.550 s.
2024-04-23 14:27:12.399 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:27:12.400 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:27:12.414 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:27:12.415 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:27:12.428 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:27:12.429 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:27:43.958 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:27:44.430 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:27:44.430 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.278 s.
2024-04-23 14:27:44.430 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:27:44.431 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:27:44.445 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:27:44.446 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:27:44.461 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:27:44.462 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:28.388 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:28:29.128 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:28:29.128 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.544 s.
2024-04-23 14:28:29.129 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:29.129 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:29.144 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:29.145 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:29.158 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:29.159 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:33.520 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:28:34.119 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:28:34.119 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.536 s.
2024-04-23 14:28:34.119 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:34.120 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:34.134 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:34.135 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:34.148 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:34.149 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:51.032 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:28:51.786 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:28:51.786 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.487 s.
2024-04-23 14:28:51.786 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:51.787 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:51.801 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:51.801 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:28:51.815 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:28:51.816 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:27.384 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:27.386 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:27.387 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 14:29:27.387 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 14:29:29.332 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:29:32.221 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:29:32.221 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.317 s.
2024-04-23 14:29:32.230 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:32.231 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:32.253 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:32.254 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:32.269 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:32.269 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:52.072 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:29:52.141 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:29:53.198 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:29:53.198 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.904 s.
2024-04-23 14:29:53.394 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:29:53.394 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.864 s.
2024-04-23 14:29:53.394 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:53.395 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:53.409 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:53.409 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:53.423 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:29:53.426 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:29:57.116 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:29:57.120 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001564945C7D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:30:03.348 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 14:30:14.193 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:30:14.196 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001564945C7D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:30:15.115 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:30:15.119 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001564945C7D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:30:27.089 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 14:30:33.808 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:30:33.811 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001564945C7D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:30:35.068 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:30:35.071 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001564945C7D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:30:45.795 | INFO     | Module.DecipherVideo:collect_video_concept:55 - set!
2024-04-23 14:30:45.796 | INFO     | Module.Intermediary:set_video_info:90 - saving!
2024-04-23 14:30:45.797 | INFO     | Module.Intermediary:set_video_info:93 - saved!
2024-04-23 14:32:40.089 | INFO     | Module.Intermediary:__init__:26 - init!
2024-04-23 14:35:56.724 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:38:05.334 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:05.336 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:05.337 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 14:38:05.337 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 14:38:07.101 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:38:09.842 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:38:09.842 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.299 s.
2024-04-23 14:38:09.850 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:09.851 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:09.869 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:09.871 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:09.888 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:09.889 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:24.608 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:38:24.697 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:38:25.651 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:38:25.652 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.846 s.
2024-04-23 14:38:25.652 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:38:25.652 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.818 s.
2024-04-23 14:38:25.652 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:25.849 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:25.866 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:25.867 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:25.881 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:38:25.881 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:38:34.321 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:38:34.324 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002350F713E10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:38:39.424 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 14:38:48.950 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:38:48.952 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002350F713E10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:38:50.746 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:38:50.748 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002350F713E10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:39:02.807 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 14:39:06.774 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:39:06.776 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002350F713E10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:39:08.019 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:39:08.023 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002350F713E10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:39:18.502 | INFO     | Module.DecipherVideo:collect_video_concept:55 - set!
2024-04-23 14:39:18.503 | INFO     | Module.Intermediary:set_video_info:92 - saving!
2024-04-23 14:39:18.504 | INFO     | Module.Intermediary:set_video_info:95 - saved!
2024-04-23 14:39:37.240 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:39:37.821 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:39:37.821 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.352 s.
2024-04-23 14:39:37.821 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:39:37.823 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:39:37.837 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:39:37.838 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:39:37.857 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:39:37.859 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:40:10.572 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:40:10.630 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:40:11.442 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:40:11.442 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.646 s.
2024-04-23 14:40:11.636 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:40:11.636 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.807 s.
2024-04-23 14:40:11.636 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:40:11.637 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:40:11.651 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:40:11.652 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:40:11.666 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:40:11.666 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:40:16.234 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:40:16.235 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000234CE0C4950>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:40:20.370 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 2646
2024-04-23 14:40:29.822 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:40:29.824 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000234CE0C4950>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:40:31.444 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:40:31.448 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000234CE0C4950>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:40:43.560 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 1582
2024-04-23 14:40:46.369 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:40:46.371 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000234CE0C4950>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:40:47.577 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:40:47.580 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000234CE0C4950>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:40:57.990 | INFO     | Module.DecipherVideo:collect_video_concept:55 - set!
2024-04-23 14:40:57.991 | INFO     | Module.Intermediary:set_video_info:92 - saving!
2024-04-23 14:40:57.992 | INFO     | Module.Intermediary:set_video_info:95 - saved!
2024-04-23 14:43:04.710 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:43:05.199 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:43:05.199 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.284 s.
2024-04-23 14:43:05.199 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:05.200 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:05.214 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:05.215 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:05.227 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:05.228 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:05.246 | INFO     | __main__:multi_video_learning:155 - B refresh!{'**Creating interactive web apps with Streamlit**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], '**Utilizing input elements and Markdown formatting in Streamlit**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], '**Working with data and visualizations in Streamlit**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], '**Deploying Streamlit apps using Streamlit Cloud or Docker images**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], 'Streamlit web application development': ['iLE6_3Sp0CA'], 'Creating interactive visualizations': ['iLE6_3Sp0CA'], 'Adding navigation elements and project details': ['iLE6_3Sp0CA']}
2024-04-23 14:43:21.758 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:43:21.812 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:43:22.508 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:43:22.508 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.547 s.
2024-04-23 14:43:23.127 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:43:23.127 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 1.166 s.
2024-04-23 14:43:23.128 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:23.128 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:23.143 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:23.143 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:23.156 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:23.156 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:23.175 | INFO     | __main__:multi_video_learning:155 - B refresh!{'**Creating interactive web apps with Streamlit**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], '**Utilizing input elements and Markdown formatting in Streamlit**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], '**Working with data and visualizations in Streamlit**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], '**Deploying Streamlit apps using Streamlit Cloud or Docker images**': ['iLE6_3Sp0CA', 'D0D4Pa22iG0'], 'Streamlit web application development': ['iLE6_3Sp0CA'], 'Creating interactive visualizations': ['iLE6_3Sp0CA'], 'Adding navigation elements and project details': ['iLE6_3Sp0CA']}
2024-04-23 14:43:28.351 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:43:28.910 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:43:28.910 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.476 s.
2024-04-23 14:43:28.910 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:28.912 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:28.927 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:28.928 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:43:28.942 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:43:28.943 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:49:28.111 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:49:28.112 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:49:28.113 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 14:49:28.113 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 14:49:33.101 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:49:35.847 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:49:35.847 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.312 s.
2024-04-23 14:49:35.855 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:49:35.856 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:49:35.875 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:49:35.875 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:49:35.890 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:49:35.891 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:49:35.914 | INFO     | __main__:multi_video_learning:155 - B refresh!None
2024-04-23 14:51:04.144 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:51:04.951 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:51:04.951 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.567 s.
2024-04-23 14:51:04.951 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:51:04.952 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:51:04.967 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:51:04.968 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:51:04.982 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:51:04.983 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:51:05.004 | INFO     | __main__:multi_video_learning:155 - B refresh!None
2024-04-23 14:52:03.655 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:52:04.162 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:52:04.162 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.295 s.
2024-04-23 14:52:04.162 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:52:04.163 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:52:04.178 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:52:04.179 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:52:04.193 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:52:04.193 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:52:04.214 | INFO     | __main__:multi_video_learning:148 - allFalse
2024-04-23 14:52:04.215 | INFO     | __main__:multi_video_learning:156 - B refresh!None
2024-04-23 14:52:46.638 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:52:47.155 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:52:47.155 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.285 s.
2024-04-23 14:52:47.155 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:52:47.157 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:52:47.171 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:52:47.171 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:52:47.186 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:52:47.186 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:52:47.206 | INFO     | __main__:multi_video_learning:155 - B refresh!(None, None)
2024-04-23 14:53:18.569 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:53:19.314 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:53:19.314 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.508 s.
2024-04-23 14:53:19.314 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:53:19.315 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:53:19.329 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:53:19.331 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:53:19.345 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:53:19.345 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:53:22.381 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:53:22.430 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:53:22.775 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:53:22.775 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.342 s.
2024-04-23 14:53:23.005 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:53:23.005 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.512 s.
2024-04-23 14:53:23.005 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:53:23.006 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:53:23.020 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:53:23.022 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:53:23.034 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:53:23.035 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:53:26.420 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:53:26.423 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000010F40C2EF10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:53:30.735 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 8531
2024-04-23 14:53:41.779 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:53:41.781 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000010F40C2EF10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:53:44.257 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:53:44.259 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000010F40C2EF10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:53:56.465 | INFO     | Action.SearchVideo:truncate_text_by_token_count:247 - 3461
2024-04-23 14:54:00.459 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:54:00.463 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000010F40C2EF10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:54:01.677 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:54:01.679 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000010F40C2EF10>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 14:54:12.370 | INFO     | Module.DecipherVideo:collect_video_concept:55 - set!
2024-04-23 14:54:12.371 | INFO     | Module.Intermediary:set_video_info:94 - saving!
2024-04-23 14:54:12.372 | INFO     | Module.Intermediary:set_video_info:97 - saved!
2024-04-23 14:54:33.147 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:54:33.262 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:54:33.931 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:54:33.931 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.574 s.
2024-04-23 14:54:33.931 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:33.932 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:33.938 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:54:33.938 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.552 s.
2024-04-23 14:54:34.133 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:34.136 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:34.149 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:34.150 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:41.297 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:54:41.898 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:54:41.898 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.496 s.
2024-04-23 14:54:41.898 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:41.899 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:41.913 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:41.914 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:41.928 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:41.928 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:43.678 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:54:44.103 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:54:44.103 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.372 s.
2024-04-23 14:54:44.103 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:44.104 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:44.117 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:44.119 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:54:44.131 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:54:44.132 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:03.779 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:55:04.494 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:55:04.494 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.460 s.
2024-04-23 14:55:04.494 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:04.495 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:04.509 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:04.510 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:04.523 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:04.524 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:08.983 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:55:09.487 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:55:09.488 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.451 s.
2024-04-23 14:55:09.488 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:09.490 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:09.503 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:09.504 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:09.517 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:09.518 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:53.295 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:55:53.858 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:55:53.858 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.302 s.
2024-04-23 14:55:53.859 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:53.859 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:53.873 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:53.873 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:55:53.887 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:55:53.888 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:14.489 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:56:15.057 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:56:15.057 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.500 s.
2024-04-23 14:56:15.057 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:56:15.058 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:15.072 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:56:15.073 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:15.087 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:56:15.088 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:16.848 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 14:56:17.278 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 14:56:17.278 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.374 s.
2024-04-23 14:56:17.278 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:56:17.279 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:17.293 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:56:17.294 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:17.308 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 14:56:17.309 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 14:56:26.972 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 14:56:26.975 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000010F00E06F90>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:01:44.718 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:01:44.720 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:01:44.721 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 15:01:44.721 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 15:01:46.836 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:01:49.605 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:01:49.605 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.307 s.
2024-04-23 15:01:49.613 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:01:49.614 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:01:49.632 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:01:49.634 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:01:49.648 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:01:49.648 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:02:17.134 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:02:17.975 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:02:17.975 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.608 s.
2024-04-23 15:02:17.976 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:02:17.976 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:02:17.991 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:02:17.992 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:02:18.007 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:02:18.007 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:02:28.270 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:02:28.274 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D30DE2E790>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:05:30.415 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:05:30.927 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:05:30.927 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.301 s.
2024-04-23 15:05:30.927 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:30.927 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:30.941 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:30.941 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:30.956 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:30.957 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:34.644 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:05:35.191 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:05:35.192 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.505 s.
2024-04-23 15:05:35.192 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:35.193 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:35.207 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:35.208 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:35.221 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:35.222 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:43.527 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:05:43.529 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D3FD066250>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:05:45.110 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:05:45.687 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:05:45.688 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.536 s.
2024-04-23 15:05:45.688 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:45.688 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:45.702 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:45.703 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:45.716 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:45.717 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:47.717 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:05:48.160 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:05:48.160 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.386 s.
2024-04-23 15:05:48.160 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:48.162 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:48.174 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:48.176 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:48.189 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:05:48.190 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:05:58.025 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:05:58.027 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000001D3FD0DE7D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:08:12.728 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:12.730 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:12.730 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 15:08:12.730 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 15:08:14.767 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:08:17.572 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:08:17.572 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.316 s.
2024-04-23 15:08:17.580 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:17.581 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:17.600 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:17.600 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:17.614 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:17.615 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:23.698 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:08:24.246 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:08:24.246 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.496 s.
2024-04-23 15:08:24.247 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:24.247 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:24.260 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:24.261 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:24.274 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:08:24.275 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:08:50.184 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:08:50.187 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002496CCC67D0>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:09:41.988 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:09:42.512 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:09:42.512 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.301 s.
2024-04-23 15:09:42.512 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:09:42.513 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:09:42.527 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:09:42.528 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:09:42.542 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:09:42.542 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:10:52.787 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:10:53.281 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:10:53.281 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.297 s.
2024-04-23 15:10:53.281 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:10:53.282 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:10:53.296 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:10:53.297 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:10:53.311 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:10:53.312 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:10:57.737 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:10:58.365 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:10:58.365 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.570 s.
2024-04-23 15:10:58.365 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:10:58.366 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:10:58.380 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:10:58.381 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:10:58.395 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:10:58.396 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:11:06.647 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:11:06.648 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000024A02066610>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:12:06.406 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:12:07.025 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:12:07.026 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.422 s.
2024-04-23 15:12:07.026 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:07.027 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:07.040 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:07.047 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:07.062 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:07.063 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:10.469 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:12:10.969 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:12:10.970 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.449 s.
2024-04-23 15:12:10.970 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:10.970 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:10.984 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:10.984 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:10.998 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:10.998 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:20.325 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:12:20.327 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000024A02031690>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:12:49.973 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:12:50.943 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:12:50.943 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.770 s.
2024-04-23 15:12:50.943 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:50.944 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:50.957 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:50.957 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:50.970 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:50.971 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:54.416 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:12:54.869 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:12:54.869 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.389 s.
2024-04-23 15:12:54.869 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:54.870 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:54.883 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:54.885 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:12:54.897 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:12:54.898 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:13:11.113 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:13:11.115 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000249BEFE5250>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:15:15.727 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:15:16.422 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:15:16.422 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.473 s.
2024-04-23 15:15:16.422 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:16.424 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:16.437 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:16.437 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:16.450 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:16.451 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:20.451 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:15:20.980 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:15:20.980 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.463 s.
2024-04-23 15:15:20.980 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:20.980 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:20.994 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:20.996 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:21.008 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:21.009 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:29.852 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:15:29.852 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000024A4B519E50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:15:40.327 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:15:41.104 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:15:41.104 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.539 s.
2024-04-23 15:15:41.104 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:41.105 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:41.120 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:41.121 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:15:41.135 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:15:41.136 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:42.506 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:43.013 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:43.014 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.277 s.
2024-04-23 15:16:43.014 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:43.015 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:43.028 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:43.029 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:43.043 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:43.043 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:43.261 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:43.575 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:43.575 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.274 s.
2024-04-23 15:16:43.575 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:43.576 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:43.590 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:43.591 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:43.606 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:43.608 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:43.808 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:44.204 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:44.204 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.359 s.
2024-04-23 15:16:44.204 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:44.205 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:44.219 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:44.221 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:44.235 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:44.237 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:44.438 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:44.738 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:44.738 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.257 s.
2024-04-23 15:16:44.738 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:44.739 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:44.753 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:44.754 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:44.766 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:44.767 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:44.984 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:45.240 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:45.240 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.231 s.
2024-04-23 15:16:45.240 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:45.241 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:45.254 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:45.255 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:45.267 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:45.268 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:45.485 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:45.765 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:45.765 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.243 s.
2024-04-23 15:16:45.765 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:45.766 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:45.783 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:45.784 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:45.799 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:45.800 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:46.020 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:46.391 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:46.391 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.339 s.
2024-04-23 15:16:46.391 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:46.392 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:46.406 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:46.407 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:46.421 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:46.422 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:46.640 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:46.933 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:46.933 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.260 s.
2024-04-23 15:16:46.933 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:46.933 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:46.947 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:46.948 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:46.964 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:46.965 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:47.181 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:47.475 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:47.475 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.253 s.
2024-04-23 15:16:47.475 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:47.476 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:47.489 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:47.490 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:47.504 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:47.506 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:47.724 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:48.025 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:48.025 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.264 s.
2024-04-23 15:16:48.025 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:48.026 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:48.040 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:48.042 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:48.055 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:48.056 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:48.278 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:48.686 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:48.687 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.364 s.
2024-04-23 15:16:48.687 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:48.688 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:48.701 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:48.702 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:48.715 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:48.716 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:48.931 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:49.291 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:49.291 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.327 s.
2024-04-23 15:16:49.291 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:49.292 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:49.307 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:49.308 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:49.322 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:49.323 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:49.535 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:49.828 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:49.828 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.259 s.
2024-04-23 15:16:49.828 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:49.828 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:49.843 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:49.844 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:49.858 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:49.859 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:50.074 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:50.372 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:50.372 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.255 s.
2024-04-23 15:16:50.372 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:50.373 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:50.388 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:50.389 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:50.403 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:50.404 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:50.622 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:50.913 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:50.913 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.252 s.
2024-04-23 15:16:50.913 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:50.913 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:50.927 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:50.927 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:50.941 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:50.941 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:51.161 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:51.568 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:51.568 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.363 s.
2024-04-23 15:16:51.568 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:51.569 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:51.581 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:51.584 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:51.597 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:51.598 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:58.429 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:16:58.705 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:16:58.705 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.243 s.
2024-04-23 15:16:58.706 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:58.707 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:58.720 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:58.722 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:16:58.737 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:16:58.737 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:01.909 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:17:02.369 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:17:02.370 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.424 s.
2024-04-23 15:17:02.370 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:02.370 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:02.384 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:02.385 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:02.398 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:02.399 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:06.861 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:17:07.403 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:17:07.404 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.500 s.
2024-04-23 15:17:07.404 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:07.405 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:07.419 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:07.420 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:07.434 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:07.435 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:13.121 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:17:13.677 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:17:13.677 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.497 s.
2024-04-23 15:17:13.678 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:13.678 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:13.692 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:13.693 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:13.707 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:13.708 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:18.317 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:17:18.687 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:17:18.687 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.320 s.
2024-04-23 15:17:18.687 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:18.689 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:18.703 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:18.705 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:18.720 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:17:18.721 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:17:24.511 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:17:24.512 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x000002493772CA50>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:18:05.971 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:18:06.465 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:18:06.465 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.277 s.
2024-04-23 15:18:06.465 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:18:06.466 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:18:06.481 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:18:06.481 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:18:06.493 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:18:06.494 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:18:09.269 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:18:09.752 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:18:09.752 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.419 s.
2024-04-23 15:18:09.753 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:18:09.753 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:18:09.767 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:18:09.768 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:18:09.780 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:18:09.782 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:18:18.798 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:18:18.801 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000024A4A2DC790>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:19:35.990 | INFO     | Action.SearchVideo:download_video_srt:135 - <class 'Exception'>
2024-04-23 15:19:37.791 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:19:37.793 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x00000249983B0390>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:20:35.821 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:20:36.593 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:20:36.593 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.562 s.
2024-04-23 15:20:36.593 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:20:36.594 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:20:36.608 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:20:36.609 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:20:36.623 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:20:36.623 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:20:40.271 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:20:40.804 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:20:40.804 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.492 s.
2024-04-23 15:20:40.804 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:20:40.805 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:20:40.818 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:20:40.819 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:20:40.832 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:20:40.833 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:40.603 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:21:41.370 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:21:41.370 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.534 s.
2024-04-23 15:21:41.370 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:21:41.371 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:41.386 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:21:41.387 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:41.401 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:21:41.402 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:44.321 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:21:44.922 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:21:44.922 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.535 s.
2024-04-23 15:21:44.922 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:21:44.924 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:44.937 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:21:44.938 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:44.951 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:21:44.952 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:21:56.618 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:21:56.621 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000024A025C6790>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:22:03.050 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:22:03.800 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:22:03.800 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.521 s.
2024-04-23 15:22:03.800 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:03.801 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:03.816 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:03.817 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:03.831 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:03.832 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:05.442 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:22:05.875 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:22:05.876 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.375 s.
2024-04-23 15:22:05.876 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:05.877 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:05.890 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:05.892 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:05.905 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:05.906 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:14.572 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:22:15.182 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:22:15.182 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.537 s.
2024-04-23 15:22:15.182 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:15.183 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:15.196 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:15.198 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:15.212 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:15.213 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:58.693 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:22:59.387 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:22:59.387 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.456 s.
2024-04-23 15:22:59.387 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:59.388 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:59.402 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:59.402 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:22:59.416 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:22:59.417 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:23:16.540 | INFO     | Action.SearchVideo:download_video_srt:135 - <class 'Exception'>
2024-04-23 15:23:18.469 | ERROR    | metagpt.provider.openai_api:_calc_usage:215 - usage calculation failed: num_tokens_from_messages() is not implemented for model gpt-3.5-turbo-0125. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.
2024-04-23 15:23:18.472 | ERROR    | metagpt.provider.openai_api:acompletion_text:140 - Calling _update_costs with args: (<metagpt.provider.openai_api.OpenAILLM object at 0x0000024A08A2E710>, CompletionUsage(completion_tokens=0, prompt_tokens=0, total_tokens=0)), kwargs: {} failed: 'gpt-3.5-turbo-0125', stack: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\exceptions.py", line 45, in sync_wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 222, in _update_costs
    CONFIG.cost_manager.update_cost(usage.prompt_tokens, usage.completion_tokens, self.model)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\cost_manager.py", line 45, in update_cost
    prompt_tokens * TOKEN_COSTS[model]["prompt"] + completion_tokens * TOKEN_COSTS[model]["completion"]
                    ~~~~~~~~~~~^^^^^^^
KeyError: 'gpt-3.5-turbo-0125'

2024-04-23 15:27:19.702 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:27:20.452 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:27:20.452 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.552 s.
2024-04-23 15:27:20.453 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:20.453 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:20.467 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:20.468 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:20.481 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:20.482 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:25.603 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:27:25.956 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:27:25.956 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.281 s.
2024-04-23 15:27:25.956 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:25.958 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:25.972 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:25.973 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:25.987 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:25.989 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:30.710 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:27:31.487 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:27:31.487 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.707 s.
2024-04-23 15:27:31.487 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:31.488 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:31.501 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:31.502 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:27:31.515 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:27:31.517 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:41:20.337 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:41:21.223 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:41:21.223 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.674 s.
2024-04-23 15:41:21.223 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:41:21.225 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:41:21.238 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:41:21.239 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:41:21.254 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:41:21.255 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:24.162 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:43:24.945 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:43:24.945 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.543 s.
2024-04-23 15:43:24.945 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:24.946 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:24.960 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:24.960 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:24.973 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:24.974 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:28.327 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:43:28.654 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:43:28.654 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.281 s.
2024-04-23 15:43:28.654 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:28.655 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:28.668 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:28.670 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:28.682 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:28.683 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:33.833 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:43:34.382 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:43:34.382 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.495 s.
2024-04-23 15:43:34.383 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:34.383 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:34.398 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:34.399 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:43:34.412 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:43:34.413 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:02.943 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:02.943 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:02.944 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Documents\GitHub\KnowledgeTranslator\workspace
2024-04-23 15:44:02.944 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-04-23 15:44:05.125 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:44:07.912 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:44:07.913 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.312 s.
2024-04-23 15:44:07.922 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:07.923 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:07.943 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:07.944 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:07.958 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:07.960 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:09.801 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:44:10.152 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:44:10.152 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.293 s.
2024-04-23 15:44:10.152 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:10.153 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:10.167 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:10.167 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:10.181 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:10.182 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:17.029 | INFO     | Module.Intermediary:__init__:27 - init!
2024-04-23 15:44:17.582 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:30 - Use device: cuda
2024-04-23 15:44:17.582 | DEBUG    | pycorrector.macbert.macbert_corrector:__init__:31 - Loaded macbert4csc model: Models/macbert4csc-base-chinese, spend: 0.493 s.
2024-04-23 15:44:17.582 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:17.583 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:17.597 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:17.598 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-04-23 15:44:17.611 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-0125
2024-04-23 15:44:17.612 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
