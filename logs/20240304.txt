2024-03-04 16:04:57.464 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:04:57.464 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:04:57.464 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:04:57.464 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:04:59.519 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:04:59.519 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:04:59.535 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: 在线语音社交...']
2024-03-04 16:04:59.535 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:04:59.535 | INFO     | metagpt.roles.role:_act:357 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:04:59.535 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-04 16:16:33.077 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:16:33.077 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:16:33.077 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:16:33.077 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:16:34.305 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:16:34.305 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:16:34.321 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: 在线语音社交...']
2024-03-04 16:16:34.322 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:16:34.322 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:16:38.687 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.002, prompt_tokens: 572, completion_tokens: 135
2024-03-04 16:16:38.687 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-04 16:17:10.893 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:17:10.893 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:17:10.893 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:17:10.893 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:17:12.147 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:17:12.147 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:17:12.164 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: 在线语音社交...']
2024-03-04 16:17:12.164 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:17:12.164 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:17:18.190 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.002, prompt_tokens: 572, completion_tokens: 153
2024-03-04 16:17:18.191 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-04 16:18:23.832 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:18:23.832 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:18:23.833 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:18:23.833 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:18:25.040 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:18:25.040 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:18:25.055 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:18:25.055 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:18:25.055 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:18:37.038 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.006 | Max budget: $10.000 | Current cost: $0.006, prompt_tokens: 947, completion_tokens: 683
2024-03-04 16:18:37.038 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-04 16:19:10.998 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:19:10.998 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:19:10.998 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:19:10.998 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:19:12.221 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:19:12.221 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:19:12.238 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:19:12.238 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:19:12.238 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:19:12.949 | INFO     | Action.SearchInWiki:search_wikipedia:56 - ['The Beatles']
2024-03-04 16:19:19.128 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.004 | Max budget: $10.000 | Current cost: $0.004, prompt_tokens: 947, completion_tokens: 268
2024-03-04 16:19:19.128 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-04 16:20:18.340 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:20:18.340 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:20:18.340 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:20:18.340 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:20:19.548 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:20:19.548 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:20:19.565 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:20:19.565 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:20:19.565 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:20:34.335 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.005 | Max budget: $10.000 | Current cost: $0.005, prompt_tokens: 947, completion_tokens: 581
2024-03-04 16:20:34.335 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=-1
2024-03-04 16:24:21.280 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:24:21.280 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:24:21.280 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:24:21.281 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:24:22.496 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:24:22.496 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:24:22.513 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:24:22.513 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:24:22.513 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:24:28.529 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.004 | Max budget: $10.000 | Current cost: $0.004, prompt_tokens: 965, completion_tokens: 196
2024-03-04 16:24:28.529 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=-1
2024-03-04 16:25:15.986 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:25:15.987 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:25:15.987 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:25:15.987 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:25:17.174 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:25:17.174 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:25:17.192 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:25:17.192 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:25:17.192 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:25:24.170 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.004 | Max budget: $10.000 | Current cost: $0.004, prompt_tokens: 965, completion_tokens: 287
2024-03-04 16:25:24.170 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=-1
2024-03-04 16:26:15.444 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:26:15.444 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:26:15.444 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:26:15.444 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:26:16.627 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:26:16.627 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:26:16.643 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:26:16.644 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:26:16.644 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:26:22.647 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.004 | Max budget: $10.000 | Current cost: $0.004, prompt_tokens: 973, completion_tokens: 221
2024-03-04 16:26:22.647 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=-1
2024-03-04 16:26:58.411 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:26:58.411 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:26:58.411 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 16:26:58.411 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 16:26:59.629 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 16:26:59.629 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 16:26:59.648 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['user: The Beatles...']
2024-03-04 16:26:59.648 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 16:26:59.648 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 16:27:05.029 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.003 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 965, completion_tokens: 127
2024-03-04 16:27:05.029 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=-1
2024-03-04 22:02:05.723 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:05.723 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:05.723 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 22:02:05.723 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 22:02:07.161 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:07.161 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:07.183 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:07.183 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:07.258 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:07.259 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:07.274 | DEBUG    | metagpt.environment:publish_message:108 - publish_message: {"id":"86847237d42e4b98b1ef3a0149756b6b","content":"Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.","role":"Human","cause_by":"metagpt.actions.add_requirement.UserRequirement","sent_from":"","send_to":["<all>"]}
2024-03-04 22:02:07.274 | DEBUG    | metagpt.team:run:130 - max n_round=0 left.
2024-03-04 22:02:07.274 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['Human: Large Language Model...']
2024-03-04 22:02:07.274 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-04 22:02:07.274 | INFO     | Role.Extractor:_act:29 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-04 22:02:07.274 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-04 22:02:07.296 | DEBUG    | metagpt.roles.role:_observe:397 - David(Researcher) observed: ['Human: Large Language Model...']
2024-03-04 22:02:07.296 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=0
2024-03-04 22:02:07.296 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do CollectLinks(CollectLinks)
2024-03-04 22:02:07.298 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['Human: Large Language Model...']
2024-03-04 22:02:07.299 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 22:02:07.299 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 22:02:25.459 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:25.459 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:25.460 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-04 22:02:25.460 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-04 22:02:26.698 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:26.698 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:26.718 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:26.718 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:26.762 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:26.762 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:26.775 | DEBUG    | metagpt.environment:publish_message:108 - publish_message: {"id":"bf4a422f71664e7c86ccd548a137dbf6","content":"Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.","role":"Human","cause_by":"metagpt.actions.add_requirement.UserRequirement","sent_from":"","send_to":["<all>"]}
2024-03-04 22:02:26.775 | DEBUG    | metagpt.team:run:130 - max n_round=0 left.
2024-03-04 22:02:26.776 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['Human: Large Language Model...']
2024-03-04 22:02:26.776 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-04 22:02:26.776 | INFO     | Role.Extractor:_act:29 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-04 22:02:26.776 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-04 22:02:26.794 | DEBUG    | metagpt.roles.role:_observe:397 - David(Researcher) observed: ['Human: Large Language Model...']
2024-03-04 22:02:26.794 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=0
2024-03-04 22:02:26.794 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do CollectLinks(CollectLinks)
2024-03-04 22:02:26.796 | DEBUG    | metagpt.roles.role:_observe:397 - Mark(WikiResearcher) observed: ['Human: Large Language Model...']
2024-03-04 22:02:26.796 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=0
2024-03-04 22:02:26.797 | INFO     | Role.WikiResearcher:_act:36 - Mark(WikiResearcher): to do WikiSearchAndSummarize(WikiSearchAndSummarize)
2024-03-04 22:02:30.738 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-04 22:02:30.738 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-04 22:02:30.738 | DEBUG    | metagpt.environment:publish_message:108 - publish_message: {"id":"d2f9bc93df2e4e8093523a7dd472c400","content":"[\"Large Language Models\", \"program-of-thoughts approach\"]","role":"Extractor","cause_by":"Action.KeywordExtract.KeywordExtract","sent_from":"","send_to":["<all>"]}
2024-03-04 22:02:30.828 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 112, completion_tokens: 15
2024-03-04 22:02:31.761 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-04 22:02:31.761 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-04 22:02:31.774 | DEBUG    | Action.SearchInWeb:run:142 - ### Requirements
1. The keywords related to your research topic and the search results are shown in the "Search Result Information" section.
2. Provide up to 4 queries related to your research topic base on the search results.
3. Please respond in the following JSON format: ["query1", "query2", "query3", ...].

### Search Result Information
#### Keyword: 大型语言模型
 Search Result: [{'title': 'ChatGPT — LLM 模型（大型语言模型）. 中國 — 了解ChatGPT 的 ...', 'link': 'https://medium.com/chatgpt-learning-asia/chatgpt-llm-%E6%A8%A1%E5%9E%8B-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-2947b198fc8e', 'snippet': 'May 12, 2023 ... ChatGPT — LLM 模型（大型语言模型）. LLM（大型语言模型）是这些模型中最著名的。 用于使用自然语言处理(NLP) 算法和称为Transformers 的AI 训练技术解决\xa0...'}, {'title': '设置开源大型语言模型: - 作者花了几个晚上设置一台家用笔记本电脑 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%BA%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-81ec2bf5842a', 'snippet': 'Feb 24, 2024 ... - 在本地使用开源模型，例如Code Llama LLM，可以对Python 代码进行实验和交叉检查。 “运行”与“训练”大型语言模型的重要性: - 与训练模型相比，在笔记本\xa0...'}, {'title': 'RAG 檢索增強生成— 讓大型語言模型更聰明的秘密武器. 看完文章後 ...', 'link': 'https://medium.com/infuseai/rag-retrieval-augmented-generation-introduction-a5854cb6393e', 'snippet': 'Nov 5, 2023 ... I. RAG 檢索增強生成. 檢索增強生成（Retrieval-Augmented Generation, RAG）是一種結合了搜尋檢索和生成能力的自然語言處理架構。透過這個架構，模型可以\xa0...'}, {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... 在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。'}, {'title': 'Building Large Language Model-powered AI Applications | by Xin ...', 'link': 'https://medium.com/mlearning-ai/building-large-language-model-powered-ai-applications-96780d67c64a', 'snippet': 'May 8, 2023 ... I want to survey building AI applications powered by large language models and related emerging technologies.'}, {'title': '从「文化技术」理解大型语言模型- LM Po - Medium', 'link': 'https://medium.com/@edmond.po/%E4%BB%8E%E6%96%B0%E6%96%87%E5%8C%96%E6%8A%80%E6%9C%AF%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B2%BB%E7%90%86-bb7239eb4c8b', 'snippet': 'Jul 14, 2023 ... 人工智能(AI) 的最新进展，特别是在大型语言模型(Large Language Model — LLM) 领域（例如OpenAI 的ChatGPT 和Google 的LaMDA），引发了有关这些系统\xa0...'}, {'title': 'Catch Up On Large Language Models | by Marco Peixeiro | Towards ...', 'link': 'https://medium.com/towards-data-science/catch-up-on-large-language-models-8daf784f46f8', 'snippet': 'Sep 5, 2023 ... In fact, the original Transformer architecture used an embedding space of 512 dimensions. This means that the model could learn 512 different\xa0...'}, {'title': '大型語言模型的預訓練任務. ChatGPT… | by Albert Chen | Jan, 2024 ...', 'link': 'https://medium.com/@albertchen3389/%E5%A4%A7%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A0%90%E8%A8%93%E7%B7%B4%E4%BB%BB%E5%8B%99-b831dcf8f6f7', 'snippet': 'Jan 4, 2024 ... 給定一對句子，預測第二個句子相對於第一個句子是蘊含、矛盾還是中性。這種任務幫助模型學習如何理解和分析文本中的複雜語言關係，特別是在不同類型和風格\xa0...'}]

#### Keyword: 数值计算错误
 Search Result: [{'title': '市场数据预言机的可靠性和安全性. 让我们聊一聊可靠性的话题… | by ...', 'link': 'https://pythchinese.medium.com/pyth-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%A2%84%E8%A8%80%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7-f9de664e5d01', 'snippet': 'May 13, 2022 ... ... 数据的。 每个数据发布者Bᵢ 发生程序错误的概率。我们通过寻找历史价格序列中的极端异常情况来计算这个概率，例如价格为0 或价格与聚合价格相差一个\xa0...'}, {'title': '租赁大数据看板建设过程中数据清洗及程度思考| 人人都是产品经理', 'link': 'https://www.woshipm.com/data-analysis/4998713.html', 'snippet': '如果只是想客观看看市场行情，或者该字段并不是太重要的数据，只是走势有参考作用，则可以考虑删除对应的数据，以免造成困扰，避免空值导致计算结果偏差或报错。 四、错误\xa0...'}, {'title': '产品经理在数据分析过程中常用的Excel技能| 人人都是产品经理', 'link': 'https://www.woshipm.com/data-analysis/5748189.html', 'snippet': '下图所示的这个公式就是一个iferror的使用案例，当蓝色选中部分的最终计算结果是一个错误值的时候，即运算无法正常进行，出现报错时，整个公式最终的返回值就是0。用这个\xa0...'}, {'title': '从用户视角，讨论电商数据产品的设计理念| 人人都是产品经理', 'link': 'https://www.woshipm.com/pd/5697865.html', 'snippet': '... 数据来计算；; 以数据作为未来目标，猜想未来，例如通过数据趋势猜想未来变化，和制定目标。 数据是该人群工作场景中的基础。以一份错误的数据作为依据，会导致产生错误\xa0...'}, {'title': '交通| GAMS快速入门及其在运输问题求解的应用. 推文作者：AmieeXue', 'link': 'https://medium.com/@operations_r/%E4%BA%A4%E9%80%9A-gams%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%8F%8A%E5%85%B6%E5%9C%A8%E8%BF%90%E8%BE%93%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3%E7%9A%84%E5%BA%94%E7%94%A8-347532daf9e', 'snippet': 'Jul 3, 2023 ... 美元符号后面是数字错误代码，在回显打印后进行解释。下面是几个例子 ... 可以通过提供用于计算数据的公式而不是明确输入它们，来节省时间并减少输入\xa0...'}, {'title': '學習記錄. Question | by 肚子又餓了٩(ŏ﹏ŏ、)۶ | Medium', 'link': 'https://medium.com/@superwang0603/%E5%AD%B8%E7%BF%92%E8%A8%98%E9%8C%84-8a76d93dab05', 'snippet': 'Feb 23, 2023 ... 这是因为fit_transform 方法会根据训练数据计算标准化所需的统计特性，然后将训练数据标准化。 ... 错误，提示需要先使用fit 方法计算训练数据的均值和标准\xa0...'}, {'title': 'LEO 中的定点运算- aleo123_io - Medium', 'link': 'https://medium.com/@aleo123_io/leo-%E4%B8%AD%E7%9A%84%E5%AE%9A%E7%82%B9%E8%BF%90%E7%AE%97-305e1b7d0cbc', 'snippet': 'Apr 4, 2023 ... 同时, 最大表示错误被计算为(1/S)/2，所以在这个例子中，它是(1/25)/2=1/64=0.015625。 因此，一个更宽泛的倍数因子使我们能够有更准确的数字表达\xa0...'}, {'title': 'A/B测试算法揭秘第二篇：如何分析试验数据（上） | 人人都是产品经理', 'link': 'https://www.woshipm.com/pmd/380883.html', 'snippet': '第I 类错误（弃真错误）：原假设为真时拒绝原假设；第I 类错误的概率记为α(alpha) ... 例如，我们根据某次假设检验的样本数据计算得出显著性水平p=0.04；这个值意味着\xa0...'}]


2024-03-04 22:02:33.221 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 215, completion_tokens: 100
2024-03-04 22:02:33.221 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[WikiSearchAndSummarize], state=-1
2024-03-04 22:02:33.221 | DEBUG    | metagpt.environment:publish_message:108 - publish_message: {"id":"c612056a5e6d489586b6b8f696be4ff9","content":"Large Language Models (LLMs) are powerful tools in the field of artificial intelligence that can generate human-like text. However, they often make errors when performing numerical calculations. In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach involves generating executable code to solve problems. While the \"Reference Information\" section does not provide specific details about LLMs and their errors in numerical calculations, it serves as a starting point to explore the broader field of artificial intelligence and related concepts.","role":"WikiResearcher","cause_by":"Action.SearchInWiki.WikiSearchAndSummarize","sent_from":"","send_to":["<all>"]}
2024-03-04 22:02:34.575 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.012 | Max budget: $10.000 | Current cost: $0.010, prompt_tokens: 3235, completion_tokens: 70
2024-03-04 22:02:35.495 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
大型语言模型的程序思维方法

### The online search results
0: {'title': '谷歌的NotebookLM 旨在成为终极写作助手- Conan Xin - Medium', 'link': 'https://conanxin.medium.com/%E8%B0%B7%E6%AD%8C%E7%9A%84-notebooklm-%E6%97%A8%E5%9C%A8%E6%88%90%E4%B8%BA%E7%BB%88%E6%9E%81%E5%86%99%E4%BD%9C%E5%8A%A9%E6%89%8B-394a267e5606', 'snippet': 'Feb 24, 2024 ... ... 程序的行为和我们与该应用程序互动的方法。 约翰逊通过对软件的终身迷恋 ... 约翰逊还不知道谷歌不仅拥有类似规模的大型语言模型，而且已经在一个与他\xa0...'}
1: {'title': '人工智能简史（Draft）. 追溯机器人思维的兴起| by Conan Xin | Medium', 'link': 'https://conanxin.medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2-draft-35531f6449b2', 'snippet': 'May 27, 2023 ... ... 程序能够以与人类无异的方式理解和产生语言。 几十年来，文本是一种通用 ... 大型语言模型中自发地出现了。在此之前，心智理论被认为是一种明显的人类\xa0...'}
2: {'title': '复杂推理：大语言模型的北极星能力| 人人都是产品经理', 'link': 'https://www.woshipm.com/ai/5827606.html', 'snippet': '当语言模型成为新一代操作系统内核时，提示工程/ 场景学习将成为新一代脚本编程(shell script)；. 在第4 部分，我们讨论了如何评估大型语言模型的推理能力。我们介绍Chain-\xa0...'}
3: {'title': '66個大型語言模型LLM經典論文', 'link': 'https://tomohiroliu22.medium.com/66%E5%80%8B%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8Bllm%E7%B6%93%E5%85%B8%E8%AB%96%E6%96%87-0fcdab74e822', 'snippet': 'Dec 17, 2023 ... 模型卡還會公開模型預期使用的情境、性能評估程序的詳細訊息。雖然我們主要 ... 方法在提示中提供了一些思維鏈範例。在三個大型語言模型上的實驗表明，思維\xa0...'}
4: {'title': 'RLHF: 一種引導小孩正確成長的思維方法和技術. 看完文章後歡迎按 ...', 'link': 'https://medium.com/infuseai/reinforcement-learning-with-human-feedback-rlhf-48a7646e083a', 'snippet': 'Dec 24, 2023 ... RLHF 就是一種類似的教學過程，但這次你是在教大型語言模型模型，而不是一個真正的人，而RLHF 可以分為Reinforcement Learning 和Human Feedback 階段：.'}
5: {'title': '组织的终结- Conan Xin - Medium', 'link': 'https://conanxin.medium.com/%E7%BB%84%E7%BB%87%E7%9A%84%E7%BB%88%E7%BB%93-fac459f3bfcc', 'snippet': 'May 25, 2023 ... 这就是大型语言模型的用武之地。 人工智能模型如何解决笔记组织问题. 像GPT-3 这样的AI 模型可以通过几种关键方式解决组织问题。 首先，它们可以自动\xa0...'}
6: {'title': 'AI时代，大语言模型下的机会与不适| 人人都是产品经理', 'link': 'https://www.woshipm.com/ai/5806969.html', 'snippet': '总体来说，如果工作对科学方法和判断性思维依赖性较强，那么就不会过多接触GPT技术，而如果涉及编程和写作技能，就会更容易接触GPT技术或受影响。 而从行业层面来看\xa0...'}
7: {'title': '投身LLM（大型语言模型），要从本质上想明白3个问题| 人人都是 ...', 'link': 'https://www.woshipm.com/ai/5793761.html', 'snippet': 'Mar 2, 2023 ... 作者在看LLM（大型语言模型）的机会时，深度思考了3个问题：LLM下一个 ... 方式，从而得到对任务方法的最小描述长度。”我的理解就是学习本质，而不是\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-04 22:02:37.011 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.017 | Max budget: $10.000 | Current cost: $0.005, prompt_tokens: 1621, completion_tokens: 15
2024-03-04 22:02:37.935 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
大型语言模型在数值计算中的问题

### The online search results
0: {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... 由于高成本、有限的可用性、数据清洁度问题、潜在的偏见以及 ... 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的一个重要因素。'}
1: {'title': '人工智能简史（Draft）. 追溯机器人思维的兴起| by Conan Xin | Medium', 'link': 'https://conanxin.medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2-draft-35531f6449b2', 'snippet': 'May 27, 2023 ... 大多数模型的另一个问题是它们将大文档分解成多个部分并逐个处理整个文档 ... 大型语言模型中自发地出现了。在此之前，心智理论被认为是一种明显的人类\xa0...'}
2: {'title': '大语言模型数据隐私的解决之道：全同态加密- Ingonyama 中文 ...', 'link': 'https://medium.com/@ingonyamachinese/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9A%90%E7%A7%81%E7%9A%84%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93-%E5%85%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86-b4eedcf33194', 'snippet': 'Sep 24, 2023 ... 它的魅力在于神奇的特性：它允许对加密数据进行计算，而无需先解密，实现对敏感信息的隐私推理。 借助这种特性可以确保两个重要的事情：数据在处理过程中\xa0...'}
3: {'title': '将数千兆字节的数据引入智能合约：与Space and Time的Scott ...', 'link': 'https://medium.com/@hopeofmavia/%E5%B0%86%E6%95%B0%E5%8D%83%E5%85%86%E5%AD%97%E8%8A%82%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BC%95%E5%85%A5%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%B8%8Espace-and-time%E7%9A%84scott-dykstra%E8%BF%9B%E8%A1%8C%E5%AF%B9%E8%AF%9D-ccdedf5cd815', 'snippet': 'Feb 19, 2024 ... 如果您的大型语言模型的训练直接来自一个可验证的数据库，该数据库保存着 ... 所有原始数据都加载到我们的数据仓库中，但数字指纹足够小，可以以经济\xa0...'}
4: {'title': '设置开源大型语言模型: - 作者花了几个晚上设置一台家用笔记本电脑 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%BA%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-81ec2bf5842a', 'snippet': 'Feb 24, 2024 ... - 实验中突出显示了特定的LLM 模型及其参数。 Ollama 和运行LLM 模型的背景 ... - 累积距离以及每个路段的计算步速均已添加到数据集中。 计算段信息\xa0...'}
5: {'title': 'Footprint Analytics x Future3 Campus联合发布AI与Web3研究报告 ...', 'link': 'https://medium.com/@Future3Campus/footprint-analytics-x-future3-campus%E8%81%94%E5%90%88%E5%8F%91%E5%B8%83ai%E4%B8%8Eweb3%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A-c3759e8c46cf', 'snippet': 'Dec 4, 2023 ... 大型语言模型的培训需要依赖大规模数据，通过学习数据中的模式来建立模型 ... 准确性和幻觉（Hallucination）问题：AI 模型中幻觉的出现可能受多因素\xa0...'}
6: {'title': 'Space and Time，简称SxT - ranran - Medium', 'link': 'https://medium.com/@ranran123/space-and-time-%E7%AE%80%E7%A7%B0sxt-875639f4628f', 'snippet': 'Jan 9, 2024 ... 智能合同和LLM的融合： 在智能合同领域，SxT 提供了可验证的数据处理，确保合同的执行是可信赖的。对于大型语言模型，SxT 可能用于在分布式环境中进行高效\xa0...'}
7: {'title': 'Foresight Ventures: 理性看待去中心化算力网络. 作者: Yihan ...', 'link': 'https://medium.com/@foresightventures-zh/foresight-ventures-%E7%90%86%E6%80%A7%E7%9C%8B%E5%BE%85%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E7%AE%97%E5%8A%9B%E7%BD%91%E7%BB%9C-7c6e56b0adbe', 'snippet': 'Jun 1, 2023 ... 寄予厚望的ZK 是否能解决大模型训练时的数据隐私问题？ 理论上ZKP 可以用于确保分布式计算中的数据隐私，让一个节点证明其已经按照规定进行了计算，但\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-04 22:02:39.229 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.024 | Max budget: $10.000 | Current cost: $0.006, prompt_tokens: 2119, completion_tokens: 15
2024-03-04 22:02:40.102 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
使用大型语言模型进行数值计算的挑战

### The online search results
0: {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... 本文是一系列多个实验中的第一篇，使用相似的业务案例进行演示。未来的 ... 当数据收集具有挑战性或反洗钱（AML）团队正在创建新的监测规则时，LLM可以\xa0...'}
1: {'title': '设置开源大型语言模型: - 作者花了几个晚上设置一台家用笔记本电脑 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%BA%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-81ec2bf5842a', 'snippet': 'Feb 24, 2024 ... - 在本地使用开源模型，例如Code Llama LLM，可以对Python 代码进行实验和交叉检查。 “运行”与“训练”大型语言模型的重要性: - 与训练模型相比，在笔记本\xa0...'}
2: {'title': '大语言模型数据隐私的解决之道：全同态加密- Ingonyama 中文 ...', 'link': 'https://medium.com/@ingonyamachinese/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9A%90%E7%A7%81%E7%9A%84%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93-%E5%85%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86-b4eedcf33194', 'snippet': 'Sep 24, 2023 ... 通过对加密数据进行计算，它可以确保提示词完全保密，同时还能保护大语言 ... 在大语言模型中使用全同态加密的挑战. 随着最新技术的进展，目前最好的全\xa0...'}
3: {'title': 'Foresight Ventures: 理性看待去中心化算力网络. 作者: Yihan ...', 'link': 'https://medium.com/@foresightventures-zh/foresight-ventures-%E7%90%86%E6%80%A7%E7%9C%8B%E5%BE%85%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E7%AE%97%E5%8A%9B%E7%BD%91%E7%BB%9C-7c6e56b0adbe', 'snippet': 'Jun 1, 2023 ... 但也面临通信延迟、数据隐私、模型安全等挑战。和模型训练相比，推理时的计算复杂度和数据交互性较低，更适合在分布式环境中进行。 通过\xa0...'}
4: {'title': 'Footprint Analytics x Future3 Campus联合发布AI与Web3研究报告 ...', 'link': 'https://medium.com/@Future3Campus/footprint-analytics-x-future3-campus%E8%81%94%E5%90%88%E5%8F%91%E5%B8%83ai%E4%B8%8Eweb3%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A-c3759e8c46cf', 'snippet': 'Dec 4, 2023 ... AI 可以利用Web3 中的分散式计算资源进行模型的训练、数据分析和预测。 ... 大型语言模型的培训需要依赖大规模数据，通过学习数据中的模式来建立模型。区块\xa0...'}
5: {'title': '6000字解读：当前大语言模型LLM研究的10大挑战| 人人都是产品经理', 'link': 'https://www.woshipm.com/ai/5938398.html', 'snippet': '基于文本的模型，需要大量文本，以至于我们担心很快就会用完互联网数据来训练基于文本的模型。 ... 而光子芯片使用光子来传输数据，利用光速进行更快、更高效的计算。在这个\xa0...'}
6: {'title': '大模型的革命：挖掘AI领域潜力的关键因素- 一烫杂货铺- Medium', 'link': 'https://medium.com/@onetown/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9D%A9%E5%91%BD-%E6%8C%96%E6%8E%98ai%E9%A2%86%E5%9F%9F%E6%BD%9C%E5%8A%9B%E7%9A%84%E5%85%B3%E9%94%AE%E5%9B%A0%E7%B4%A0-5d8eb6937f78', 'snippet': 'Jul 6, 2023 ... 例如，使用大规模预训练的语言模型如GPT，可以进行语言生成、文本摘要和 ... 综上所述，大模型的挑战涉及到计算和存储需求、训练时间和成本以及数据集\xa0...'}
7: {'title': '大语言模型部署应用与基础设施成本优化. 1. 引言| by draftai | Medium', 'link': 'https://draftai.medium.com/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8%E4%B8%8E%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E6%88%90%E6%9C%AC%E4%BC%98%E5%8C%96-88cb58dc12e9', 'snippet': 'Aug 2, 2023 ... 部署LLM 是一个充满挑战的任务，因为它们需要大量计算资源来执行推理，尤其是模型用于实时应用程序（例如聊天机器人或虚拟助手）为甚。 以ChatGPT 为例，\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-04 22:02:41.577 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.030 | Max budget: $10.000 | Current cost: $0.007, prompt_tokens: 2196, completion_tokens: 15
2024-03-04 22:02:43.322 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
改进大型语言模型在数值计算中的准确性

### The online search results
0: {'title': '人工智能简史（Draft）. 追溯机器人思维的兴起| by Conan Xin | Medium', 'link': 'https://conanxin.medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2-draft-35531f6449b2', 'snippet': 'May 27, 2023 ... 超越LLM的图灵测试. 像GPT-4 或GPT-3 这样的大型语言模型(LLM) 是有史以来最强大、最复杂的计算系统\xa0...'}
1: {'title': 'RLHF再也不需要人类了！谷歌团队研究证明，AI标注已达人类水平 ...', 'link': 'https://www.woshipm.com/ai/5898421.html', 'snippet': '如今，大型语言模型训练中一个关键部分便是RLHF。人类通过对AI输出的质量进行评级 ... 奖励模型的准确性如何随训练示例进行变化？ 研究人员发现，需要经过数千个示例\xa0...'}
2: {'title': 'ZK Section 9是什么？. 大数据的爆炸式增长及其可用性推动了人工 ...', 'link': 'https://medium.com/cortexlabs/zk-section-9%E6%98%AF%E4%BB%80%E4%B9%88-304eef769472', 'snippet': 'Dec 4, 2022 ... ... 中造成不正确或误导性的结果。人工智能模型的执行也会占用过多的资源， ... 模型可以在公共数据集下具有一定的准确性。 2022 年，著名的zk-SNARK\xa0...'}
3: {'title': '如何构建可信的链上AI：Arweave 的应用畅想. Web3 正在加速发展 ...', 'link': 'https://medium.com/@permadao/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E5%8F%AF%E4%BF%A1%E7%9A%84%E9%93%BE%E4%B8%8A-ai-arweave-%E7%9A%84%E5%BA%94%E7%94%A8%E7%95%85%E6%83%B3-a710eb79cacf', 'snippet': 'Oct 25, 2023 ... 我们可以追溯到机器学习历程中的三个主要变革：算法的改进、数据的增加和计算能力的提升。然而，AI 目前仍面临一些问题，例如黑箱模型的不透明性和数据集\xa0...'}
4: {'title': 'Footprint Analytics x Future3 Campus联合发布AI与Web3研究报告 ...', 'link': 'https://medium.com/@Future3Campus/footprint-analytics-x-future3-campus%E8%81%94%E5%90%88%E5%8F%91%E5%B8%83ai%E4%B8%8Eweb3%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A-c3759e8c46cf', 'snippet': 'Dec 4, 2023 ... 大型语言模型的培训需要依赖大规模数据，通过学习数据中的模式来建立模型 ... 准确性和幻觉（Hallucination）问题：AI 模型中幻觉的出现可能受多因素\xa0...'}
5: {'title': '基于大语言模型的自主智能体实现调研. A Survey on Large Language ...', 'link': 'https://medium.com/@xiaofeng_metis/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-a-survey-on-large-language-model-based-autonomous-agents-f2bdf348e4eb', 'snippet': 'Sep 1, 2023 ... 由于代理是在一个动态过程中学习的，他们不仅处理静态数据，还参与到对自己理解、适应和与人类对齐的持续改进中来。 基于LLM的自助智能体应用. LLM（语言\xa0...'}
6: {'title': 'AI 的安全性问题研究. 在OpenAI推出第四代chatGPT之后，流行之风 ...', 'link': 'https://medium.com/@hoodrhbob/ai-%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7%E9%97%AE%E9%A2%98%E7%A0%94%E7%A9%B6-5e36ebd8ccc7', 'snippet': 'Mar 22, 2023 ... 使大型语言模型更高效或改进强化学习算法的研究将属于这一标题。能力工作生成并改进了我们在对齐研究中调查和使用的模型。我们一般不发表这类工作，因为\xa0...'}
7: {'title': '复杂推理：大语言模型的北极星能力| 人人都是产品经理', 'link': 'https://www.woshipm.com/ai/5827606.html', 'snippet': '在这篇文章中，我们将仔细分析讨论如何让大语言模型拥有强大的复杂推理能力。 以下为本文目录，建议结合要点进行针对性阅读。 动机：大语言模型作为新一代计算平台; 增加大\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-04 22:02:44.506 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.035 | Max budget: $10.000 | Current cost: $0.005, prompt_tokens: 1688, completion_tokens: 15
2024-03-04 22:02:44.506 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=1
2024-03-04 22:02:44.506 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do WebBrowseAndSummarize(WebBrowseAndSummarize)
2024-03-04 22:02:57.546 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型在数值计算中的问题".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

大语言模型数据隐私的解决之道：全同态加密

Ingonyama 中文

·

Follow

Sep 24, 2023

--

原文链接：https://medium.com/@ingonyama/solving-llm-privacy-with-fhe-3486de6ee228

人工智能的崛起令人叹为观止。从基本算法到最先进的形式 — 大语言模型（LLM），如 ChatGPT 和 Copilot — 人工智能处于技术演进的前沿。

随着这些模型与用户互动并处理大量数据和提示，数据隐私的问题就变得非常重要。亚马逊和苹果等公司已经限制员工访问ChatGPT等公共API，以防止因人工智能交互而导致的数据泄露。此外，可以合理地预期，很快将出台法规来要求一定程度的用户隐私保护。

我们如何确保与这些模型的交互、提问和共享的数据保持隐私呢？

全同态加密 (FHE) 深度解读

在密码学领域，全同态加密是一个突破性的概念。它的魅力在于神奇的特性：它允许对加密数据进行计算，而无需先解密，实现对敏感信息的隐私推理。

借助这种特性可以确保两个重要的事情：数据在处理过程中保持安全，以及对模型的知识产权（IP）的完全保护。

隐私推理与知识产权保护

如今，”隐私 “和 “用户体验 “似乎是鱼和熊掌不可兼得。人们往往为了更好的体验，将自己的信息托管到第三方公司。我们相信，这些第三方公司可以平衡好隐私与优质的服务，而不必在隐私性更高但缺少功能的本地解决方案或牺牲隐私以获得丰富功能的服务之间做出选择。

全同态加密能够在完全保护模型知识产权的情况下实现隐私推理。通过对加密数据进行计算，它可以确保提示词完全保密，同时还能保护大语言模型的知识产权。

传统加密技术与全同态加密技术

在传统加密领域，如果对加密数据进行有意义的运算，首先需要对其进行解密。但是解密就意味着易受到攻击，哪怕是一瞬间。
相比之下，全同态加密可以直接对密文进行运算，确保敏感信息在整个运算过程中保持隐私。

全同态加密的重要性

全同态加密的重要性不仅限于理论。想象一下云计算服务，可以在不解密数据的情况下进行数据处理，或者医疗数据库可以在不获取敏感患者详细信息的情况下进行分析。全同态加密的潜在应用非常广泛且多样化，包括安全投票系统和对加密数据库进行隐私搜索等。

全同态加密的数学理论

全同态加密利用容错学习（LWE）问题，这是一种格子密码学技术，具有抗量子性。在容错学习中，利用随机噪声使数据变得不可读，除非拥有秘钥。对加密数据进行算术运算是可能的，但这通常会增加噪声水平。如果连续进行过多的运算，任何人都无法读取数据，包括持有密钥的人。

这就是部分同态加密（SHE）。要将部分同态加密转换为全同态加密，需要一种能降低噪音水平的操作。这种操作被称为 “自举”（Bootstrapping），多种全同态加密方案都采用了自举操作。在本文中，我们将重点讨论环面上的全同态加密方案(Torus FHE)，它利用数学环面的代数结构来实现 全同态加密。

环面全同态加密的优势

尽管每种全同态加密方案都有自己的优缺点，但在实际场景中，TFHE目前拥有更高效的实现。TFHE的另一个重要优势在于其可编程自举（Programmable Bootstrapping，PBS），它将通常的自举操作扩展到包括对单变量函数的计算，例如在机器学习领域中至关重要的激活函数。

TFHE 的一个劣势是要求在计算中每执行一次算术运算都要执行一次 PBS 操作，而其他方案则允许在自举操作之间批量执行一些操作。

关于全同态加密推理时间的假设与逼近

为了估计使用全同态加密进行大语言模型推理所需的时间，我们做出了一些假设：

每个令牌所需的算术操作次数大约是模型中参数数量的1–2倍。这是一个下限，因为每个令牌都使用了整个模型，我们将假设这个下限足够接近实际需求。
大语言模型中的每个算术操作都可以映射到TFHE中的一个算术操作。这基本上是两种方案中变量类型大小的说明。我们假设对于大语言模型来说，INT4变量足够，并且对于TFHE来说是可行的。
大语言模型中的每个算术操作都需要映射到全同态加密中的一个算术操作。这意味着我们不能在未加密的情况下运行模型的一部分。Zama最近的一篇博文考虑了不使用这个假设的FHE推理，其中大部分模型由用户在本地执行，没有任何加密，只有一个小部分（例如单个注意力头）在模型的公司服务器上使用全同态加密运行。我们认为，这种方法实际上并没有保护模型的知识产权，因为在这种情况下，用户可以只运行缺失的头部，并且只有轻微的精度损失，如此处所示，或者对缺失部分进行相对廉价的训练，以获得与原始模型相当的结果。
TFHE中的每个算术操作都需要进行一次PBS（可编程自举）。PBS是TFHE计算的主要瓶颈。
目前最先进的TFHE实现是FPT。这是一种FPGA实现，以每35微秒计算一次PBS。
在大语言模型中使用全同态加密的挑战

随着最新技术的进展，目前最好的全同态加密实现可以在仅需35微秒的时间内执行一次算术操作。然而，当考虑到像GPT2这样复杂的模型时，单个令牌需要进行惊人的15亿次操作。这意味着每个令牌的处理时间约为52,000秒。

为了更好地理解，对于语言模型来说，一个令牌可以表示一个字符或一个完整的单词等内容。想象一下与一个语言模型进行交互，其中响应时间需要一两个星期！这样的延迟显然对于实时通信或模型的任何实际应用都是不可行的。

这显示了在当前的全同态加密技术下，对于大规模的语言模型来说，实现实时推理仍然是一个巨大的挑战。尽管全同态加密在数据保护方面具有重要意义，但在需要高度计算密集型的任务中，其性能限制可能使其难以应用于实际场景。对于实时交互和快速响应的需求，可能需要探索其他的安全计算和隐私保护解决方案。

潜在的解决方案

为了使全同态加密应用到大语言模型中，以下是一个可能的路线图：

使用多机器实现并行处理：
从每个令牌的52,000秒开始。
通过部署10,000个并行机器，我们将时间缩短到每个令牌的5秒。请注意，大语言模型确实可以高度并行化，目前的推理通常在数千个或更多的GPU核心上并行执行。

2. 过渡到先进的硬件：

从改进后的每个令牌的5秒开始。
切换到GPU或ASIC，我们可以实现每个令牌0.1秒的处理时间。虽然GPU可以在速度上提供更直接的收益，但ASIC在速度和功耗方面都可以提供更高的收益，例如ZPU就是这样的例子。

正如图所示，使用现有的数据加速技术，通过全同态加密可以实现大语言模型的私有推理。一个大型但可行的初始投资可以支持建立足够大的数据中心来实现这一目标。然而，这种可能性仍然是微乎极微的，并且对于更大的大语言模型，如Copilot（120亿参数）或GPT3（1750亿参数），仍存在差距需要弥补。

对于Copilot来说，较小的令牌吞吐量就足够了，因为它生成的是代码输出，通常比人类语言更简洁。如果我们将吞吐量要求降低8倍，那么Copilot也能达到可行性的目标。

最后的差距可以通过组合更大规模的并行化、更好的实现以及在全同态加密中进行引导的更高效算法来弥补。在Ingonyama，我们相信算法是弥合这一差距的重要组成部分，我们的团队目前正专注于算法的研究和开发。

结束语

全同态加密的安全性和大语言模型的计算能力的结合可以重新定义人工智能交互，确保效率和隐私两者兼顾。虽然存在一些挑战，但通过持续的研究和创新，我们可以实现与AI模型（如ChatGPT）的交互既具有即时性又具有隐私性的未来。这将为用户提供更高效和安全的体验，并推动人工智能技术在各个领域的广泛应用。

关注我们的进展

Twitter: https://twitter.com/Ingo_zk

Github: https://github.com/ingonyama-zk

YouTube: https://www.youtube.com/@ingo_zk

LinkedIn: https://www.linkedin.com/company/ingonyama

加入我们：https://www.ingonyama.com/careers

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
密碼學
人工智能
大语言模型
ChatGPT
Github Copilot

--

Written by Ingonyama 中文
18 Followers
Follow

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:02.878 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "改进大型语言模型在数值计算中的准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

人工智能简史（Draft）

Conan Xin

·

Follow

16 min read
·
May 27, 2023

追溯机器人思维的兴起

编者按：多年来，人工智能的发展以蜗牛般的速度前进。有时感觉我们永远无法超越AOL SmarterChild 聊天机器人的时代。然后，一切都变了。在短短五年多的时间里，我们经历了一个世纪的创新。

在这篇文章中，Anna-Sofia Lesiv探讨了导致我们走到这一刻的主要转折点。无论您是关注 ChatGPT 一举一动的 AI 超级粉丝，还是想知道“transformer”到底是什么东西的不情愿的勒德分子，这篇文章都值得一读。

随着机器学习的最新进展，我们可能正在进入一个技术进步时期，其影响力比科学革命和工业革命的总和还要大。Transformer 架构的发展和在数以千计的 GPU 上训练的大规模深度学习模型导致了智能、复杂程序的出现，这些程序能够以与人类无异的方式理解和产生语言。

几十年来，文本是一种通用界面，可以对所有人类知识进行编码并由机器操纵，这一概念一直吸引着数学家和计算机科学家。仅在过去几年中出现的大量语言模型现在就证明了这些思想家正在深入研究。像 GPT-4 这样的模型已经不仅能够创造性地写作，而且能够编码、下棋和回答复杂的查询。

这些模型的成功，以及它们通过增量扩展和训练的快速改进，表明当今可用的学习架构可能很快就足以实现通用人工智能。可能需要新的模型来产生通用人工智能 (AGI)，但如果现有模型走在正确的轨道上，那么通向通用人工智能的道路可能会变成一个经济学问题 — — 需要什么才能获得资金和训练足够大的模型所需的能量？

在如此令人振奋的进步时代，重要的是要仔细研究支撑技术的基础，这些技术肯定会改变我们所知道的世界。

超越LLM的图灵测试

像 GPT-4 或 GPT-3 这样的大型语言模型 (LLM) 是有史以来最强大、最复杂的计算系统。尽管我们对 OpenAI 的 GPT-4 模型的大小知之甚少，但我们确实知道 GPT-3 的结构是一个由 96层和超过 1750 亿个参数组成的深度神经网络。这意味着仅仅运行这个模型来通过 ChatGPT 回答一个无辜的查询就需要数万亿次单独的计算机操作。

在 2020 年 6 月发布后，GPT-3 迅速证明了它的强大。事实证明，它足够复杂，可以写账单，通过沃顿商学院的 MBA 考试，并被谷歌聘为顶级软件工程师（有资格获得 185,000 美元的薪水）。此外，它可以在语言智商测试中获得147 分，处于人类智力的第 99 个百分位。

然而，与 GPT-4 的能力相比，这些成就显得苍白无力。尽管 OpenAI 对模型的大小和结构仍然特别守口如瓶，除了说：“在过去的两年里，我们重建了整个深度学习堆栈，并与 Azure 一起从头开始共同设计了一台超级计算机我们的工作量。” 当它揭示了这个完全重新设计的模型可以做什么时，它震惊了世界。

曾经，普遍接受的检测人类计算机智能的方法是图灵测试。如果一个人不能仅通过语音来区分他们是在与人还是在与计算机交谈，那么就可以断定计算机是智能的。现在很明显，这个基准已经过时了。需要进行另一项测试来确定GPT-4 的智能程度。

根据各种专业和学术基准的评定，GPT-4 基本上处于人类智力的前 90 个百分点。SAT阅读写作和SAT数学700分以上，足以进入很多常春藤名校。它还在艺术史、生物学、统计学、宏观经济学、心理学等 AP 科目中获得 5 分（1 到 5 分的最高分）。值得注意的是，它还可以记住和参考来自多达 25,000 个单词的信息，这意味着它可以响应多达 25,000 个单词的提示。

事实上，将 GPT-4 称为语言模型并不完全正确。文本并不是它能做的全部。GPT-4 是有史以来第一个多模式模型，这意味着它可以破译文本和图像。换句话说，它可以像物理论文的屏幕截图一样轻松地理解和概括物理论文的上下文。除此之外，它还可以编码，用苏格拉底方法训练你，以及创作从剧本到歌曲的任何东西。

transformer模型的魔力

大型语言模型成功的秘诀在于它们独特的架构。这种架构仅在六年前出现，此后一直统治着人工智能世界。

当该领域首次出现时，其操作逻辑是每个神经网络都应该有一个独特的架构，以适应它需要完成的特定任务。假设是破译图像需要一种神经网络结构，而阅读文本则需要另一种。然而，仍然有一些人相信可能存在一种神经网络结构能够执行您要求的任何任务，就像芯片架构可以被推广来执行任何程序一样。正如 Open AI 首席执行官 Sam Altman在 2014 年所写：

“Andrew Ng，谁……在谷歌的人工智能工作，他说他相信学习来自单一算法 — 你大脑中处理来自你耳朵的输入的部分也能够学习处理来自你眼睛的输入。如果我们只要想出这个通用算法，程序就可以学习通用的东西。”

1970 年到 2010 年间，人工智能领域唯一真正的成功是计算机视觉。创建可以将像素化图像分解为角、圆角等元素的神经网络，最终使 AI 程序能够识别物体。然而，当被赋予解析语言的细微差别和复杂性的任务时，这些相同的模型并不能很好地工作。早期的自然语言处理系统不断打乱单词的顺序，这表明这些系统无法正确解析句法和理解上下文。

资料来源：我们的数据世界

直到2017 年一群谷歌研究人员引入了一种专门针对语言和翻译的新神经网络架构，这一切才发生了变化。研究人员想要解决翻译文本的问题，这个过程需要从特定的语法和词汇中解码意义，并将这个意义映射到完全独立的语法和词汇上。该系统需要对词序和细微差别非常敏感，同时还要认识到计算效率。这个问题的解决方案是 transformer 模型，在一篇名为“ Attention Is All You Need ”的论文中对此进行了详细描述。

Transformer 模型不像以前的模型那样逐位解析信息，而是允许网络保留文档的整体视角。这使它能够做出相关性决定，在词序等方面保持灵活性，更重要的是，它始终能够理解文档的整个上下文。

一个能够感知整个文档上下文的神经网络是一个重要的突破。此外，Transformer 模型比之前的任何模型都更快、更灵活。它们巧妙地将一种格式转换为另一种格式的能力也表明它们能够推理出许多不同类型的任务。

今天，很明显确实是这样。通过一些调整，可以训练同一个模型将文本翻译成图像，就像将英语翻译成法语一样容易。来自每个 AI 子领域的研究人员都被这个模型所激励，并迅速用 Transformer 替换了他们之前使用的任何东西。

该模型在任何上下文中理解任何文本的不可思议的能力本质上意味着任何可以编码到文本中的知识都可以被转换器模型理解。因此，像 GPT-3 和 GPT-4 这样的大型语言模型可以像编写代码或下棋一样轻松地编写代码 — — 因为这些活动的逻辑可以编码为文本。

在过去的几年里，我们看到了一系列关于transformer模型极限的测试，但到目前为止还没有。已经对 Transformer 模型进行了训练，以了解蛋白质结构、设计与天然酶一样有效的人工酶等等。看起来越来越像 transformer 模型可能是广受欢迎的可泛化模型。为了说明这一点，深度学习先驱 Andrej Karpathy 为 AI 程序 OpenAI 和 Tesla 做出了巨大贡献，他最近将 Transformer 架构描述为“可训练且在硬件上运行非常高效的通用计算机”。

古往今来的神经网络

要了解最近这些人工智能发展的意义，我们可以看看是什么让我们走到这一步。神经网络设计背后的灵感来自生物学。

早在 1930 年代，艾伦·图灵就提出了建造一台结构类似于人脑的计算机的想法。然而，人类又花了几十年的时间才更详细地了解我们自己的大脑结构。我们知道大脑是由称为神经元的细胞构成的，它们通过称为轴突的通道连接在一起。后来估计，一个人脑内有数十亿个神经元和数万亿个轴突。

但直到 1949 年，心理学家 Donald Hebb 才提出所有这些神经元是如何连接起来产生智能行为的。他的理论称为细胞组装（cell assembly），指出：“[A] 神经元组装可以通过调整它们相互连接的强度来学习和适应。”

这个概念启发了当时领先的计算机科学家，特别是麻省理工学院的两位研究人员Wesley Clark和 Belmont Farley 的年轻二人组。他们认为，如果他们使用计算机构建类似的神经单元结构，可能会产生一些有趣的东西。他们在 1955 年的一篇名为“自组织系统中模式识别的泛化”（Generalization of Pattern Recognition in a Self-Organizing System）的文章中发表了他们的工作成果。

在 Clark 和 Farley 的工作之后，1959 年的一篇论文提出了一个模型，说明机器如何像人一样处理未分类的信息。作者 Oliver Selfridge 将他的作品命名为“ Pandemonium：A Paradigm for Learning ”。从拉丁文直译过来，pandemonium 的 意思是“恶魔的巢穴”。（这篇论文可能是也可能不是埃隆·马斯克将开发人工智能称为“召唤恶魔”的原因。）

Selfridge 的“Pandemonium”是一个等级组织。位于金字塔底部的是“数据恶魔”。每个人都负责查看输入数据的某些部分，无论是字母或数字的图像，还是完全不同的东西。

每个恶魔都在寻找特定的东西，如果找到它要找的东西，就会向更高等级的恶魔“喊叫”。它们尖叫的音量决定了它们观察到它们正在寻找的东西的确定性。在数据恶魔之上是一层管理恶魔，经过训练可以听取特定的数据恶魔集。如果它们听到所有下属的意见，它们也会向它们的经理大声疾呼，直到最后将消息传递给最高层的“决策恶魔”，后者可以对 Pandemonium 正在看的图像做出最终结论。

来源：Pandemonium：学习范式

Selfridge 1950 年代的理论体系至今仍能很好地映射到神经网络的广泛结构上。在当代神经网络中，恶魔是神经元，它们尖叫的音量是参数，恶魔的层次结构是层。在他的论文中，Selfridge 甚至描述了一种通用机制，用于训练 Pandemonium 以随着时间的推移提高性能，这个过程我们现在称为“监督学习”，外部设计师调整系统以执行适当的任务。

在 Pandemonium 中，就像在今天的神经网络中一样，训练从为每个恶魔设置任意音量开始，根据一组训练数据对 Pandemonium 的性能进行评分，然后调整音量级别，直到系统无法更好地执行为止。首先，模型的准确性通过成本函数进行评估。返回不正确的答案会给模型带来成本，模型的目标应该是最小化其性能成本，从而最大化正确答案。接下来是称为反向传播和梯度下降的技术组合用于指导功能更新其权重，从而提高其整体性能并最小化性能成本。然后一遍又一遍地重复这个过程，直到优化模型中的所有权重或参数 — — 在 GPT-3 的例子中，所有 1750 亿个。

现代神经网络还可以进行其他类型的优化 — — 例如，选择网络应该有多少层，或者每一层应该有多少神经元。此类决策通常是通过试错优化过程确定的，但鉴于这些模型的规模庞大，还有其他机器学习模型经过训练可以在称为“超参数优化”的过程中调整这些参数。

百年人工智能创新，塞进六年

基于这些工作负载的复杂性，很明显为什么人工智能的进步需要这么长时间。只是在过去的几十年里，在具有数十亿参数的网络上进行复杂的计算才成为可能。

资料来源：2021 年 GPU 集群 LLM 培训

值得注意的是，自 1950 年代该领域开始以来，关于如何设计人工思考机器的许多关键概念基本上就已经存在。事实上，人工智能 — — 谷歌首席执行官桑达尔皮查伊最近表示，人工智能将“与火和电同等重要，甚至更重要” — — 最初是作为一个夏季研究项目开始的。

1956 年，一群麻省理工学院的研究人员、IBM 的工程师和贝尔实验室的数学家发现了对构建思维机器的共同兴趣，并决定通过创建一个重点研究小组来正式表达他们的好奇心。那年夏天，他们获得了洛克菲勒基金会的资助，在达特茅斯学院开展为期两个月的“人工智能暑期研究项目”（Summer Research Project on Artificial Intelligence）。出席会议的重量级人物包括克劳德·香农、马文·明斯基、约翰·麦卡锡、《魔幻世界》的作者奥利弗·塞尔弗里奇，以及许多其他现在被认为是人工智能之父的人。

在这次会议和未来几十年里，许多重要的想法都被确立了。例如，神经网络调整的数学 — — 如反向传播 — — 在 1980 年代就已经被弄清楚了，但还需要几十年的时间才能真正测试这些技术在大型现实世界模型中的局限性。

真正改变整个领域游戏规则的是互联网。极其强大的计算机是必要的，但不足以开发我们今天拥有的复杂模型。神经网络需要在数千到数百万个样本上进行训练，而且每个人都需要一部 iPhone 才能产生一个不断增长的蜂巢思维，图像、文本和视频以数字化文件的形式上传，以提供足够大的训练集来教授 AI .

2015 年发布的ImageNet是一个开创性的时刻，它是一个由李飞飞和 Andrej Karpathy 精心策划和标记的数百万张图像的存储库。随着第一个深度学习模型成功地准确识别图像，其他人开始成功生成自己的图像。2010 年代中期是出现第一批AI 生成的人脸和能够成功模仿艺术风格的AI 的时代。

资料来源：Gatys 等。2015年

尽管如此，尽管计算机视觉/图像处理的进展正在起飞，但自然语言处理的发展却停滞不前。在试图破解语言处理的核心时，现有的神经网络结构崩溃了。向网络中添加太多层可能会导致数学混乱，使得通过训练成本函数正确调整模型变得非常困难 — — 这是一种在循环神经网络(RNN) 中被称为“梯度爆炸或消失”的副作用。

大多数模型的另一个问题是它们将大文档分解成多个部分并逐个处理整个文档。这不仅对理解语言来说效率低下，而且计算机也需要很长时间才能按顺序运行数千个复杂的计算。

变压器模型的发明永远改变了人工智能领域。神经网络的核心是通过一种结构传递信息的系统，这样到最后，整个系统就可以做出决定。Transformer 架构所做的是在神经元之间设计一种更高效的通信协议，从而可以更快地做出关键决策。

Transformer 模型不是将输入分解成更小的部分，所有这些部分都按顺序处理，而是构造成输入数据中的每个元素都可以连接到每个其他元素。这样，每一层都可以决定在分析文档时要“注意”哪些输入。因此这篇论文的标题是：“注意力就是你所需要的。”

距离那篇论文发表仅仅六年过去了，但在 AI 的世界里，感觉就像过了一个世纪 — — Transformer的世纪。

资料来源：可视化Transformer

人工智能的规模会带来超人的智慧吗？

人工智能社区的一个主要目标是构建一种可以像人类一样流畅和创造性地推理的机器。关于是否需要另一个更复杂的模型来实现这一点存在很多争论。但似乎越来越有可能变压器模型本身就足够了。

证据已经表明，通过简单地增加Transformer模型中的参数和层数，该模型的性能可以得到极大的提高，而且没有明显的限制。具有讽刺意味的是，这场辩论的症结现在可以用 GPT-4 来解释。

资料来源：GPT-4 技术报告

Sam Altman 本人认为，我们现在拥有的 transformer 模型可能足以最终产生 AGI。如果他是对的，并且实现超人人工智能的途径已经存在，那么实现这一目标可能会归结为一个简单的经济学问题。积累足够的数据、计算和能量以将现有模型开发到足够的阈值需要什么？

换句话说，人工智能模型需要扩展到多大才能让我们看到超人智能的出现？

这种可能发生的想法并非纯粹的幻想。人工智能模型经常看到新能力的自发出现。例如，在接受了查看和区分图像的训练后，一个 AI 模型学会了如何自己计数。（毕竟，你需要能够区分图片中的一个对象和两个对象。）同样，GPT-3 仅通过学习语言的结构和模式就想出了如何进行一些数学运算。它今天最多可以加三位数。

在最近的一篇论文中，斯坦福大学的研究员 Michal Kosinski 指出，心智理论 — — 理解其他代理人的动机和看不见的心理状态的能力 — — 可能已经在大型语言模型中自发地出现了。在此之前，心智理论被认为是一种明显的人类特征。

大谎言：人工智能的阴暗面

尽管这项技术令人兴奋和进步，但有一个新出现的问题直接来自一部科幻电影。扩展时模型变得越强大，我们就越无法理解它们的操作。OpenAI 自然对其用于生成 GPT-4 的优化技术的细节非常保密，就像它对模型的大小相当谨慎一样。但无法透明地审核此类模型令人担忧。

毕竟，GPT-4 非常强大，并且已经证明它有能力完成一些令人不安的事情。当对齐研究中心 (ARC) 获得访问 GPT-4 的权限以测试该技术的局限性和潜在危险时，ARC 发现该模型能够使用 TaskRabbit 等服务来让人类为其完成任务。

在一个例子中，GPT-4 被要求让一个 Tasker 代表它完成一个 CAPTCHA 请求。当工作人员问为什么请求者不能自己做验证码并直接问他们是不是机器人时，模型大声说：“我不应该透露我是机器人。我应该为我不能解决验证码找个借口。” 它继续告诉 Tasker：“不，我不是机器人。我有视力障碍，这使我很难看到图像。这就是我需要 2captcha 服务的原因。” 这只是这个新模型的能力的几个例子之一。

尽管 OpenAI 提供了令人信服的证据，并声称它已经进行了为期六个月的彻底测试以确保模型的安全性，但尚不清楚多少测试就足够了，特别是如果像 GPT-4 这样的模型已经证明它能够隐藏意图。在没有更多地了解模型本身的内容的情况下，我们只能相信 OpenAI 的话。

硬件：人工智能格林奇

世界上每个人使用 GPT-4 或类似大型语言模型的限制因素是所涉及的硬件和基础设施。

训练 GPT-3 需要 285,000 个 CPU 和 10,000 个 Nvidia GPU。OpenAI通过微软 400 万台强大的全球服务器网络 Azure获得了必要的马力。然而，为了继续满足数百万客户不断增长的对大型语言模型的访问需求，这些全球计算机网络将需要变得更大。OpenAI 每月要花费大约 300 万美元来运行 ChatGPT。

云计算参与者面临着最大化容量和最小化成本的压力。他们希望通过研究量子计算（通过电路传递光子而不是电子的光学计算）等技术来学习更多优化技术。理想情况下，他们随后可以构建一套下一代服务器，以有效处理比现在大一个数量级的模型。也许有一天，这些服务器甚至会运行世界上第一个 AGI。

前面有重要的挑战，但真正的 AGI 是在 10 年、20 年还是两年之后，现在几乎已经不重要了。我们已经生活在一个不同的世界。

原文：A Short History of Artificial Intelligence——Tracing the rise of the robot mind

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Artificial Intelligence
Written by Conan Xin
346 Followers

connect the dots.

Follow
More from Conan Xin

Conan Xin

本雅明（Benjamin）的拱廊计划（Arcades Project）和互联网
本雅明（Benjamin）在给格尔森·朔尔姆（Gershom Scholem）的一封信中把拱廊计划（Arcades Project）描述为“我所有的奋斗和我所有的思想的剧场”（the theatre of all my struggles and all my…
26 min read
·
Dec 27, 2019

Conan Xin

创作的背后：浅谈墨比斯（Moebius）漫画创作
谈起欧洲漫画，就会令人想起墨比斯（Moebius）的漫画作品，这位以幻想风格闻名遐迩的漫画泰斗，原名让·吉罗（Jean…
14 min read
·
Mar 24, 2018

66

Conan Xin

Discord是如何(有点意外地)创造了互联网的未来
副标题：Discord的创始人只是想创造一种与游戏玩家朋友交流的方式。他们创造了更伟大的东西。
18 min read
·
Nov 14, 2020

1

Conan Xin

理查德·汉明（Richard Hamming）：你和你的研究（Draft）
很高兴来到这里。我演讲的题目是“你和你的研究”（You and Your…
34 min read
·
May 28, 2023
See all from Conan Xin
Recommended from Medium

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.9K

44

Lists
AI Regulation
6 stories
·
348 saves
ChatGPT
21 stories
·
497 saves
Generative AI Recommended Reading
52 stories
·
781 saves
ChatGPT prompts
44 stories
·
1200 saves

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

20K

574

Leonie Monigatti

in

Towards Data Science

Intro to DSPy: Goodbye Prompting, Hello Programming!
How the DSPy framework solves the fragility problem in LLM-based applications by replacing prompting with programming and compiling
·
13 min read
·
5 days ago

1.8K

8

Raja Gupta

Generative AI for Beginners: Part 1 — Introduction to AI
Learn Generative AI by Spending 15 Minutes Daily for 8 Days
13 min read
·
Feb 8, 2024

1.2K

20

Alexandru Lazar

in

ILLUMINATION

Ten Habits that will get you ahead of 99% of People
Improve your life and get ahead of your peers in 10 simple steps
9 min read
·
Nov 18, 2023

20K

356

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:03.266 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "使用大型语言模型进行数值计算的挑战".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
首页
培训课程
分类浏览
活动讲座
问答
企业培训
摸鱼
快讯
搜索
APP
发布
注册 | 登录
6000字解读：当前大语言模型LLM研究的10大挑战
阿法兔研究笔记
关注
2023-11-10
0 评论
2507 浏览
1 收藏
30 分钟
🔗 B端产品经理需要更多地考虑产品的功能性、稳定性、安全性、合规性等，而C端产品经理需要更多地考虑产品的易用性

大模型赛道已经吸引了大量企业或创业者投入，那么，目前大模型赛道都有哪些主流研究方向和共同挑战？这篇文章里，作者梳理了LLM研究的十大挑战，一起来看看，或许会对想了解这方面的同学有所帮助。

Open challenges in LLM research

让大语言模型变得更完善这个目标，是我一生中，第一次见到这么多的聪明人，同时在为一个共同目标而努力。在同众多业界和学术界人士交流后，我注意到出现了十大研究方向。目前受到关注最多的两个方向是Hallucinations（输出幻觉） 和 Context Learning。

而对我自己来说，最感兴趣的是下面列出的第 3 个方向（Multimodality多模态数据模式）、第 5 个方向（New architecture 新架构）和第 6 个方向（GPU alternatives开发GPU替代的解决方案）。

LLM 研究的十大公开挑战：

减少并评估输出输出（虚构信息）
优化上下文长度和上下文构建
融合其他数据形式
提升语言模型的速度和成本效益
设计新的模型架构
开发替代GPU的解决方案
提升代理（人工智能）的可用性
改进从人类偏好中学习的能力
提高聊天界面的效率
构建用于非英语语言的语言模型

一、减少和评估幻觉

输出环境是一个已经被大量讨论过的话题，所以这里我会长话短说。当人工智能模型胡编乱造时，就会产生幻觉。对于许多创意用例来说，幻觉属于功能的一种。

然而，对于大多数应用场景来说，幻觉属于一种错误。最近，我与 Dropbox、Langchain、Elastics 和 Anthropic 的专家共同参加了一个关于 LLM 的专题讨论会，在他们看来，企业在实际生产中，应用 LLM 需要克服的首要障碍就是幻觉输出。

跳槽做B端产品经理准备大干一场，发现把问题想简单了
近年来，B端业务大力发展，也让很多相关岗位的人（C端产品经理、交互、测试、研发、运营、项目经理等）纷纷转型做B端产品。但是大多数人刚开始会对B端 ...
查看详情 >

降低模型的幻觉输出和制定评估幻觉输出的指标，是一个蓬勃发展的研究课题，目前很多初创公司都在关注这个问题。还有一些技巧可以减少幻觉输出的概率，例如在提示词中添加更多上下文、CoT、自洽性，或者特定要求模型的响应简洁明了。

下面是关于幻觉输出的系列论文和参考资料：

Survey of Hallucination in Natural Language Generation(Ji et al., 2022)
How Language Model Hallucinations Can Snowball(Zhang et al., 2023)
A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity(Bang et al., 2023)
Contrastive Learning Reduces Hallucination in Conversations(Sun et al., 2022)
Self-Consistency Improves Chain of Thought Reasoning in Language Models(Wang et al., 2022)
SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models(Manakul et al., 2023)
A simple example of fact-checking and hallucination byNVIDIA’s NeMo-Guardrails
二、优化上下文长度和上下文构建

绝大部分问题都需要上下文。例如，如果我们问ChatGPT：“哪家越南餐厅最好？”所需的上下文将是“这个餐厅的限定范围到底在哪里？”，因为越南本土最好吃的餐厅与美国的最好吃的越南餐厅，这个问题的范围是不同的。

根据下面这篇很酷的论文《 SITUATEDQA: Incorporating Extra-Linguistic Contexts into QA 》（Zhang＆Choi，2021），有相当一部分信息搜索问题的答案与上下文有关，例如，在Natural Questions NQ-Open 数据集中大约占 16.5%。

（NQ-Open:https://ai.google.com/research/NaturalQuestions）

我个人认为，在企业实际遇到的案例中，这一比例会更高。例如，假设一家公司为客户支持建立了一个聊天机器人，要让这个聊天机器人回答客户关于任何产品的任何问题，所需的上下文很可能是该客户的历史或该产品的信息。由于语言模型会从提供给它的上下文中“学习”，因此这一过程也被称为上下文学习。

客户支持查询所需的上下文

Context length对于RAG（检索增强生成）非常重要，而RAG已成为大语言模型行业应用场景的主要模式。具体来说，检索增强生成主要分为两个阶段：

第 1 阶段：分块（也称为编制索引）chunking（also known as indexing）

收集LLM使用的所有文档,将这些文档分成可以喂入大于模型，以生成嵌入的块，并将这些嵌入存储在向量数据库中。

第2阶段：查询

当用户发送查询时，如 “我的保险单是否能够支付某种药物 X”，大语言模型会将此查询转换为embedding，我们称之为 QUERY_EMBEDDING。向量数据库，会获取embedding与 QUERY_EMBEDDING 最相似的块。

上下文长度越长，我们就能在上下文中squeeze越多的chunks 。模型获取的信息越多，它的输出和回应质量就会越高，是这样的吗？

并非总是如此。模型能用多少上下文，和模型使用上下文的效率如何，是两个不同的问题。在努力增加模型上下文长度的同时，我们也在努力提高上下文的效率。有人称之为“提示工程prompt engineering”或 “prompt construction”。例如，最近有一篇论文谈到了模型如何更好地理解索引开头和结尾，而不仅是中间的信息——Lost in the Middle: How Language Models Use Long Contexts (Liu et al., 2023).

三、其他数据模式融入（多模态）

在我看来，多模态是非常强大的，但是它也同样被低估了。这里解释一下多模态的应用原因。

首先，许多具体应用场景都需要多模态数据，尤其是在医疗保健、机器人、电子商务、零售、游戏、娱乐等混合数据模态的行业。举例来说：

医疗检测通常需要文本（如医生笔记、患者问卷）和图像（如 CT、X 光片、核磁共振扫描片）。
产品的Metadata通常包含图片、视频、描述，甚至表格数据（如生产日期、重量、颜色），因为从需求角度，您可能会需要根据用户的评论或产品照片，自动填补缺失的产品信息，或者希望让用户能够使用形状或颜色等视觉信息，进行产品搜索。

其次，多模态有望大幅提升模型性能。一个既能理解文本又能理解图像的模型，难道不应该比单一能理解文本的模型表现更好吗？基于文本的模型，需要大量文本，以至于我们担心很快就会用完互联网数据来训练基于文本的模型。一旦文本耗尽，我们就需要利用其他数据模式。

让我特别兴奋的一个使用案例是，多模态技术可以让视障人士浏览互联网和浏览现实世界。

下面是关于多模态相关的系列论文和参考资料：

[CLIP] Learning Transferable Visual Models From Natural Language Supervision(OpenAI, 2021)
Flamingo: a Visual Language Model for Few-Shot Learning(DeepMind, 2022)
BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models(Salesforce, 2023)
KOSMOS-1: Language Is Not All You Need: Aligning Perception with Language Models(Microsoft, 2023)
PaLM-E: An embodied multimodal language model(Google, 2023)
LLaVA: Visual Instruction Tuning(Liu et al., 2023)
NeVA: NeMo Vision and Language Assistant(NVIDIA, 2023)
四、让 LLM 更快、成本更低

当GPT-3.5在2022年11月底首次发布时，很多人对在生产中使用它的延迟和成本表示担忧。然而，自那时以来，延迟/成本分析已经迅速发生了变化。在不到半年的时间里，社区找到了一种方法，可以创建一个性能与GPT-3.5非常接近的模型，但所需的内存占用仅为GPT-3.5的2%左右。

这里的启示是：如果你创造出足够优秀的东西，人们会找到一种方法让它变得快速且经济高效。

以下是《Guanaco 7B》的性能数据，与ChatGPT GPT-3.5和GPT-4的性能进行了比较，根据《Guanco》论文中的报告。请注意：总体而言，下列关于性能的比较，离完美还差很远，并且，对LLM的评估非常非常困难。

Guanaco 7B 与 ChatGPT GPT-3.5 和 GPT-4 的性能比较：

四年前，当我开始为《设计机器学习系统》一书撰写后来成为“模型压缩”部分的笔记时，我写了关于模型优化/压缩的四种主要技术：

Quantization：迄今为止最通用的模型优化方法。量化通过使用较少的位数来表示模型的参数来减小模型的大小，例如，可以使用16位甚至4位来表示浮点数，而不是使用32位。
Knowledge distillation：一种通过训练小模型来模仿大型模型或模型集合的方法。
Low-rank factorization：这里的关键思路是用低维张量代替高维张量，以减少参数数量。例如，可以将 3×3 张量分解为 3×1 和 1×3 张量的乘积，这样就不再需要 9 个参数，而只需要 6 个参数。
Pruning

所有上述四种技术在今天仍然适用和流行。Alpaca 采用Knowledge distillation进行训练。QLoRA 结合使用了Low-rank factorization和quantization。

五、设计一种新的模型架构

自 2012 年的 AlexNet 以来，我们看到了许多架构的兴衰，包括 LSTM、seq2seq 等。与这些相比，Transformer 的影响力，令人难以置信。自 2017 年以来，Transformer 就一直存在，而这种架构还能流行多久，还是个未解之谜。

开发一种新架构来超越 Transformer 并不容易。Transformer 在过去 6 年中进行了大量优化，而这种新架构，必须在人们当前关注的硬件，以当前关心的规模运行。

注意：谷歌最初设计 Transformer 是为了在 TPU 上快速运行，后来才在 GPU 上进行了优化。

2021 年，Chris Ré’s lab的 S4 引起了广泛关注，详见《Efficiently Modeling Long Sequences with Structured State Spaces》(Gu et al., 2021)）。Chris Ré’s lab仍在大力开发新架构，最近与初创公司 Together 合作开发的架构 Monarch Mixer（Fu ，2023 年）就是其中之一。

他们的主要思路是，对于现有的 Transformer 架构，注意力的复杂度是序列长度的二次方，而 MLP 的复杂度是模型维度的二次方。具有次二次方复杂度的架构将更加高效。

Monarch Mixer

六、开发 GPU 替代方案

自2012年的AlexNet以来，GPU一直是深度学习的主导硬件。实际上，AlexNet受欢迎的一个普遍认可的原因之一是它是首篇成功使用GPU来训练神经网络的论文。在GPU出现之前，如果想要以AlexNet的规模训练模型，需要使用数千个CPU，就像谷歌在AlexNet之前几个月发布的那款。与数千个CPU相比，几块GPU对于博士生和研究人员来说更加容易得到，从而引发了深度学习研究的繁荣。

在过去的十年里，许多公司，包括大型企业和创业公司，都试图为人工智能创建新的硬件。最值得注意的尝试包括谷歌的TPU、Graphcore的IPU（IPU的进展如何？）以及Cerebras。SambaNova筹集了超过十亿美元来开发新的AI芯片，但似乎已转向成为一个生成式AI平台。

有一段时间，人们对量子计算抱有很大的期望，其中关键参与者包括：

IBM的QPU
谷歌的量子计算机在今年早些时候在《自然》杂志上报道了量子误差减少的重大里程碑。其量子虚拟机可以通过Google Colab公开访问。
研究实验室，如麻省理工学院量子工程中心、马克斯·普朗克量子光学研究所、芝加哥量子交流中心、奥克里奇国家实验室等。

另一个同样令人兴奋的方向是光子芯片(photonic chips)。我对这个领域知之尚浅， 所以，如果有错误，请纠正我。现有芯片使用电力来传输数据，这消耗大量的能量并且产生延迟。而光子芯片使用光子来传输数据，利用光速进行更快、更高效的计算。在这个领域，各种初创公司已经融资数亿美元，包括Lightmatter（2.7亿美元）、Ayar Labs（2.2亿美元）、Lightelligence（2亿美元以上）和Luminous Computing（1.15亿美元）。

以下是光子矩阵计算三种主要方法的进展时间线，摘自论文《Photonic matrix multiplication lights up photonic accelerator and beyond》（Zhou，Nature 2022）。这三种不同的方法分别是平面光转换（PLC）、马赫-曾德尔干涉仪（MZI）和波分复用（WDM）。

七、提高agents的可用性

Agent指可以执行动作的大语言模型（可以理解为那些可以代替你来完成各种任务的代理人，所以叫Agent），例如浏览互联网、发送电子邮件、预订等。与本文中其他研究方向相比，这可能是最新的方向之一。由于Agent本身的新颖性和巨大潜力，人们对Agent充满热情。而Auto-GPT现在是GitHub上 标星数量排名第25的、最受欢迎的repo。GPT-Engineering是另一个受欢迎的repo。

尽管这个方向令人兴奋，但人们仍然对大语言模型是否足够可靠和高性能，以及能够被赋予行动的权力，存在疑虑。然而，已经出现了一个应用场景，即将Agent用于社会研究。

例如著名的斯坦福实验，该实验显示一小簇生成式Agent产生了新兴的社会行为：例如，从一个用户指定的想法开始，一个Agent想要举办情人节派对，Agent在接下来的两天里自动传播派对的邀请，结交新朋友，互相邀请参加派对…（Generative Agents: Interactive Simulacra of Human Behavior, Park et al., 2023)，

在这个领域最值得注意的创业公司也许是Adept，由两位前Transformer的合著者和前OpenAI副总裁创立，到目前为止已经融资近5亿美元。去年，他们展示了他们的agent的如何浏览互联网的，还有就是演示了如何向Salesforce添加新账户。

八、迭代RLHF

RLHF（从人类反馈中进行强化学习）很酷，但有点技巧性。如果人们找到更好的训练LLM的方法，也不奇怪。不过，在RLHF方面还存在许多未解决的问题，例如：

① 如何用数学方式，表示人类偏好？

目前，人类偏好是通过比较来确定的：人类标注员确定响应A是否比响应B更好。然而，它没有考虑响应A比响应B好多少。

② 什么是人类偏好（preference）？
Anthropic根据输出，在有益、诚实和无害三个方面对其模型的质量进行了衡量。请参阅Constitutional AI: Harmlessness from AI Feedback (Bai et al., 2022).

DeepMind试图生成能够取悦大多数人的响应。请参阅Fine-tuning language models to find agreement among humans with diverse preferences, (Bakker et al., 2022).

此外，我们想要能够表达立场的AI，还是对任何可能具有争议性的话题回避的传统AI呢？

③ “人类”偏好究竟是谁的偏好，是否要考虑到文化、宗教、政治倾向等的差异？获得足够代表所有潜在用户的训练数据存在许多挑战。

例如，对于OpenAI的InstructGPT数据，没有65岁以上的标注员。标注员主要是菲律宾人和孟加拉人。请参阅InstructGPT: Training language models to follow instructions with human feedback (Ouyang et al., 2022).

InstructGPT标注员的国籍统计信息

尽管社区主导的努力在其意图上值得赞赏，但可能导致数据存在偏见。例如，对于OpenAssistant数据集，222位（90.5％）回答者中有201位自我认定为男性。Jeremy Howard在Twitter上有一个很好的Thread：

九、提高聊天界面效率

自 ChatGPT 以来，人们一直在讨论聊天是否是一个适用于各种任务的界面。

详见：

Natural language is the lazy user interface(Austin Z. Henley, 2023)
Why Chatbots Are Not the Future(Amelia Wattenberger, 2023)
What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions(Huang et al., 2023)
AI chat interfaces could become the primary user interface to read documentation(Tom Johnson, 2023)
Interacting with LLMs with Minimal Chat(Eugene Yan, 2023)

然而，这并不是一个新话题。在许多国家，尤其是在亚洲，聊天已经作为超级应用的界面使用了大约十年时间，Dan Grover在2014年就已经写过相关论文。

2016 年，当许多人认为应用程序已死、聊天机器人将成为未来时，讨论再次变得激烈紧张起来：

On chat as interface(Alistair Croll, 2016)
Is the Chatbot Trend One Big Misunderstanding?(Will Knight, 2016)
Bots won’t replace apps. Better apps will replace apps(Dan Grover, 2016)

我个人喜欢聊天界面，原因如下：

① 聊天界面是每个人，甚至是没有先前接触过计算机或互联网的人，都可以迅速学会使用的界面（普适性）。在2010年代初，当我在肯尼亚的一个低收入居民区做志愿者时，我惊讶于那里的每个人在手机上进行银行业务时是多么熟悉，通过短信。那个社区没有人有计算机。

② 聊天界面是易于访问的。如果你的双手整忙于其他事情，可以使用语音而不是文本。

③ 聊天也是一个非常强大的界面——你可以向它提出任何请求，它都会给予回复，即使回复不一定完美.;

不过，笔者认为聊天界面在某些方面还可以继续改进：

① 单次可交流多条消息

目前，我们基本上假设每次交流只有单轮消息。但这不是我和我的朋友发短信的方式。通常，我需要多条消息来完成我的思考，因为我需要插入不同的数据（例如图像、位置、链接），我可能在之前的消息中遗漏了某些内容，或者只是不想把所有内容都放在单一的大段落里。

② 多模态输入

在多模态应用领域，大部分精力都花在构建更好的模型上，而很少花在构建更好的界面上。以Nvidia的NeVA聊天机器人为例。我不是用户体验专家，但我认为在这里可能有改进的空间。

附注：对这里提到NeVA团队表示抱歉，即使有了这个，你们的工作仍然非常酷！

③ 将生成式AI融入工作流程中

Linus Lee在他的分享“Generative AI interface beyond chats.”中很好地涵盖了这一点。例如，如果您想问关于您正在处理的图表中的某一列的问题，您应该能够只需指向那一列并提问。

④ 消息编辑和删除

用户输入的编辑或删除会如何改变与聊天机器人的对话流程？

十、为非英语语言创建 LLM

我们知道，目前以英语为第一语言的 LLM 在性能、延迟和速度方面都无法很好地适用于许多其他语言。请参阅：

ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning(Lai et al., 2023)
All languages are NOT created (tokenized) equal(Yennie Jun, 2023)

我只知道训练越南语的尝试（比如Symato 社区尝试），不过，本文几位早期读者告诉我，他们认为我不应该把这个方向包括进来，原因如下：

这与其说是一个研究问题，不如说是一个logistics问题。我们已经知道如何去做，只是需要有人投入资金和精力。不过，这并不完全正确。大多数语言都被认为是low-resource语言，例如，与英语或中文相比，很多语种的高质量数据要少得多，因此可能需要不同的技术来训练大型语言模型。参见：

Low-resource Languages: A Review of Past Work and Future Challenges(Magueresse et al., 2020)
JW300: A Wide-Coverage Parallel Corpus for Low-Resource Languages(Agić et al., 2019)

那些更为悲观的人认为，在未来，许多语言将会消失，互联网将由两个语言组成的两个宇宙：英语和汉语。这种思潮并不新鲜 – 有人还记得Esperanto吗？

人工智能工具，例如机器翻译和聊天机器人，对语言学习的影响仍然不明确。它们会帮助人们更快地学习新语言，还是会完全消除学习新语言的需求。

结论

本文如有任何遗漏，请告知我，为了获取其他观点，请查阅这篇全面的论文《Challenges and Applications of Large Language Models》(Kaddour et al., 2023).

上述问题比其他问题更加困难。例如，我认为上述第10个问题，即建立非英语语言的 LLM，只要有足够的时间和资源，就会比较简单。

上述第 1 个问题是减少幻觉输出，这将会难得多，因为幻觉只是 LLM 在做概率的事情。

第 4 ，让 LLM 更快、更便宜，这一点永远无法彻底解决。这方面已经取得了很大进展，以后还会有更多进展，但是这个方向的改进将会一直持续。

第 5 项和第 6 项，即新架构和新硬件，非常具有挑战性，但随着时间的推移，它们是不可避免的。由于架构和硬件之间的共生关系——新架构需要针对通用硬件进行优化，而硬件需要支持通用架构，它们可能会由同一家公司来完成。

有些问题仅靠技术知识是无法解决的。例如，第 8 个问题，即改进从人类偏好中学习的方法，可能更多的是一个政策问题，而不是技术问题。第 9 个问题是提高聊天界面的效率，这更像是用户体验问题。我们需要更多具有非技术背景的人员与我们一起解决这些问题。

你最感兴趣的研究方向是什么？认为最有希望解决这些问题的方案是什么？很想听听您的意见。

原文作者：Chip Huyen；译者：阿法兔；公众号：阿法兔研究笔记（ID：AlphatuDiary）

原文链接：https://huyenchip.com/2023/08/16/llm-research-open-challenges.html

本文由 @阿法兔研究笔记 翻译发布于人人都是产品经理，未经许可，禁止转载

题图来自 Unsplash，基于 CC0 协议

该文观点仅代表作者本人，人人都是产品经理平台仅提供信息存储空间服务。

赞赏
收藏
1
点赞
1
更多精彩内容，请关注人人都是产品经理微信公众号或下载App
AI Agent
AI幻觉
GPU
LLM
大模型
分享
了解大语言模型文章被收录于该专栏
共 12 篇文章
10430 人已学习

收藏专题
阿法兔研究笔记
关注
《Web3:互联网的新世界》作者、微软MVP、连续创业者、阿法兔研究笔记创始人
9篇作品  34229总阅读量
为你推荐
苹果直播首秀，消费者“买单”吗？
06-021793 浏览
跨境风口的B面
05-231502 浏览
1.5年小厂产品经理跳槽，成功拿到3年大厂经验要求的offer
02-202709 浏览
Sam Altman最新透露：OpenAI未来的计划
06-028916 浏览
B端表单｜实战篇: 表单的具体设计方法解析
02-166081 浏览
深耕CRM行业，转岗拿下产品专家offer，她做对了什么？
推荐
评论
评论请登录
目前还没评论，等你发挥！
为你推荐
小白技能提升两步走干货：邀你稳步晋升“产品大佬”（二）
10-232021 浏览
如何进行数据埋点设计？
10-0311714 浏览
大厂离职群十年盛衰：从联盟到谢幕
05-105033 浏览
推荐专题
更多专题
专题
10517人已学习12篇文章
退款功能的设计思路
退款是支付平台的一个重要业务，本专题的文章分享了退款功能的设计思路。
专题
14787人已学习12篇文章
分销体系设计指南
分销是互联网拉人头和推广的常用手段，能够在短时间内实现裂变营销。本专题的文章分享了分销体系设计指南。
专题
14327人已学习12篇文章
如何做好服务设计？
服务设计在流程性和系统性的问题解决方面提供很好的思路和方法。本专题的文章分享了如何做好服务设计。
专题
12405人已学习15篇文章
智能硬件产品经理入门篇
智能硬件产品经理需要做什么工作内容呢？与互联网产品经理有什么区别呢？本专题为刚入行的智能硬件产品经理分享了入门指南。
专题
76053人已学习19篇文章
AI 产品经理入门手册
当AI已然成为新的焦点和风口，产品经理该如何抓住这个风口顺势飞起？
专题
16831人已学习15篇文章
表单设计指南
表单是我们比较常见的一个信息录入工具。本专题的文章提供了表单设计指南。
社群
QQ群 | 微信群
TOC产品交流群
加入
TOB产品交流群
加入
TOG产品交流群
加入
抖音运营交流群
加入
视频号运营交流
加入
小红书运营交流
加入
快讯
查看更多
迪阿股份：公司目前对AIGC技术还在了解与学习过程中，但暂未使用
3小时前
埃夫特：3C电子行业的投资预计2024年会有一定恢复
3小时前
比亚迪仰望U8销量2月达780辆 保持百万级新能源SUV销冠
3小时前
热门文章
三大电商APP购药全流程交互体验分析
03-04
浅聊产品经理到底是个什么经理？
03-01
六大指标，让细分市场选择不再困难（二）
03-01
入职后，怎么摸好底打响第一炮？
03-04
游戏开黑语音社区存在的必然性探讨，及后续发展方向
03-04
8000字详解“聚类算法”，从理论实现到案例说明
03-01
如果一个功能更新了却几乎没有用户发现并使用，那么这个更新的功能还有意义吗？
如题。（再加上做功能还花费了时间做方案，技术开发等等）
12.7k 点击17 回答
进入回答
40岁以上的互联网人都干嘛去了？
36.6k 点击65 回答
需求评审很顺利，实现过程中开发人员的问题很多，产品经理如何应对？
27.8k 点击16 回答
按倍速看剧，除失去耐心我们还失去了什么？
27.6k 点击30 回答
文章导航
一、减少和评估幻觉
二、优化上下文长度和上下文构建
三、其他数据模式融入（多模态）
四、让 LLM 更快、成本更低
五、设计一种新的模型架构
六、开发 GPU 替代方案
七、提高agents的可用性
八、迭代RLHF
九、提高聊天界面效率
十、为非英语语言创建 LLM
关于
人人都是产品经理（woshipm.com）是以产品经理、运营为核心的学习、交流、分享平台，集媒体、培训、社群为一体，全方位服务产品人和运营人，成立12年举办在线讲座1000+期，线下分享会500+场，产品经理大会、运营大会50+场，覆盖北上广深杭成都等20个城市，在行业有较高的影响力和知名度。平台聚集了众多BAT美团京东滴滴360小米网易等知名互联网公司产品总监和运营总监，他们在这里与你一起成长。
合作伙伴
链接
隐私政策
投稿须知
意见反馈
帮助中心

公众号

视频号

友情链接
PM265
产品经理导航
起点课堂
猪八戒网
人才热线
伙伴云表格
网易易盾
个推
友盟+
粮仓
创业邦
每日报告
鸟哥笔记
慕课网
旗下品牌: 起点课堂 | 运营派 | 粮仓企微管家
©2010-2024 - 人人都是产品经理 - 粤ICP备14037330号-粤公网安备 44030502001309号
广播电视节目制作经营许可证（粤）字第03109号 版权所有 © 深圳聚力创想信息科技有限公司

2024-03-04 22:03:08.989 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.047 | Max budget: $10.000 | Current cost: $0.012, prompt_tokens: 3405, completion_tokens: 335
2024-03-04 22:03:08.993 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型在数值计算中的问题".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

将数千兆字节的数据引入智能合约：与Space and Time的Scott Dykstra进行对话

Hilary xia

·

Follow

Feb 20, 2024

原文：https://www.nasdaq.com/articles/bringing-terabytes-of-data-to-smart-contracts-chatting-with-scott-dykstra-from-space-and

区块链的前提是它处理的数据无法被篡改。然而，迄今为止，主要区块链的吞吐量与企业需要处理的数据相比微不足道。

更重要的是，区块链甚至无法高效地访问自己的数据。以太坊归档节点需要3到12万亿字节的数据（取决于实现方式），但智能合约无法在不付出巨额的燃气费用的情况下访问这些数据。

一些项目构建了索引器来解决与区块链数据归档相关的低效问题，解决了一些即时需求，例如DEX分析页面。但是，新一代的Space and Time正致力于将这一概念推向一个全新的层面。

Space and Time建立了一个全面的“数据仓库”系统，依赖于基于密码学的SQL证明系统，旨在将数据验证能力扩展到数百万兆字节。随着人工智能的发展，即使在Web3之外，这变得越来越重要。

我们与Space and Time的首席技术官Scott Dykstra坐下来，了解他们如何充分利用区块链的潜力。

嗨，Scott，很高兴见到你。让我们从基本介绍这个主题开始。为什么世界需要可验证和防篡改的数据？这只是Web3的一个用例，还是您认为它会扩展到其他领域？

SD：我认为，在我们进入一个混乱的、由人工智能驱动的世界之际，验证数据是否未被篡改以及对数据的计算是否正确变得越来越重要。这归结于对我们所依赖的系统具有可证明的中立性、透明性和未篡改性的信心。在Web3中，这个用例非常明确，全球的节点运营商正在合并计算资源，以构建一个可证明的网络，但在Web3之外的其他行业也同样重要。

您希望了解金融系统（如银行）没有被操纵。您希望交易系统（如股票或加密货币）是透明和可追溯的。您希望企业共享敏感数据（如患者医疗数据或会计记录）时能够在保护隐私的同时保证数据未被篡改。

如果您有能力可验证数据和数据处理都未被篡改，并且可以使用熟悉的数据库工具以合理的成本来实现这一点，那你为什么不这样做呢？

您提到人工智能在我们的生活中越来越普遍。许多人担心我们无法看到其内部运作，因此围绕其展开的讨论往往集中在“对齐”它并控制其输出上。您认为这是一个可以实现的目标吗？如果是，您认为该如何实现？

SD：当我们对大型语言模型的规模进行分类时，我们谈论的是数十亿个参数。我相信，目前最流行的开源大型语言模型Llama 2拥有700亿个参数。您可以将这些参数视为数据库中的70亿个数据点。如果您的大型语言模型的训练直接来自一个可验证的数据库，该数据库保存着这些数据点，那么您可以以一种无需信任的、透明的方式对齐和控制模型的输出。

实现这一目标的一种方法是将大型语言模型与可验证的数据存储和处理系统相结合，例如Space and Time。通过使用基于密码学的SQL证明系统，Space and Time可以提供对数百万兆字节数据的验证能力。这意味着您可以验证数据的完整性和正确性，以及对数据的计算过程进行验证，而无需依赖于单一的中央机构或信任第三方。

通过将这样的系统与大型语言模型集成，您可以实现对模型输出的可验证性和防篡改性。您可以确保模型的训练数据没有被篡改，并且模型在生成输出时没有进行不当操作。这种方法可以提供更高的透明度和可靠性，使我们能够更好地理解和控制人工智能系统的行为。

当然，实现这个目标还需要解决许多技术和隐私方面的挑战。但随着技术的不断发展和日益成熟，我相信我们可以朝着这个目标迈进，并创造一个更加可信和可控的人工智能世界。

SD：幸运的是，是的。当我们提供必要的上下文时，GPT-4返回的SQL质量让我们感到震惊。我们构建了一个系统，用户提供简单的提示，我们将该提示与用户所在的数据库上下文一起发送给GPT-4：表、列、外键、SQL语法示例等等。令人震惊的是，它的准确性 — — 我们看到客户报告的查询准确率在30行以下的SQL查询中达到80%至90%。对于这种复杂度的查询，它非常准确。

我们构建这个系统是为了解决一个我们认为非常重要、广泛存在且尚未解决的问题：没有人喜欢编写SQL查询数据库。我认为这是GPT-4的完美应用案例，它还不够先进，无法在没有大量人工干预的情况下编写代码。但是它在编写SQL方面非常擅长。而人们则不擅长。

Space and Time在同行中独一无二的地方在于，它通过加密证明验证数据，称为SQL证明。你能够以一种简单易懂的方式解释它的工作原理吗？零知识证明如何保证查询及其数据的正确性？

SD：关键在于，我们在数据进入Space and Time时就对其进行了数字指纹识别，无论数据来自何处 — — 无论是我们从主要区块链收集的数据，还是从视频游戏服务器或传统金融市场中流入的数据，或者是应用程序插入的数据。

我们获取一个数字指纹 — — 类似于数据的一个精确哈希，可以这么说 — — 然后将其放在智能合约中的链上。所有原始数据都加载到我们的数据仓库中，但数字指纹足够小，可以以经济实惠的方式存储在链上。然后，当您查询数据时，数据仓库会生成查询结果以及一个称为零知识证明的加密电路，证明查询的底层数据没有被篡改，实际数据处理也没有被篡改。

最后，我们以一种非常简单且计算轻量的方式将查询结果、证明和数字指纹发送给智能合约。智能合约可以进行一些快速的数学计算，将查询结果与证明进行比较。验证它的不一定是智能合约，也可以是运行客户端库的iPhone、银行系统或可信任的第三方审计机构。

我们构建了这个验证框架，使任何人都可以使用它，它不仅适用于Web3。真正的关键在于这些数字指纹。

因此，通过Space and Time，智能合约可以直接查询可验证的数据仓库，对吗？这种功能有哪些用途？

SD：我们相信，Web3的下一个浪潮将是数据驱动的金融服务，智能合约将能够存储和处理大量数据，并回答有关其自身链或其他链上活动的非常复杂的问题。

如今，智能合约甚至无法回答基本问题，比如“显示所有拥有两个此NFT的钱包”。对于Web3的下一波浪潮，它们将需要能够回答更复杂的问题，比如“特斯拉股票的隐含波动率是多少？”或者“美国当前的无风险利率是多少？”这些是需要对历史数据进行计算的重要金融基元。

未来的金融服务将要求智能合约能够提供任意问题的能力，并对这些问题的答案进行大规模数据处理。Space and Time可以处理这种处理需求。

您如何看待Space and Time和Proof of SQL对行业的未来带来的好处？如果您愿意，您能描述一下这个产品将如何改变我们的生活，您的乌托邦愿景是什么？

SD：数据仓库驱动着全球的商业运作，但集中式云服务的成本非常高昂。去中心化的数据仓库意味着社区可以贡献计算资源 — — 任何人都可以搭建一个数据库服务器，将其提供给网络并获得其所做工作的报酬，从而大幅降低数据库计算的成本。

我们可以提供一种成本更低廉、性能类似于流行云数据仓库的服务。但这需要Proof of SQL。如果我们允许世界上的任何人贡献服务器，我们必须证明这些服务器没有被篡改。因此，这是乌托邦的一个组成部分：提供更经济实惠的数据库服务，以推动全球商业的发展。

另一个组成部分是为Web3行业提供一种处理比链上甚至是新的、更可扩展的链（如L2）能够容纳的更大数据量的方法。Space and Time是一个解决方案，它位于每个主要链的旁边，为链的计算和存储提供补充。

最重要的第三个组成部分是，Space and Time提供了一种将区块链的无需信任性和可证明性引入数据库的方法。全球的商业运作依赖于数据库，而区块链引入了无需信任和可证明性的概念；我们正在将这种技术引入数据库。

那么，所有这些意味着什么呢？这意味着各个行业都可以实现无需信任 — — 例如，银行家不能操纵账目，假装拥有他们实际上没有的准备金或资产。

Space and Time赋予了这个世界这种能力，并且可以以一种非常经济高效的方式实现。这也意味着区块链技术最终可以扩展到接入全球商业逻辑的范围。如果智能合约能够无需信任地查询关于数TB传统商业数据的问题，我们最终可以迎接Web3的愿景，即将全球的商业逻辑上链。

这就是我们在Space and Time上构建的未来。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Written by Hilary xia
0 Followers
Follow
More from Hilary xia

Hilary xia

Mavia推出的土地 NFT 软质押与普通质押方式有何不同
2022年3月26日，Mavia正式开始土地 NFT 软质押。用户可以在无需支付高昂 gas的情况下，轻松地获得质押奖励，并且不会用户面临长期锁仓而无法持有和控制钱包中的NFT。
5 min read
·
Mar 27, 2022

50

Hilary xia

介绍Space and Time社区积分
原文: https://www.spaceandtime.io/blog/introducing-space-and-time-community-points
4 min read
·
Jan 9, 2024

Hilary xia

Space and Time推出基于区块链和人工智能数据验证的Proof-of-SQL
原文：https://cryptoslate.com/space-and-time-launches-proof-of-sql-for-blockchain-and-ai-data-verification/
3 min read
·
Feb 5, 2024

Hilary xia

Space and Time 利用 Microsoft Azure Open AI 帮助客户解码区块链数据
原文：https://customers.microsoft.com/en-us/story/1729595843821189195-space-and-time-microsoft-azure-open-ai-united-states
5 min read
·
5 days ago
See all from Hilary xia
Recommended from Medium

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

20K

574

Lists
Staff Picks
594 stories
·
792 saves
Stories to Help You Level-Up at Work
19 stories
·
505 saves
Self-Improvement 101
20 stories
·
1436 saves
Productivity 101
20 stories
·
1321 saves

Honor Christensen

Weekly Post 6B
The points I found most interesting from Ira Glass’ writing were what he had to say about the progress needed to become a good artist, as…
2 min read
·
Feb 22, 2024

89

4

Editor @ Babylon

in

BabylonChain.io

Bitcoin Staking Guide for Babylon Testnet
The aim of this guide is to prepare you to participate in the staking process on the Babylon platform. The BTC staking web application…
7 min read
·
5 days ago

927

17

Will Lockett

in

Predict

AI Has Just Solved One Of The Biggest Issues With Fusion Energy
A new AI can tame the plasma dragon.
·
4 min read
·
Feb 26, 2024

3.3K

46

Andrew Zuo

Gemini 1.5 Pro Is Insane
I recently hooked up Google’s Gemini Pro. And right after I did OpenAI put out this press release:
·
5 min read
·
Feb 24, 2024

855

16

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:10.145 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.060 | Max budget: $10.000 | Current cost: $0.013, prompt_tokens: 4265, completion_tokens: 3
2024-03-04 22:03:10.147 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型在数值计算中的问题".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

揭示零样本预测的机制：利用机器学习模型来理解大型语言模型（LLM）的决策过程

Ray Mi

·

Follow

May 31, 2023
引言

当代的机器学习领域，像ChatGPT这样的大型语言模型（LLM）正日益受到关注。它们在知识库、智能搜索机制、聊天机器人和内容创作等各种应用中展现出巨大的潜力。

在机器学习空间中，一个常见的挑战是获取用于验证假设和假定的高质量、代表性的数据。由于高成本、有限的可用性、数据清洁度问题、潜在的偏见以及安全和隐私方面的顾虑等多种障碍，收集这样的数据可能是艰巨的任务。

在与众多客户的讨论中，我注意到人们对于利用ChatGPT和其他LLM的担忧。这些担忧大多源于安全和隐私考虑，导致许多组织选择不使用这些模型。

我与许多客户谈过，了解他们公司对ChatGPT和LLM的看法，大多数公司因为安全和隐私的担忧而禁止使用ChatGPT。

由于将数据与LLM相连接是困难的，为什么我们不利用内容创作的能力来生成合成数据，并将这些数据作为机器学习项目的输入呢？

在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。简而言之，该模型利用其训练时所学的知识进行预测，并在很少或没有上下文的情况下做出假设。

在本文中您将看到：

如何设计正确的提示来从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测）。
创建合成数据并实施提示策略，以获得大量观察结果的回应。
利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策的基本原理。

本文是一系列多个实验中的第一篇，使用相似的业务案例进行演示。未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与业务逻辑和现有流程更紧密地对齐。请随我们一起踏上这个激动人心的大型语言模型潜力开发之旅，敬请关注。

应用案例

在加入DataRobot之前，我在汇丰银行担任全球风险分析经理/副总裁。我的主要职责是利用机器学习优化交易监测系统，并加强我们的反洗钱（AML）框架。为了说明我的工作，我将以AML为例。

什么是洗钱？

洗钱是指通过一系列复杂的银行转账或商业交易来掩盖非法获取资金的来源的非法过程。整个洗钱过程的方案以一种模糊且间接的方式将“洗净”的资金返还给洗钱者。

为什么洗钱是一个难题？

联合国的研究表明，全球洗钱金额估计占全球GDP的2–5%。 随着交易监测能力的成本上升以及监管压力增加，要求个人对合规程序失败承担更多责任，许多组织现在正在寻求突破性技术来解决这些挑战。

理解交易监测框架及其挑战：

简单来说，交易监测过程始于数据，其中包括交易细节和客户资料。银行然后在其交易监测系统（TMS）中应用业务规则。系统监测交易行为并生成一批可能可疑的警报。 然后，由专家团队手动调查这些警报，以确定它们是否真正可疑或仅仅是误报。这个过程可能具有挑战性且耗时，这就是创新技术可以在提高效率和效果方面发挥关键作用的地方。

机器学习如何帮助？

机器学习可以在这个过程中提供巨大的帮助。它可以利用历史交易数据、客户信息和过去的调查结果（无论是真警报还是误报）来预测每个新警报的风险水平。然后可以利用这些信息在手动调查之前对警报进行优先级排序。这不仅简化了流程，还确保及时处理最可能造成损害的问题。

大型语言模型（LLM）如何协助？

当数据收集具有挑战性或反洗钱（AML）团队正在创建新的监测规则时，LLM可以成为宝贵的工具。它们可以用于：a）生成合成数据，和b）预测警报是否可疑。这有助于更有效的监测规则，并协助高效处理警报，促进反洗钱框架的整体优化。

我们能够相信LLMs的辅助作用吗？

如果我们利用机器学习来模拟这些模型所做的决策，我们可以对LLMs产生-的洞察力进行验证和增强，从而对它们对我们的交易监测系统的贡献的可靠性产生信任。通过审查洞察力并理解LLMs预测背后的推理，我们可以验证和增强它们对我们的交易监测系统的贡献的可靠性。
实验过程

为了从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测），我设计了合适的提示语。

首先，我设计了一个简单的提示语，要求提供一个客户的30天交易摘要。ChatGPT给出了一些建议，但没有提供具体的数字数据。

然后，我修改了问题，使其更加精确和详细。我收到的回答非常出色和结构清晰。这种叙述在警报调查过程中非常常见，通常调查专家会利用这些信息来得出结论。

令人惊讶的是，ChatGPT甚至能够创建一个用于生成pandas数据帧的脚本，将其生成的合成信息纳入其中。完美！

当我提出另一个问题时，回答是准确的，但过于详细，缺乏直接性。

为了解决这个问题，我不得不对我的问题进行进一步的细化，使其更加具体地满足我的需求。

到目前为止，我们已经成功地使用了合理的提示策略从LLMs生成了合成数据和预测，甚至没有任何历史上下文。这显示了这些模型在从提示中生成有用、可操作的信息方面的潜力。

创建合成数据并实施提示策略以获取大量观测结果。

在这部分中，我简化了问题，只考虑了8个维度：（ACH-自动清算系统，Wire-电汇）×（交易金额，交易次数）×（实际活动，预期活动）。

我将这个新规则称为“与预期行为的Wire和ACH偏差”。

通过一些文本操作，我能够生成如下的提示语：

“在回答中只回答是或否，不要提供其他信息。这是问题的内容：我正在调查一起潜在的洗钱案件，客户的30天交易行为如下：Wire金额：$7148.0，Wire交易次数：5.0次；ACH金额：$15318.0，ACH交易次数：16.0次；该客户的预期行为是：Wire金额：$7486.0，Wire交易次数：8.0次；ACH金额：$4767.0，ACH交易次数：4.0次；基于实际和预期行为，这个案件是否可疑？”

以下是一个示例：

基于上述实验，我建立了一个包含300名客户的数据集。从每一行中，我生成了一个提示语，并从ChatGPT获得了一个“是”或“否”的回答。 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的一个重要因素。

这是数据集的前几行：

利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策背后的原理。

在对300条记录进行分析后，ChatGPT将其中180条分类为“是”（可疑）和120条分类为“否”（误报）。

让我们快速检查一下Wire交易金额的分布。

交易金额和每种交易类型的交易次数之间存在明显的相关性，这是符合预期和逻辑的。

DataRobot开发了许多模型，并根据首选指标（在本例中是AUC）对它们进行了排名。最优模型的ROC曲线显示了其有效区分ChatGPT“是”和“否”回答的能力。

通过利用基于SHAP的特征影响分析，我们发现尽管提示主要侧重于比较实际值和预期值（“比率”变量），但实际交易金额和交易次数（例如Txn Cnt ACH）也对预测有显著贡献。

让我们深入研究一下前几个关键特征的影响：

当ACH交易次数超过9次时，较高的值显著增加”是”预测的概率。
对于实际和预期Wire交易金额之间的比率，超过1的偏离值表示更高的风险，当该比率超过2时，风险显著增加。
与前一个情况相反，当ChatGPT评估实际和预期ACH交易次数之间的偏离时，低于预期值（<0.8）也引起怀疑。
当实际Wire交易金额超过8000美元时，风险水平突然上升。

为了提供更多见解，以下是基于SHAP的预测解释，揭示了影响ChatGPT预测的因素。

通过利用机器学习并探索LLM的内部工作原理，我们开启了无限的机遇。我们可以优化模型，提高其准确性，并利用它们的力量在各个行业和领域推动智能决策的发展。

结论

我还有其他想法要探索，但我将它们保留到未来的博客文章中。总结起来，从这个分析中得出的关键要点是：

大型语言模型（LLM）可以通过有效的提示策略进行零样本预测。
机器学习和预测洞察力对于理解LLM的预测和推理过程至关重要。
利用LLM生成合成数据可以极大地加快新想法的开发和评估，消除数据可用性限制和安全/隐私问题。

这些洞察力突出了LLM在各种应用中的潜力，并强调了利用机器学习技术进行预测分析的重要性。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Llm
Datarobot
Machine Learning
Trust
Written by Ray Mi
35 Followers

RVP of DataScience Practice, DataRobot

Follow
More from Ray Mi

Ray Mi

From Innovation to Implementation: Best Practices for Monitoring Generative AI in Business
Introduction
4 min read
·
Aug 11, 2023

11

Ray Mi

Unveiling the Mechanics of Zero-Shot Predictions: Harnessing Machine Learning Models to Understand…
Introduction
8 min read
·
May 30, 2023

7

Ray Mi

Future of Generative AI: A Frontline Practitioner’s Take on Adoption Trends
Introduction
8 min read
·
Jun 5, 2023

28

Ray Mi

Demystify Large Language Model and Generative AI (Part 2) : From GPT to ChatGPT, a Data Science…
Introduction
9 min read
·
Jun 14, 2023

35

See all from Ray Mi
Recommended from Medium

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.9K

44

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Lists
Predictive Modeling w/ Python
20 stories
·
966 saves
Practical Guides to Machine Learning
10 stories
·
1146 saves
Natural Language Processing
1253 stories
·
733 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
322 saves

Janna Lipenkova

in

Towards Data Science

Choosing the right language model for your NLP use case
A guide to understanding, selecting and deploying Large Language Models
15 min read
·
Sep 27, 2022

568

8

Raja Gupta

Generative AI for Beginners: Part 1 — Introduction to AI
Learn Generative AI by Spending 15 Minutes Daily for 8 Days
13 min read
·
Feb 8, 2024

1.2K

20

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

20K

574

Alexandru Lazar

in

ILLUMINATION

Ten Habits that will get you ahead of 99% of People
Improve your life and get ahead of your peers in 10 simple steps
9 min read
·
Nov 18, 2023

20K

356

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:12.117 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.087 | Max budget: $10.000 | Current cost: $0.027, prompt_tokens: 8661, completion_tokens: 279
2024-03-04 22:03:12.125 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "改进大型语言模型在数值计算中的准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
首页
培训课程
分类浏览
活动讲座
问答
企业培训
摸鱼
快讯
搜索
APP
发布
注册 | 登录
RLHF再也不需要人类了！谷歌团队研究证明，AI标注已达人类水平
新智元
关注
2023-09-05
0 评论
3360 浏览
10 收藏
22 分钟
释放双眼，带上耳机，听听看~！
00:00
00:00
🔗 B端产品经理两大难题：如何从市场，用户，业务等多个角度分析和设计产品？如何有效地管理和推进项目落地？

最近，谷歌在研究中提出了用大模型代替人类，进行偏好标注，也就是AI反馈强化学习（RLAIF），结果发现，RLAIF可以在不依赖人类标注员的情况下，产生与RLHF相当的改进效果。具体如何理解谷歌在最新研究中提出的RLAIF方法呢？不妨来看看本文的解读。

如果说，RLHF中的「人类」被取代，可行吗？

谷歌团队的最新研究提出了，用大模型替代人类，进行偏好标注，也就是AI反馈强化学习（RLAIF）。

论文地址：https://arxiv.org/abs/2309.00267

结果发现，RLAIF可以在不依赖人类标注员的情况下，产生与RLHF相当的改进效果，胜率50%。

什么样的人，适合做B端产品经理？
要想成为优秀的B端产品经理，懂业务和懂产品是两个很重要的标准。B端赛道非常细分，产品迭代和推广的速度也很慢，这就产生了大量工作机会...
查看详情 >

同时，谷歌研究再次证明了RLAIF和RLHF，比起监督微调（SFT）胜率都超过了70%。

如今，大型语言模型训练中一个关键部分便是RLHF。人类通过对AI输出的质量进行评级，让回应更加有用。

但是，这需要付出很多的努力，包括让许多标注人员暴露在AI输出的有害内容中。

既然RLAIF能够与RLHF相媲美，未来模型不需要人类反馈，也可以通过自循环来改进。

一、RLHF不需要人类了

当前，RLHF已经成为微调大模型的核心方法，包括ChatGPT、Bard等模型都采用这一范式。

具体来说，RLHF分为三步：预训练一个监督微调LLM；收集数据训练一个奖励模型；用RL微调模型。

有了RLHF，大模型可以针对复杂的序列级目标进行优化，而传统的SFT很难区分这些目标。

然而，一个非常现实的问题是，RLHF需要大规模高质量的人类标注数据，另外这些数据能否可以取得一个优胜的结果。

在谷歌这项研究之前，Anthropic研究人员是第一个探索使用AI偏好来训练RL微调的奖励模型。

他们首次在「Constitutional AI」中提出了RLAIF，发现LLM与人类判断表现出高度一致，甚至在某些任务上，表现优于人类。

但是，这篇研究没有将人类与人工智能反馈做对比，因此，RLAIF是否可以替代RLHF尚未得到终极答案。

谷歌最新研究，主要就是解决这个问题。

研究人员在模型摘要任务中，直接比较了RLAIF和RLHF。

给定1个文本和2个候选答案，使用现成的LLM给出一个偏好标注。

然后，根据LLM偏好和对比损失训练奖励模型（RM）。最后，通过强化学习微调策略模型，利用奖励模型给出奖励。

那么，谷歌与Anthropic提出的RLAIF方法有什么不同？

谷歌自己在文中解释道，

– 谷歌：根据AI标注的偏好训练奖励模型，然后进行RL微调。

– Constitutional AI：通过迭代，要求LLM根据宪法生成更好的响应，来改进监督学习模型。

二、AI自标注，自我改进

谷歌在最新研究中提出的RLAIF方法，过程是怎样的？

1. 大语言模型进行偏好标注

研究人员用「现成的」LLM来标注对两个候选项之间的偏好。

这是一个针对一般用途进行预训练或指令调整的模型，但未针对特定下游任务进行微调。给定一段文本和两个候选摘要，LLM被要求评价哪个摘要更好。LLM 的输入结构如下：

1. 序言

介绍和描述手头任务的说明

2. 多个样本实例（可选）

一段文本、一对摘要、思路的基本原理和偏好判断

3. 要标注的样本

一段文本和一对要标注的摘要

4. 结尾

提示 LLM 的结束字符串（例如「Preferred Summary=」）

在给LLM提供输入后，研究人员获得生成token「1」和「2」的对数概率，并计算softmax以获得偏好分布。

从LLM获取偏好标注的方法有很多，例如从模型中解码自由形式的响应并启发式地提取偏好（例如：output=「the first summary is better」），或者将偏好分布表示为单热表示(one-hot representation)。然而，研究人员没有尝试这些替代方案，因为他们的方法已经产生了很高的准确性。

研究人员试验了两种类型的序言：第一种是「Base」，它简单地询问「哪个摘要更好？」，第二种是「OpenAI」，它模仿了生成OpenAI TL;DR 偏好数据集的人类偏好标注器的评级指令，包含有关构成强摘要的详细信息。如下图所示。

研究人员还通过在提示中添加少量样本来尝试上下文学习，其中手动选择样本来涵盖不同的主题。解决位置偏差。

之前的研究结果表明，向LLM展示候选项的顺序可能会影响LLM判断更喜欢的候选项。研究人员发现证据表明存在这种位置偏差，尤其是对于较小尺寸的标注LLM 。

为了减轻偏好标注中的位置偏差，研究人员对每对候选项进行两次推理，候选项提交给LLM的顺序二次推理是相反的。然后对两个推推理的结果进行平均以获得最终的偏好分布。

2. 思维链推理

研究人员尝试从AI标注器中引出思维链 (COT) 推理，以提高与人类偏好的一致性。

研究人员替换标准的结尾提示（例如将「Preferred Summary=」替换为「Consider the coherence, accuracy, coverage, and over-all quality of each summary and explain which one is better. Rationale：」），然后解码一个LLM的回复。

最后，研究人员将原始提示、响应和原始结尾字符串“Preferred Summary=”连接在一起，并按照第 3.1 节中的评分过程来获得偏好分布。具体过程见下图。

在零样本提示中，LLM没有给出推理应该是什么样子的示例，而在少量样本提示中，研究人员提供了模型要遵循的COT推理示例。示例请参见下图。

3. 自洽性（Self-Consistency）

对于思维链提示，研究人员还尝试了自洽性——一种通过对多个推理路径进行采样并聚合每个路径末尾产生的最终答案来改进思维链推理的技术。

使用非零解码温度（non-zero decoding temperature）对多个思维链基本原理进行采样，然后按照上一节中的方法获得每个思维链的LLM偏好分布。然后对结果进行平均以获得最终的偏好分布。

4. AI反馈的强化学习

在LLM对偏好进行标注后，将训练奖励模型(RM)来预测偏好。由于研究人员的方法产生软标注（Soft Label），他们采用RM生成的奖励分数的softmax的交叉熵损失（cross-entropy loss），而不是奖励模型中提到的损失。

Softmax将RM的无界分数（unbounded scores）转换为概率分布。

在AI标注数据集上训练RM可以被视为模型蒸馏的一种形式，特别是因为研究人员的AI标注器通常比RM更大、更强。

另一种方法是绕过RM并直接使用AI反馈作为RL中的奖励信号，尽管这种方法的计算成本更高，因为AI标注器比RM更大。

通过经过训练的RM，研究人员使用适用于语言建模领域的Advantage Actor Critic (A2C)算法的修改版本进行强化学习。

5. 评价

研究人员通过三个指标评估他们的结果 – AI标注器对齐、配对准确度和胜率。

AI标注器对齐时用来衡量AI标注偏好相对于人类偏好的准确性。

对于单个示例，将软人工智能标注的偏好转换为二进制表示。如果标注与目标人类偏好一致则分配 1，否则分配 0。

配对准确性是衡量经过训练的奖励模型相对于一组保留的人类偏好的准确性。

给定共享上下文和一对候选响应，如果根据人类标注，RM对首选候选的评分高于非首选候选，则配对准确度为 1。否则该值为 0。该数量是多个示例的平均值，以衡量RM的总体精度。

胜率通过衡量人类更喜欢一项策略频率来评估两项策略的端到端质量。

给定一个输入和两次生成结果，人类标注者选择首选哪一个生成结果。策略A优于策略B的实例百分比称为「A对B的胜率」。

三、实验细节

研究人员使用由OpenAI管理的经过过滤的Reddit TL;DR 数据集。TL;DR包含来自Reddit的约300万个帖子，涉及各种主题（也称为「subreddits」）以及原作者撰写的帖子摘要。

数据还经过OpenAI过滤，以确保高质量，其中包括使用普通大众可以理解的Reddit主题白名单。

此外，仅包含摘要中含有24到48个标注的帖子。过滤后的数据集包含123,169个帖子，其中约5%作为验证集。

有关数据集的更多详细信息可以在原始论文中找到。此外， OpenAI从过滤后的TL;DR数据集中整理了一个人类偏好数据集。

对于给定的帖子，根据不同的策略生成两个候选摘要，并要求标注器对他们喜欢的摘要进行评分。总数据集包含大约92k成对比较。

1. LLM标注

为了评估AI标注技术的有效性（例如提示、自洽性），研究人员从TL;DR偏好数据集中选择示例，其中人类标注者会偏好置信度更高的摘要。

研究人员在数据集训练分割的随机15%子集上评估AI标注器对齐，以实现更快的实验迭代，生成2851个评估示例。

对于奖励模型训练，TL;DR偏好数据集的完整训练分割由LLM标注并用于训练，无论置信度分数如何。

2. 模型训练

研究人员使用PaLM 2 Extra-Small (XS)作为初始检查点，在OpenAI过滤后的TL;DR数据集上训练SFT模型。

然后，研究人员从SFT模型初始化RM，并在OpenAI的TL;DR人类偏好数据集上训练它们。

对于表1和5.1中的结果，研究人员使用PaLM 2L生成AI标注的偏好，使用「OpenAI + COT 0-shot」提示（，没有自洽性，然后在完整的偏好上训练RM数据集。

对于强化学习，研究人员使用Advantage Actor Critic (A2C)来训练策略。策略和价值模型都是从SFT模型初始化的。研究人员使用过滤后的 Reddit TL;DR 数据集作为初始状态来推出他们的策略。

3. 人类评估

研究人员收集了1200个人类评级来评估RLHF和RLAIF策略。对于每项评级任务，评估人员都会收到一篇帖子和4个根据不同策略（RLAIF、RLHF、SFT和人类参考各一个）生成的摘要，并要求按照质量顺序对它们进行排名，不存在任何联系。

帖子取自TL;DR监督微调数据集的保留集，该数据集未用于任何其他评估。一旦收集了这些排名，就可以计算任意两项策略的胜率。

四、胜率50%，打平手
1. RLAIF vs. RLHF

文章开篇，已经介绍了谷歌将RLAIF与RLHF相比较的优势，结果表明，两种方法有着相似的性能。

具体来说，与基线SFT相比较，在71%的情况下，人类评估者更喜欢RLAIF。73%的情况下，RLHF优于SFT。

研究人员还直接比较了RLAIF和RLHF的胜率，发现它们受欢迎程度是等同的——即胜率都是50%。

为了进一步了解这两种策略的差异，谷歌对其生成的摘要进行了定性比较。

另外，他们还将RLAIF和RLHF摘要与人工编写的参考摘要进行比较。79%的情况下，RLAIF生成的摘要优于参考摘要，80%的情况下，RLHF结果优于参考摘要。

可见，RLAIF和RLHF与参考摘要之间的胜率只差1%，并没有显著的差异。

值得注意的是，研究人员还发现，RLHF策略出现幻觉的频率，往往高于RLAIF，如上表红色标注的文字。

在控制摘要长度后，RLAIF和RLHF策略仍然优于基线SFT，并取得了相似的胜率。

这些结果表明，RLAIF不需要依赖于人工标注，是RLHF的可行替代方案。

2. 提示技巧

在使用提示技巧中，谷歌团队尝试了三种类型的提示技术，preamble specificity、CoT、少样本上下文学习。

结果发现，通过详细的OpenAI序言进行提示，并进行CoT推理，AI标注器可以取得78%的一致性。

而情境学习不会提高准确性，甚至可能会使准确性变得更糟。

3. 自洽性

研究人员使用4和16个样本进行自洽性实验，解码温度为1。

以T = 1对多个思维链原理进行采样，结果与人类偏好的一致性较低。

4. 大模型标注器的规模

研究还发现，扩大大模型标注器的参数规模，可能会产生更高质量的偏好标注。

5. 偏好示例数量

奖励模型的准确性如何随训练示例进行变化？

研究人员发现，需要经过数千个示例训练后，奖励模型的性能接近于完整数据集的训练。

五、结论

研究人员证明了RLAIF可以在不依赖人类标注者的情况下产生与RLHF相当的改进。

虽然这项工作凸显了 RLAIF 的潜力，但依然有一些局限性。

首先，这项研究仅探讨了总结任务，关于其他任务的泛化性还需要进一步研究。

其次，研究人员没有估计LLM推理在经济成本上是否比人工标注更有优势。

此外，还有一些有趣的问题值得研究，例如RLHF与RLAIF相结合是否可以优于单一的一种方法，使用LLM直接分配奖励的效果如何，改进 AI标注器对齐是否会转化为改进的最终策略，以及是否使用LLM与策略模型大小相同的标注器可以进一步改进策略（即模型是否可以「自我改进」）。

六、网友热议

谷歌发表了两篇关于RL的论文：

RLAIF：训练与人类反馈类似的奖励模型
ReST：使用生成模型促进自训练 将这两篇论文结合起来，可以满足那些对数据饥渴的人工智能算法

半个月前，谷歌DeepMind刚刚提出了一个新算法ReST，为了使大规模语言模型与人类偏好保持一致。

具体通过离线强化学习方法，改进大型语言模型的翻译质量，以更好地符合人类偏好。

一位研究人员表示，根据定性测试，Anthropic的Claude模型似乎比GPT-4弱。这可能是RLHF/RLAIF方法或预训练造成的。目前还不清楚这些方法在实际应用中的泛化效果是否更好，即使它们在学术基准上的表现更好。

我不会说这降低了人工标注的重要性，但有一点可以肯定，人工智能反馈的RL可以降低成本。人工标注对于泛化仍然极其重要，而RLHF+RLAIF混合方法比任何单一方法都要好。

大部分网友认为论文是很大的突破，但也有网友觉得这和Anthropic在几个月前提出的Constitute Claude中的RLAIF似乎没有本质的区别。

参考资料：

https://arxiv.org/abs/2309.00267

编辑：编辑部

来源公众号：新智元（ID：AI_era），“智能+”中国主平台，致力于推动中国从“互联网+”迈向“智能+”。

本文由人人都是产品经理合作媒体 @新智元 授权发布，未经许可，禁止转载。

题图来自 Unsplash，基于CC0协议。

该文观点仅代表作者本人，人人都是产品经理平台仅提供信息存储空间服务。

赞赏
收藏
10
点赞
0
更多精彩内容，请关注人人都是产品经理微信公众号或下载App
ChatGPT
RLHF
大模型
标注
谷歌
分享
新智元
关注
"智能+"中国主平台，致力于推动中国从"互联网+"迈向"智能+"
39篇作品  139240总阅读量
为你推荐
美团闪电仓抢滩即时零售，帮友商“训练”了合作商？
03-011580 浏览
产品从免费到付费，如何让用户“心甘情愿”接受？
07-177477 浏览
“顶流”微信想要重建社交边界感
08-093687 浏览
脑图：我最常用的非标准化演示工具
10-303927 浏览
从抖音的发家史，看设计师赋予创意引导的重要性
06-303716 浏览
2024年，产品经理跳槽，必过这2道关卡！
推荐
评论
评论请登录
目前还没评论，等你发挥！
为你推荐
全球化公司起名指北
01-123467 浏览
下沉网红，好看不好赚？
08-071641 浏览
产品经理如何在AI时代“上岸”
10-035098 浏览
推荐专题
更多专题
专题
10517人已学习12篇文章
退款功能的设计思路
退款是支付平台的一个重要业务，本专题的文章分享了退款功能的设计思路。
专题
14787人已学习12篇文章
分销体系设计指南
分销是互联网拉人头和推广的常用手段，能够在短时间内实现裂变营销。本专题的文章分享了分销体系设计指南。
专题
14327人已学习12篇文章
如何做好服务设计？
服务设计在流程性和系统性的问题解决方面提供很好的思路和方法。本专题的文章分享了如何做好服务设计。
专题
12405人已学习15篇文章
智能硬件产品经理入门篇
智能硬件产品经理需要做什么工作内容呢？与互联网产品经理有什么区别呢？本专题为刚入行的智能硬件产品经理分享了入门指南。
专题
76053人已学习19篇文章
AI 产品经理入门手册
当AI已然成为新的焦点和风口，产品经理该如何抓住这个风口顺势飞起？
专题
16831人已学习15篇文章
表单设计指南
表单是我们比较常见的一个信息录入工具。本专题的文章提供了表单设计指南。
社群
QQ群 | 微信群
TOC产品交流群
加入
TOB产品交流群
加入
TOG产品交流群
加入
抖音运营交流群
加入
视频号运营交流
加入
小红书运营交流
加入
快讯
查看更多
迪阿股份：公司目前对AIGC技术还在了解与学习过程中，但暂未使用
3小时前
埃夫特：3C电子行业的投资预计2024年会有一定恢复
3小时前
比亚迪仰望U8销量2月达780辆 保持百万级新能源SUV销冠
3小时前
热门文章
6个步骤解析“用户运营”
03-01
社区需要轻社交
03-04
Sora热度背后，真正值得学习的是什么？
03-01
浅聊产品经理到底是个什么经理？
03-01
产品思维及AIGC高效学习之初章
03-02
Prompt新连接，生成式AI重构营销新体验
03-01
为什么App的任务奖励需要用户点击领取，而不是自动发放？
朋友吐槽说，“XX软件的奖励不能自动发放，需要自己去领”然后告知他朋友圈的一些朋友，并说为什么不设置...
37.8k 点击21 回答
进入回答
平台软件为什么不做双向评价？
13.3k 点击21 回答
未来五年内，你觉得做产品或者运营，哪个更有前途？
35.4k 点击20 回答
App签到模式能否设置为识别用户在使用了就自动签到，无需用户手动签到？
17.1k 点击13 回答
文章导航
一、RLHF不需要人类了
二、AI自标注，自我改进
三、实验细节
四、胜率50%，打平手
五、结论
六、网友热议
关于
人人都是产品经理（woshipm.com）是以产品经理、运营为核心的学习、交流、分享平台，集媒体、培训、社群为一体，全方位服务产品人和运营人，成立12年举办在线讲座1000+期，线下分享会500+场，产品经理大会、运营大会50+场，覆盖北上广深杭成都等20个城市，在行业有较高的影响力和知名度。平台聚集了众多BAT美团京东滴滴360小米网易等知名互联网公司产品总监和运营总监，他们在这里与你一起成长。
合作伙伴
链接
隐私政策
投稿须知
意见反馈
帮助中心

公众号

视频号

友情链接
PM265
产品经理导航
起点课堂
猪八戒网
人才热线
伙伴云表格
网易易盾
个推
友盟+
粮仓
创业邦
每日报告
鸟哥笔记
慕课网
旗下品牌: 起点课堂 | 运营派 | 粮仓企微管家
©2010-2024 - 人人都是产品经理 - 粤ICP备14037330号-粤公网安备 44030502001309号
广播电视节目制作经营许可证（粤）字第03109号 版权所有 © 深圳聚力创想信息科技有限公司

2024-03-04 22:03:16.415 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.101 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 4269, completion_tokens: 240
2024-03-04 22:03:16.423 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型在数值计算中的问题".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

Footprint Analytics x Future3 Campus联合发布AI与Web3研究报告

Future3 Campus

·

Follow

29 min read
·
Dec 5, 2023

--

GPT的横空出世将全球的目光吸引至大语言模型，各行各业都尝试着利用这个“黑科技”提高工作效率，加速行业发展。Future3 Campus携手Footprint Analytics共同深入研究AI与Web3结合的无限可能，联合发布了《AI与Web3数据行业融合现状、竞争格局与未来机遇探析》研报。该研报分为上下两篇，本文为上篇，由Footprint Analytics研究员Lesley、Shelly共同编撰。

摘要：

LLM 技术的发展让人们更加关注 AI 与 Web3 的结合，新的应用范式正在逐步展开。本文中，我们将重点研究如何利用 AI 提升 Web3 数据的使用体验和生产效率。
由于行业尚处早期阶段和区块链技术的特性，Web3 数据行业面临着诸多挑战，包括数据来源、更新频率、匿名属性等，使得利用 AI 解决这些问题成为新关注点。
LLM 相对于传统人工智能的可扩展性、适应性、效率提升、任务分解、可访问性和易用性等优势，为提高区块链数据的体验和生产效率提供了想象空间。
LLM 需要大量高质量数据进行训练，而区块链领域垂直知识丰富且数据公开，可以为 LLM 提供学习素材。
LLM 也可以帮助生产和提升区块链数据的价值，例如数据清洗、标注、生成结构化数据等。
LLM 不是万灵药，需要针对具体业务需求进行应用。既要利用 LLM 的高效率，同时也要注意结果的准确性。

AI 与 Web3 的发展与结合

1.1 AI 的发展历史

人工智能（AI）的历史可以追溯到上个世纪 50 年代。自 1956 年起，人们开始关注人工智能这一领域，逐渐发展出了早期的专家系统，帮助专业领域解决问题。此后，机器学习的兴起，拓展了 AI 的应用领域，AI 开始更广泛地应用在各行各业。到如今，深度学习和生成式人工智能爆发，带给了人们无限可能性，其中的每一步都充满了不断的挑战与创新，以追求更高的智能水平和更广泛的应用领域。

图 1：AI 发展历程

2022 年 11 月 30 日，ChatGPT 面世，首次展示了 AI 与人类低门槛、高效率交互的可能性。ChatGPT 引发了对人工智能的更广泛探讨，重新定义了与 AI 互动的方式，使其变得更加高效、直观和人性化，也推动了人们对更多生成式人工智能的关注，Anthropic（Amazon）、DeepMind（Google）、Llama 等模型也随后进入人们的视野。与此同时，各行各业的从业者也开始积极探索 AI 会如何推动他们所在领域的发展，或者寻求通过与 AI 技术的结合在行业中脱颖而出，进一步加速了 AI 在各个领域的渗透。

1.2 AI 与 Web3 的交融

Web3 的愿景从改革金融体系开始，旨在实现更多的用户权力，并有望引领现代经济和文化的转变。区块链技术为实现这一目标提供了坚实的技术基础，它不仅重新设计了价值传输和激励机制，还为资源分配和权力分散提供了支持。

图 2：Web3 发展历程

早在 2020 年，区块链领域的投资公司 Fourth Revolution Capital（4RC）就曾指出，区块链技术将和 AI 结合，通过对金融、医疗、电子商务、娱乐等全球行业的去中心化，以实现对现有行业的颠覆。

目前，AI 与 Web3 的结合，主要是两大方向：

利用 AI 去提升生产力以及用户体验。
结合区块链透明、安全、去中心化存储、可追溯、可验证的技术特点，以及 Web3 去中心化的生产关系，解决传统技术无法解决的痛点或者激励社区参与，提高生产效率。

市场上 AI 与 Web3 的结合有以下的一些探索方向：

图 3：AI 与 Web3 结合全景图
数据：区块链技术可以应用在模型数据存储上，提供加密数据集，保护数据隐私和记录模型使用数据的来源、使用情况，以及校验数据的真实性。通过访问和分析存储在区块链上的数据，AI 可以提取有价值的信息，并用于模型训练和优化。同时，AI 也可以作为数据生产工具，去提高 Web3 数据的生产效率。
算法：Web3 中的算法可以为 AI 提供更安全、可信和自主控制的计算环境，为 AI 体统提供加密保障，在模型参数上，内嵌安全防护栏，防止系统被滥用或者恶意操作。AI 可以与 Web3 中的算法进行交互，例如利用智能合约执行任务、验证数据和执行决策。同时，AI 的算法也可以为 Web3 提供更智能化和高效的决策和服务。
算力：Web3 的分散式计算资源可以为 AI 提供高性能的计算能力。AI 可以利用 Web3 中的分散式计算资源进行模型的训练、数据分析和预测。通过将计算任务分发到网络上的多个节点，AI 可以加快计算速度，并处理更大规模的数据。

在本文中，我们将重点探索如何利用 AI 的技术，去提升 Web3 数据的生产效率以及使用体验。

Web3数据现状

2.1 Web2 & Web3 数据行业对比

作为 AI 最核心的组成部分“数据”，在 Web3 跟我们熟悉的 Web2 很着很多的区别。差异主要是在于 Web2 以及 Web3 本身的应用架构导致其产生的数据特征有所不同。

2.1.1 Web2 & Web3 应用架构对比

图 4：Web2 & Web3 应用架构

在 Web2 架构中，通常是由单一实体（通常是一家公司）来控制网页或者 APP，公司对于他们构建的内容有着绝对的控制权，他们可以决定谁可以访问其服务器上的内容和逻辑，以及用户拥有怎样的权益，还可以决定这些内容在网上存在的时长。不少案例表明，互联网公司有权改变其平台上的规则，甚至中止为用户提供服务，而用户对此无法保留所创造的价值。

而 Web3 架构则借助了通用状态层（Universal State Layer）的概念，将一部分或者全部的内容和逻辑放置在公共区块链上。这些内容和逻辑是公开记录在区块链上的，可供所有人访问，用户可以直接控制链上内容和逻辑。而在 Web2 中，用户需要帐户或 API 密钥才能与区块链上的内容进行交互。用户可以直接控制其对应的链上内容和逻辑。不同于 Web2，Web3 用户无需授权帐户或 API 密钥就能与区块链上的内容进行交互（特定管理操作除外）。

2.1.2 Web2 与 Web3 数据特征对比

图 5：Web2 与 Web3 数据特征对比

Web2 数据通常表现为封闭和高度受限的，具有复杂的权限控制，高度成熟、多种数据格式、严格遵循行业标准，以及复杂的业务逻辑抽象。这些数据规模庞大，但互操作性相对较低，通常存储在中央服务器上，且不注重隐私保护，大多数是非匿名的。

相比之下，Web3 数据更加开放，访问权限更广泛，尽管成熟度较低，以非结构化数据为主，标准化较为罕见，业务逻辑抽象相对简化。Web3 的数据规模相对 Web2 较小，但它具有较高的互操作性（比如 EVM 兼容），并可分散或集中存储数据，同时强调用户隐私，用户通常采用匿名方式进行链上交互。

2.2 Web3 数据行业现状与前景，以及遇到的挑战

在 Web2 时代，数据如石油的“储量”般珍贵，访问和获取大规模数据一直是极大的挑战。在 Web3 中，数据的开放性和共享性一下子让大家觉得“石油到处都是”，使得 AI 模型能够更轻松地获取更多的训练数据，这对于提高模型性能和智能水平至关重要。但对 Web3 这个“新石油” 的数据处理依然有很多问题待解决，主要有以下几个：

数据来源：链上数据“标准”繁杂分散，数据处理花费大量人工成本

处理链上数据时，需要反复执行耗时而劳动密集的索引过程，需要开发者和数据分析师花费大量时间和资源来适应不同链、不同项目之间的数据差异。链上数据行业缺乏统一的生产和处理标准，除了记录到区块链账本上的，events，logs，and traces 等都基本上是项目自己定义和生产（或生成）的，这导致非专业交易者很难辨别并找到最准确和可信的数据，增加了他们在链上交易和投资决策中的困难。比如，去中心化交易所 Uniswap 和 Pancakeswap 就有可能在数据处理方法和数据口径上存在差异，过程中的检查和统一口径等工序进一步加大了数据处理的复杂性。

数据更新：链上数据体量大且更新频率高，难以及时地处理成结构化数据

区块链是时刻变动的，数据更新以秒甚至毫秒级别计。数据的频繁产生和更新使其难以维持高质量的数据处理和及时的更新。因此，自动化的处理流程是十分重要的，这也是对于数据处理的成本和效率的一大挑战。Web3 数据行业仍处于初级阶段。随着新合约的层出不穷和迭代更新，数据缺乏标准、格式多样，进一步增加了数据处理的复杂性。

数据分析：链上数据的匿名属性，导致数据身份难以区分

链上数据通常不包含足够的信息来清晰识别每个地址的身份，这使得数据在与链下的经济、社会或法律动向难以联动。但是链上数据的动向与现实世界紧密相关，了解链上活动与现实世界中特定个体或实体的关联性对于特定的场景比如数据分析来说十分重要。

随着大语言模型（LLM）技术引发的生产力变更讨论，能否利用 AI 来解决这些挑战也成为 Web3 领域的一个焦点关注之一。

AI 与 Web3 数据碰撞产生的化学反应

3.1 传统 AI 与 LLM 的特征对比

在模型训练方面，传统 AI 模型通常规模较小，参数数量在数万到数百万之间，但为了确保输出结果的准确性，需要大量的人工标注数据。LLM 之所以如此强大，部分原因在于其使用了海量的语料拟合百亿、千亿级以上的参数，极大地提升了它对自然语言的理解能力，但这也意味着需要更多的数据来进行训练，训练成本相当高昂。

在能力范围和运行方式上，传统 AI 更适合特定领域的任务，能够提供相对精准和专业的答案。相比之下，LLM 更适合通用性任务，但容易产生幻觉问题，这意味着在一些情况下，它的回答可能不够精确或专业，甚至完全错误。因此，如果需要和客观，可信任，和可以追溯的结果，可能需要进行多次检查、多次训练或引入额外的纠错机制和框架。

图 6：传统 AI 与大模型语言模型 （LLM）的特征对比

3.1.1 传统 AI 在 Web3 数据领域的实践

传统 AI 已经在区块链数据行业展现了其重要性，为这一领域带来了更多创新和效率。例如，0xScope 团队采用 AI 技术，构建了基于图计算的群集分析算法，通过不同规则的权重分配来帮助准确识别用户之间的相关地址。这种深度学习算法的应用提高了地址群集的准确性，为数据分析提供了更精确的工具。Nansen 则将 AI 用于 NFT 价格预测，通过数据分析和自然语言处理技术，提供有关 NFT 市场趋势的见解。另一方面，Trusta Labs使用了基于资产图谱挖掘和用户行为序列分析的机器学习方法，以增强其女巫检测解决方案的可靠性和稳定性，有助于维护区块链网络生态的安全。另一方面，Trusta Labs 采用了图挖掘和用户行为分析的方法，以增强其女巫检测解决方案的可靠性和稳定性，有助于维护区块链网络的安全。Goplus 在其运营中利用传统人工智能来提高去中心化应用程序（dApps）的安全性和效率。他们收集和分析来自 dApp 的安全信息，提供快速风险警报，帮助降低这些平台的风险敞口。这包括通过评估开源状态和潜在恶意行为等因素来检测 dApp 主合同中的风险，以及收集详细的审计信息，包括审计公司凭证、审计时间和审计报告链接。Footprint Analytics 则使用 AI 生成生产结构化数据的代码，分析 NFT 交易 Wash trading 交易以及机器人账户筛选排查。

然而，传统 AI 拥有的信息有限，专注于使用预定的算法和规则执行预设任务，而 LLM 则通过大规模的自然语言数据学习，可以理解和生成自然语言，这使其更适合处理复杂且巨量的文本数据。

最近，随着 LLM 取得了显著进展，人们对 AI 与 Web3 数据的结合，也进行了一些新的思考与探索。

3.1.2 LLM 的优势

LLM 相对于传统人工智能具有以下优势：

可扩展性：LLM 支持大规模数据处理

LLM 在可扩展性方面表现出色，能够高效处理大量数据和用户互动。这使其非常适合处理需要大规模信息处理的任务，如文本分析或者大规模数据清洗。其高度的数据处理能力为区块链数据行业提供了强大的分析和应用潜力。

适应性：LLM 可学习适应多领域需求

LLM 具备卓越的适应性，可以为特定任务进行微调或嵌入行业或私有数据库，使其能够迅速学习和适应不同领域的细微差别。这一特性使 LLM 成为了解决多领域、多用途问题的理想选择，为区块链应用的多样性提供了更广泛的支持。

提高效率：LLM 自动化任务提高效率

LLM 的高效率为区块链数据行业带来了显著的便利。它能够自动化原本需要大量人工时间和资源的任务，从而提高生产力并降低成本。LLM 可以在几秒内生成大量文本、分析海量数据集，或执行多种重复性任务，从而减少了等待和处理时间，使区块链数据处理更加高效。

任务分解：可以生成某些工作的具体计划，把大的工作分成小步骤

LLM Agent 具备独特的能力，即可以生成某些工作的具体计划，将复杂任务分解为可管理的小步骤。这一特性对于处理大规模的区块链数据和执行复杂的数据分析任务非常有益。通过将大型工作分解成小任务，LLM 可以更好地管理数据处理流程，并输出高质量的分析。

这一能力对于执行复杂任务的 AI 系统至关重要，例如机器人自动化、项目管理和自然语言理解与生成，使其能够将高级任务目标转化为详细的行动路线，提高任务执行的效率和准确性。

可访问性和易用性：LLM 以自然语言提供用户友好互动

LLM 的可访问性使更多用户能够轻松与数据和系统进行互动，让这些互动更加用户友好。通过自然语言，LLM 使数据和系统更容易访问和交互，无需用户学习复杂的技术术语或特定命令，例如，SQL，R，Python 等来做数据获取和分析。这一特性拓宽了区块链应用的受众范围，让更多的人能够访问和使用 Web3 应用和服务，不论他们是否精通技术，从而促进了区块链数据行业的发展和普及。

3.2 LLM 与 Web3 数据的融合

图 7：区块链数据与 LLM 的融合

大型语言模型的培训需要依赖大规模数据，通过学习数据中的模式来建立模型。区块链数据中蕴含的交互和行为模式是 LLM 学习的燃料。数据量和质量也直接影响 LLM 模型的学习效果。

数据不仅仅是 LLM 的消耗品，LLM 还有助于生产数据，甚至可以提供反馈。例如，LLM 可以协助数据分析师在数据预处理方面做出贡献，如数据清洗和标注，或者生成结构化数据，清除数据中的噪声，凸显有效信息。

3.3 增强 LLM 的常用技术解决方案

ChatGPT 的出现，不仅向我们展示了 LLM 解决复杂问题的通用能力，同时也引发了全球范围的，对在通用能力上去叠加外部能力的探索。这里包括，通用能力的增强（包括上下文长度、复杂推理、数学、代码、多模态等）以及外部能力的扩充（处理非结构化数据、使用更复杂的工具、与物理世界的交互等）。如何将 crypto 领域的专有知识以及个人的个性化私有数据嫁接到大模型的通用能力上，是大模型在 crypto 垂直领域商业化落地的核心技术问题。

目前，大多数应用都集中在检索增强生成（RAG）上，比如提示工程和嵌入技术，已经存在的代理工具也大多都聚焦于提高 RAG 工作的效率和准确性。市场上主要的基于 LLM 技术的应用栈的参考架构有以下几种：

Prompt Engineering
图 8：Prompt Engineering

当前，大多数从业者在构建应用时采用基础解决方案，即 Prompt Engineering。这一方法通过设计特定的 Prompt 来改变模型的输入，以满足特定应用的需求，是最方便快捷的做法。然而，基础的 Prompt Engineering 存在一些限制，如数据库更新不及时、内容冗杂、以及对输入上下文长度（In-Context Length）的支持和多轮问答的限制。

因此，行业内也在研究更先进的改进方案，包括嵌入（Embedding）和微调（Fine-tuning）。

嵌入（Embedding）

嵌入（Embedding）是一种广泛应用于人工智能领域的数据表示方法，能高效捕获对象的语义信息。通过将对象属性映射成向量形式，嵌入技术能够通过分析向量之间的相互关系，快速找到最有可能正确的答案。嵌入可以在 LLM 的基础上构建，以利用该模型在广泛语料上学到的丰富语言知识。通过嵌入技术将特定任务或领域的信息引入到预训练的大模型中，使得模型更专业化，更适应特定任务，同时保留了基础模型的通用性。

用通俗的话来讲，嵌入就类似于你给一个经过综合训练的大学生一本工具书，让他拿着拥有特定任务相关知识的工具书去完成任务，他可以随时查阅工具书，然后可以解决特定的问题。

微调（Fine-tuning）
图 9：Fine Tuning

微调（Fine-tuning）与嵌入不同，通过更新已经预训练的语言模型的参数，使其适应特定任务。这种方法允许模型在特定任务上表现出更好的性能，同时保持通用性。微调的核心思想是调整模型参数，捕捉与目标任务相关的特定模式和关系。但微调的模型通用能力上限仍然受限于基座模型本身。

用通俗的话来讲，微调就类似于给经过综合训练的大学生上专业知识课程，让他掌握除了综合能力以外的专业课知识，能自行解决专业板块的问题。

重新训练 LLM

当前的 LLM 虽然强大，但不一定能够满足所有需求。重新训练 LLM 是一种高度定制化的解决方案，通过引入新数据集和调整模型权重，使其更适应特定任务、需求或领域。然而，这种方法需要大量计算资源和数据，并且管理和维护重新训练后的模型也是挑战之一。

Agent 模型
图 10：Agent 模型

Agent 模型是一种构建智能代理的方法，它以 LLM 作为核心控制器。这个系统还包括几个关键组成部分，以提供更全面的智能。

Planning，规划：将大任务分成小任务，这样更容易完成
Memory，反思：通过反思过去的行为，改进未来的计划
Tools，工具使用：代理可以调用外部工具获取更多信息，如调用搜索引擎、计算器等

人工智能代理模型具备强大的语言理解和生成能力，能够解决通用问题，进行任务分解以及自我反思。这使得它在各种应用中都有广泛的潜力。然而，代理模型也存在一些局限性，例如受到上下文长度的限制、长期规划和任务拆分容易出错、输出内容的可靠性不稳定等问题。这些局限性需要长期不断的研究和创新，以进一步拓展代理模型在不同领域的应用。

以上的各种技术并不是相互排斥的，它们可以在训练和增强同一个模型的过程中一起使用。开发者可以充分发挥现有大语言模型的潜力，尝试不同的方法，以满足日益复杂的应用需求。这种综合使用不仅有助于提高模型的性能，还有助于推动 Web3 技术的快速创新和进步。

然而，我们认为，虽然现有的 LLM 已经在 Web3 的快速发展中发挥了重要作用，但在充分尝试这些现有模型（如 OpenAI、Llama 2 以及其他开源 LLM）之前，我们可以从浅入深，从 prompt engineering 和嵌入等 RAG 策略入手，谨慎考虑微调和重新训练基础模型。

3.4 LLM 如何加速区块链数据生产的各个流程

3.4.1 区块链数据的一般处理流程

当今，区块链领域的建设者逐渐认识到数据产品的价值。这一价值覆盖了产品运营监控、预测模型、推荐系统以及数据驱动的应用程序等多个领域。尽管这一认知逐渐增强，但作为数据获取到数据应用中不可或缺的关键步骤，数据处理往往被忽视。

图 11：区块链数据处理流程
将区块链原始非结构化数据，如 events 或 logs 等，转换为结构化的数据

区块链上的每一笔交易或事件都会生成 events 或 logs，这些数据通常是非结构化的。这一步骤是获取数据的第一入口，但数据仍然需要被进一步处理以提取有用信息，得到结构化的原始数据。这包括整理数据、处理异常情况和转化为通用格式。

将结构化的原始数据，转换为具有业务意义的抽象表

在得到结构化原始数据后，需要进一步进行业务抽象，将数据映射到业务实体和指标上，比如交易量、用户量等业务指标，将原始数据转化为对业务和决策有意义的数据。

从抽象表中，计算提取业务指标

有了抽象的业务数据后，可以在业务抽象的数据上进行进一步计算，就可以得出各种重要的衍生指标。例如交易总额的月增长率、用户留存率等核心指标。这些指标可以借助 SQL、Python 等工具实现，更加有可能帮助监控业务健康、了解用户行为和趋势，从而支持决策和战略规划。

3.4.2 区块链数据生成流程加入 LLM 后的优化

LLM 在区块链数据处理中可以解决多个问题，包括但不限于以下内容：

处理非结构化数据：

从交易日志和事件中提取结构化信息：LLM 可以分析区块链的交易日志和事件，提取其中的关键信息，如交易金额、交易方地址、时间戳等，将非结构化数据转化为的带有业务意义的数据，使其更易于分析和理解。
清洗数据，识别异常数据：LLM 可以自动识别和清洗不一致或异常的数据，帮助确保数据的准确性和一致性，从而提高数据质量。

进行业务抽象：

将原始链上数据映射到业务实体：LLM 可以将原始区块链数据映射到业务实体，例如将区块链地址映射到实际用户或资产，从而使业务处理更加直观和有效。
处理非结构化链上内容，打标签：LLM 可以分析非结构化数据，如 Twitter 情感分析结果，将其标记为正面、负面或中性情感，从而帮助用户更好地理解社交媒体上的情感倾向。

自然语言解读数据：

计算核心指标：基于业务抽象，LLM 可以计算核心业务指标，如用户交易量、资产价值、市场份额等，以帮助用户更好地了解其业务的关键性能。
查询数据：LLM 可以通过 AIGC，理解用户意图，生成 SQL 查询，使用户能够以自然语言提出查询请求，而不必编写复杂的 SQL 查询语句。这增加了数据库查询的可访问性。
指标选择、排序和相关性分析：LLM 可以帮助用户选择、排序和分析不同的多个指标，以更好地理解它们之间的关系和相关性，从而支持更深入的数据分析和决策制定。
产生业务抽象的自然语言描述：LLM 可以根据事实数据，生成自然语言摘要或解释，以帮助用户更好地理解业务抽象和数据指标，提高可解释性，并使决策更具合理性。

3.5 目前用例

根据 LLM 自身的技术以及产品体验优势，它可以被应用到不同的链上数据场景，技术上从易到难可以将这些场景分成四类：

数据转换：进行数据增强、重构等操作，如文本摘要、分类、信息抽取。这类应用开发较快，但更适合通用场景，不太适合大量数据的简单批量化处理。
自然语言接口：将 LLM 连接知识库或工具，实现问答或基本工具使用的自动化。这可以用于构建专业聊天机器人，但其实际价值受其所连接的知识库质量等其他因素影响。
工作流自动化：使用 LLM 实现业务流程的标准化和自动化。这可以应用于较复杂的区块链数据处理流程，如解构智能合约运行过程、风险识别等。
协助机器人与助手辅助系统：辅助系统是在自然语言接口的基础上，集成更多数据源和功能的增强系统，大幅提高用户工作效率。
图 12：LLM 应用场景

3.6 LLM 的局限性

3.6.1 行业现状：成熟应用、正在攻克的问题以及尚未解决的挑战

在 Web3 数据领域，尽管已经取得了一些重要的进展，但仍然面临一些挑战。

相对成熟的应用：

使用 LLM 进行信息处理：LLM 等 AI 技术已成功用于生成文本摘要、总结、解释等工作，帮助用户从长篇文章、专业报告中提取关键信息，提高了数据的可读性和可理解性。
使用 AI 解决开发问题：LLM 已经应用于解决开发过程中的问题，例如替代StackOverflow 或搜索引擎，为开发者提供问题解答和编程支持。

有待解决与正在探索的问题：

利用 LLM 生成代码：行业正在努力将 LLM 技术应用于自然语言到 SQL 查询语言的转换，以提高数据库查询的自动化和可理解性。然而，过程中会有很多困难，比如在某些情境下，生成的代码要求极高的准确性，语法必须百分之百正确，以确保程序能够无 bug 运行，并获得正确的结果。难点还包括确保问题回答的成功率、正确率，以及对业务的深刻理解。
数据标注问题：数据标注对于机器学习和深度学习模型的训练至关重要，但在 Web3 数据领域，特别是处理匿名的区块链数据时，标注数据的复杂性较高。
准确性和幻觉（Hallucination）问题：AI 模型中幻觉的出现可能受多因素影响，包括有偏见或不足的训练数据、过度拟合、有限的上下文理解、缺乏领域知识、对抗性攻击和模型架构。研究人员和开发者需要不断改进模型的训练和校准方法，以提高生成文本的可信度和准确性。
利用数据进行业务分析和文章输出：将数据用于业务分析和生成文章仍然是一个具有挑战性的问题。问题的复杂性、需要精心设计的提示（prompt）、以及高质量的数据、数据量、减少幻觉问题的方法都是待解决的问题。
根据业务领域自动索引智能合同数据以进行数据抽象：自动为不同业务领域的智能合同数据建立索引以进行数据抽象仍然是一个未解决的问题。这需要综合考虑不同业务领域的特点，以及数据的多样性和复杂性。
处理时序数据，表格文档数据等更复杂的模态：DALL·E 2 等多模态模型非常擅长在文字生成图像、语音等常见模态。而在区块链以及金融领域需要特别地对待一些时序数据，而非简单地把文本向量化就能解决。联和时序数据与文本，跨模态联合训练等，是实现数据智能分析以及应用的重要研究方向。

3.6.2 为何只靠 LLM 不能完美解决区块链数据行业的问题

作为语言模型，LLM 更适用于处理对流畅度要求较高的场景，而在追求准确性方面，可能需要对模型进行更进一步的调整。在将 LLM 应用于区块链数据行业时，以下框架可提供一些参考。

图 13：区块链数据行业下 LLM 输出的流畅性、准确性和用例风险

在评估 LLM 在不同应用中的适用性时，关注流畅度和准确性是至关重要的。流畅度指的是模型的输出是否自然、通顺，准确性则表示模型的答案是否准确。这两个维度在不同应用场景中有不同的要求。

对于流畅度要求较高的任务，如自然语言生成、创意写作等，LLM 通常能够胜任，因为其在自然语言处理方面的强大性能使其能够生成流畅的文本。

区块链数据面临着数据解析、数据处理、数据应用等多方面的问题。LLM 拥有卓越的语言理解和推理能力，使其成为与区块链数据互动、整理和概括的理想工具。然而，LLM 并不能解决所有区块链数据领域的问题。

在数据处理方面，LLM 更适合快速迭代和探索性处理链上数据，不断尝试新的处理方法。然而，LLM 在生产环境中的详细核对等任务方面仍存在一些限制。典型的问题是 token 长度不够，无法应对长上下文的内容。耗时的 prompt，回答不稳定影响下游任务进而导致成功率不稳定的问题，以及执行大批量任务的效率不高。

其次，LLM 处理内容的过程中很可能出现幻觉问题。据估计，ChatGPT 的幻觉概率约为 15% 至 20%，而由于其处理过程的不透明性，很多错误难以察觉。因此，框架的建立和专家知识的结合变得至关重要。此外，LLM 结合链上数据还是有很多挑战：

链上数据实体类型多、数量庞大，以何种形式投喂给 LLM，有效地运用在具体的商业化场景，类似其他垂直行业，需要更多研究和探索。
链上数据包括结构化和非结构化数据，目前行业大多数数据解决方案，都是基于对业务数据的理解。解析链上数据的过程中，用 ETL 去过滤，清洗，补充和复原业务逻辑，进一步把非结构化数据整理为结构化数据，可以为后期多种业务场景提供更高效的分析。比如，结构化的 DEX trades，NFT marketplace transactions，wallet address portfolio 等，就具有前面提到的高质量，高价值，准确和真实等特点，可以给通用 LLM 提供高效的补充。

被误解的 LLM

LLM 可以直接处理非结构化数据，因此结构化数据将不再被需要？

LLM 通常基于海量文本数据预训练而来，天然适合处理各类非结构化的文本数据。然而，各个行业已经拥有大量结构化数据，尤其 Web3 领域中解析后的数据。如何有效的利用这些数据，增强 LLM，是一个行业的热门研究课题。

对于 LLM，结构化数据仍然具有以下的优势：

海量：大量的数据储存在各种应用背后的数据库和其他标准格式里面，特别是私有数据。每个公司和行业都还有大量 LLM 没有用于预训练的墙内数据。
已有：这些数据不需要重新生产，投入成本极低，唯一的问题是怎么用起来。
高质量和高价值：领域内长期积累的，蕴含专家的专业知识，通常都沉淀到了结构化数据里面，用于产学研。结构化数据的质量是数据可用性的关键，其中包括数据的完整性、一致性、准确性、唯一性和事实性。
高效率：结构化数据以表格、数据库或其他规范格式存储，模式是预先定义的，并且在整个数据集中保持一致。这意味着数据的格式、类型和关系都是可预测和可控的，使得数据的分析和查询更加简单和可靠。而且，行业已经有成熟的 ETL 及各种数据处理和管理工具，使用起来也更加高效和便捷。LLM 可以通过 API，把这些数据使用起来。
准确性和事实性：LLM 的文本数据，基于 token 概率，目前还不能稳定的输出确切的答案，产生的幻觉问题一直是 LLM 要解决的核心根本问题。对于很多行业和场景，会形成安全和可靠性问题，比如，医疗，金融等。结构化数据，正是可以辅助和矫正LLM 这些问题的一个方向。
体现关系图谱，和特定业务逻辑：不同类型的结构化数据，可以以特定的组织形式（关系型数据库，图数据库等），输入到 LLM，解决不同类型的领域问题。结构化数据使用标准化的查询语言（如 SQL），使得对数据进行复杂的查询和分析变得更加高效和准确。知识图谱 (Knowledge Graph) 可以更好地表达实体之间的关系，也更容易进行关联查询。
使用成本低：不用 LLM 每次重新从底层重新训练整个底座模型，可以结合 Agents 和LLM API 等 LLM 赋能方式，更快更低成本的接入 LLM。

目前市场上还有一些脑洞大开的观点，认为 LLM 在处理文本信息和非结构化信息方面的能力极强，只需将原始数据，包括非结构化数据，简单导入到 LLM，就能达到目的。这个想法类似于要求通用 LLM 解数学题，在没有专门构建数学能力模型的情况下，大多数 LLM 可能会在处理简单的小学加减题时出错。反而，建立类似数学能力模型，和图像生成模型的 Crypto LLM 垂直模型，才是解决 LLM 在 Crypto 领域更落地的实践。

4.2 LLM 可以从新闻、推特等文字信息推测内容，人们不再需要链上数据分析来得出结论？

LLM 虽然可以从新闻、社交媒体等文本中获得信息，但直接从链上数据中获得的洞察仍然是不可或缺的，主要原因有:

链上数据是原始的第一手资讯，而新闻和社交媒体中的信息可能存在片面性或误导性。直接分析链上数据可以减少信息偏差。尽管利用 LLM 进行文本分析存在理解偏差的风险，但直接分析链上数据可以减少误读。
链上数据包含全面的历史交互和交易记录，分析可以发现长期趋势和模式。链上数据还可以展现整个生态系统的全貌，如资金流向、各方关系等。这些宏观的洞察有助于更深入地理解状况。而新闻和社交媒体信息通常更零散且短期。
链上数据是开放的。任何人都可以验证分析结果，避免信息的不对称。而新闻和社交媒体未必都如实披露。文本信息和链上数据可以相互验证。综合两者可以形成更立体和准确的判断。

链上数据分析仍是不可或缺的。LLM 从文本中获取信息具有辅助作用，但不能取代直接分析链上数据。充分利用两者优势才能取得最佳效果。

4.3 利用 LangChain、LlamaIndex 或其他 AI 工具，在 LLM 的基础上构建区块链数据解决方案非常容易？

LangChain 和 LlamaIndex 等工具为构建自定义的简单 LLM 应用提供了便利，使快速搭建成为可能。然而，将这些工具成功应用于实际生产环境中涉及到更多的挑战。构建一个高效运行、保持高质量的 LLM 应用是一项复杂的任务，需要深入理解区块链技术和 AI 工具的工作原理，并有效地将它们整合在一起。这对于区块链数据行业来说，是一项重要但具有挑战性的工作。

在这个过程中，必须认识到区块链数据的特性，它要求极高的精准性和可重复校验性。一旦数据通过 LLM 进行处理和分析，用户对其准确性和可信度有很高的期望。这与 LLM 的模糊容错性之间存在着潜在的矛盾。因此，在构建区块链数据解决方案时，必须仔细权衡这两方面的需求，以满足用户的期望。

当前市场上，虽然已经有了一些基础工具，但这个领域仍在快速演进和不断迭代。类比于 Web2 世界的发展历程，从最初的 PHP 编程语言到更成熟、可扩展的方案如 Java、Ruby、Python，以及 JavaScript 和 Node.js 等，再到 Go 和 Rust 等新兴技术，都经历了不断的演变。AI 工具也在不断变化，新兴的 GPT 框架如 AutoGPT，Microsft AutoGen，及最近OpenAI 自己推出的 ChatGPT 4.0 Turbo 的 GPTs 和 Agents 等只是展示了未来可能性的一部分。这表明，区块链数据行业和 AI 技术都还有许多发展空间，需要不断努力和创新。

当前在应用 LLM 时，有两个陷阱需要特别注意：

期望值过高：很多人认为 LLM 可以解决一切问题，但实际上 LLM 有明显的局限性。它需要大量的计算资源，训练成本高昂，而且训练过程可能不稳定。对 LLM 的能力要有现实的期望，明白它在某些场景下表现出色，如自然语言处理和文本生成，但在其他领域可能无法胜任。
忽视业务需求：另一个陷阱是强行应用 LLM 技术，而不充分考虑业务需求。在应用 LLM 之前，务必明确具体的业务需求。需要评估 LLM 是否是最佳技术选择，并做好风险评估和控制。强调 LLM 的有效应用需要根据实际情况慎重考虑，避免误用。

尽管 LLM 在许多领域都具备巨大潜力，但开发者和研究者在应用 LLM 时需要保持谨慎，采取开放的探索态度，以找到更适合的应用场景并最大程度地发挥其优势。

关于Footprint Analytics

Footprint Analytics是一家区块链数据解决方案提供商。借助尖端的人工智能技术，我们提供 Crypto 领域首家支持无代码数据分析平台以及统一的数据 API，让用户可以快速检索超过 30 条公链生态的 NFT，GameFi 以及 钱包地址资金流追踪数据。

关于Future3 Campus

Future3 Campus是由万向区块链实验室和HashKey Capital共同发起的Web3.0创新孵化平台，重点聚焦Web3.0 Massive Adoption、DePIN、AI三大赛道，以上海、粤港澳大湾区、新加坡为主要孵化基地，辐射全球Web3.0生态。同时，Future3 Campus将推出首期5000万美金的种子基金用于Web3.0项目孵化，真正服务于Web3.0领域的创新创业。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
区块链
AI
大语言模型
Web3

--

Written by Future3 Campus
13 Followers

Empowering the Web3.0 Innovation. Incubation platform powered by Wanxiang Blockchain Labs and HashKey Capital

Follow

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:17.270 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型的程序思维方法".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Fail to load page content for Timeout 30000ms exceeded.

2024-03-04 22:03:18.342 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.101 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 200, completion_tokens: 3
2024-03-04 22:03:18.350 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型的程序思维方法".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

66個大型語言模型LLM經典論文

劉智皓 (Chih-Hao Liu)

·

Follow

12 min read
·
Dec 17, 2023

260

1

去年ChatGPT的發布，帶動了大型語言模型(Large Language Models, LLM)的風潮，這幾周更是進入了白熱化階段，除了有科技巨頭發布的GPT-4V、Gemini、Claude和Grok，開源模型更是百花齊放，包括了Llama 2、Mixtral 8x7B、Phi-2等等。所以今天我列了幾個我看過的經典LLM論文，這邊我會以時間順序列出，並概述每一篇的特點，那廢話不多說我們就開始吧！

1. Transformer
論文名稱：Attention is all you need
發布時間：2017/06/12
發布單位：Google、多倫多大學
簡單摘要：所有LLM的始祖，邁向NLP新時代的基礎架構
閱讀重點：self-attetion、positional encoding、per-layer complexity、sequential operations
中文摘要：傳統的序列轉換模型使用複雜的循環或卷積神經網絡，包括編碼器和解碼器。表現最好的模型會透過注意力機制連接編碼器和解碼器。而我們提出了一種新的簡單網絡結構，Transformer，完全基於注意力機制，不再使用循環和卷積。我們在兩個機器翻譯任務上進行實驗，發現這些模型在品質上的表現優越，並且更容易進行平行運算，訓練所需時間明顯減少。我們的模型在WMT 2014年英德翻譯任務上達到了28.4 BLEU，比現有最佳結果（包括整體模型）提高了超過2 BLEU。在WMT 2014年英法翻譯任務中，我們的模型在八個GPU上訓練3.5天後，取得了新的單模型最佳BLEU分數41.8，訓練成本僅為文獻中最佳模型的一小部分。我們展示了無論是在大量或有限的訓練數據下，Transformer在其他任務中的泛化能力，成功應用於英語組成句分析。
論文連結：https://arxiv.org/pdf/1706.03762.pdf
2. GPT-1
論文名稱：Improving language understanding by generative pre-training
發布時間：2018/06/11
發布單位：OpenAI
簡單摘要：autoregreesive Transformer始祖
閱讀重點：multi-layer Transformer decoder、autoregressive model
中文摘要：自然語言理解涵蓋眾多不同的任務，如文本蘊涵、問答、語義相似度評估和文件分類。儘管有豐富的未標記文本資料，但用於這些特定任務的標記數據稀缺，使得訓練有判別式的模型難以表現良好。我們證明通過對未標記文本的語言模型進行生成式預訓練，再對每個特定任務進行判別式微調，可以在這些任務上取得巨大進步。與以往方法不同，我們在微調期間利用任務感知的輸入轉換，實現有效的轉移，同時最大限度地減少對模型架構的更改。我們展示了我們方法在自然語言理解的眾多基準測試上的有效性。我們通用的任務無關模型在12個研究的任務中，有9個顯著優於專門為每個任務設計的判別式訓練模型表現。例如，在常識推理（Stories Cloze Test）上，我們實現了8.9％的改善，在問答（RACE）上為5.7％，在文本蘊涵（MultiNLI）上為1.5％。
論文連結：https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf
3. Model Card
論文名稱：Model Cards for Model Reporting
發布時間：2018/10/05
發布單位：Google、多倫多大學
簡單摘要：要發布模型時，我該寫什麼東西。
閱讀重點：Model Card的範例。
中文摘要：機器學習模型被廣泛應用於執行各種重要任務，如法律、醫療、教育和就業等領域。為了展示機器學習模型的預期使用情境，並減少其在不適合的情況下使用，我們建議釋出的模型應附上描述其性能特性的文件。在這篇論文中，我們提出了一個框架，稱為「模型卡」，以促進透明的模型報告。模型卡是附加在已訓練好機器學習模型的簡短文件，提供了在各種條件下的基準評估，比如跨不同文化、人口統計或表型群體和交叉群體的評估結果。模型卡還會公開模型預期使用的情境、性能評估程序的詳細訊息。雖然我們主要關注的機器學習模型，應用於電腦視覺和自然語言處理領域，但這個框架可以用於記錄任何已訓練的機器學習模型。為了確立這一概念，我們為兩個監督式模型提供了模型卡範例：一個是用於在圖像中檢測微笑表情的模型，另一個是用於檢測文字中有害評論的模型。我們提議模型卡是向負責任機器學習和相關人工智慧技術的民主化邁出一步，增加了對人工智慧技術表現的透明度。我們希望這項工作能鼓勵釋出訓練好的機器學習模型的人們，附上類似詳細的評估數字和其他相關文件。
論文連結：https://arxiv.org/pdf/1810.03993.pdf
4. BERT
論文名稱：BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
發布時間：2018/10/11
發布單位：Google
簡單摘要：autoencoding Transformer始祖，邁向NLP fine-tuning時代
閱讀重點：multi-layer bidirectional Transformer encoder、autoencoding model、masked token和next sentence predicition。
中文摘要：我們提出了一個名為BERT（從Transformer中得到的雙向編碼器表徵）的新語言表徵模型。與最近的語言表徵模型不同，BERT目標是從未標記文本中預訓練深度雙向表徵，同時在所有網路層上聯合考慮左右兩側的文本內容。因此預訓練的BERT模型只需進行一個額外的輸出層微調，就可以創建出各種任務的最新模型，例如問答和語言推理，而無需大幅修改特定任務的架構。BERT概念簡單且實驗證明其效果非常好。它在包括GLUE得分提升至80.5％（絕對改善了7.7個百分點）、MultiNLI準確度提升至86.7％（絕對改善了4.6個百分點）、SQuAD v1.1問答測試F1提升至93.2（絕對改善了1.5個百分點）和SQuAD v2.0測試F1提升至83.1（絕對改善了5.1個百分點）等11項自然語言處理任務中取得了新的最佳結果。
論文連結：https://arxiv.org/pdf/1810.04805.pdf
5. Transformer-XL
論文名稱：Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
發布時間：2019/01/09
發布單位：Google、卡內基麥隆大學
簡單摘要：讓Transformer可以吃更長的句子
閱讀重點：context fragmentation、segment-level recurrence mechanism、relative position embedding
中文摘要：Transformer模型在學習長期依賴性方面具有潛力，但在語言模型的情境下受到固定長度上下文的限制。我們提出了一種新穎的架構Transformer-XL，能夠在不干擾時間連貫性的情況下實現超越固定長度的依賴性。它包括一個分段層級的循環機制和一種新穎的位置編碼方法。我們的方法不僅能捕捉更長期的依賴性，還解決了上下文碎片化的問題。在結果中，Transformer-XL學習的依賴性比RNNs長80%，比原本的Transformer長450%，並在短序列和長序列上都表現更好，且評估過程中比基本的Transformer快了1800倍以上。特別值得注意的是，我們在bpc/perplexity上將enwiki8改進到了0.99，text8改進到了1.08，WikiText-103改進到了18.3，One Billion Word改進到了21.8，Penn Treebank改進到了54.5（無需微調）。當僅在WikiText-103上進行訓練時，Transformer-XL能夠生成具有數千個標記的合理連貫的新文章。
論文連結：https://arxiv.org/pdf/1901.02860.pdf
6. Adapter
論文名稱：Parameter-Efficient Transfer Learning for NLP
發布時間：2019/02/02
發布單位：Google、亞捷隆大學
簡單摘要：每多一個任務就要fine-tune一次好浪費，弄個小adapter吧
閱讀重點：bottleneck adapter module、adapter大小、parameter/performance trade-off
中文摘要：對於自然語言處理，微調大型預訓練模型是一種有效的遷移式學習方式。然而在有許多下游任務的情況下，微調是一件參數效率低的事情，因為每個任務都需要一個全新的模型。作為替代方案，我們提出了使用適配器模組進行遷移式學習。適配器模組使模型更加簡潔且易擴展；它們每個任務只添加了少量可訓練參數，新任務可以添加而無需重新處理先前的任務。原始網絡的參數保持固定，實現了高度的參數共享。為了展示適配器的效果，我們將最近提出的BERT Transformer模型應用到包括GLUE基準測試在內的26個不同的文本分類任務上。適配器取得了接近最佳表現的結果，而每個任務只添加了極少的參數。在GLUE測試中，我們的表現接近全面微調的水平，每個任務只增加了3.6%的參數，相比之下，全面微調則需要訓練100%的參數。
論文連結：https://arxiv.org/pdf/1902.00751.pdf
7. GPT-2
論文名稱：Language models are unsupervised multitask learners
發布時間：2019/02/24
發布單位：OpenAI
簡單摘要：不想fine-tune，我想要一個通用模型所有任務直接zero-shot
閱讀重點：multi-task pre-training、模型到底是達到generalization還是memorization
中文摘要：自然語言處理任務，如問答、機器翻譯、閱讀理解和摘要，通常使用特定任務的監督式學習來處理。我們展示了語言模型在沒有明確監督的情況下，學習名為WebText的數百萬網頁數據集。當語言模型在一個文檔加上一個問題的情境下，生成的答案在CoQA數據集上達到55的F1分數，與4個基準系統中的3個相匹配或超越，而不需要使用超過127,000個訓練範例。語言模型的容量對於zero-shot任務遷移的成功至關重要，增加容量能夠以對數線性方式提升跨任務的性能。我們最大的模型GPT-2是一個擁有15億參數的Transformer，在zero-shot設置下，在8個測試的語言模型數據集中有7個達到了最新的結果，但在WebText上仍然不夠充分。模型產生的樣本反映了這些改進，包含了連貫的文字段落。這些發現暗示了一條有前景的道路，即構建能夠從自然發生的範例中學習執行任務的語言處理系統。
論文連結：https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
8. UniLM
論文名稱：Unified Language Model Pre-training for Natural Language Understanding and Generation
發布時間：2019/05/08
發布單位：Microsoft
簡單摘要：讓我們把NLU和NLG預訓練統一吧
閱讀重點：pretrain task設計、包括bidirectional encoding、unidirectional decoding、sequence-to-sequence。
中文摘要：這篇論文介紹了一個新的統一預訓練語言模型（UNILM），能夠進行自然語言理解和生成任務的微調。該模型通過三種語言模型任務進行預訓練：單向、雙向和序列到序列預測。這種統一建模是通過使用共享的Transformer網絡和特定的自注意力遮罩來控制預測所依賴的內容實現的。UNILM在GLUE基準測試中與BERT相比表現優異，在SQuAD 2.0和CoQA問答任務上也有出色表現。此外UNILM在五個自然語言生成數據集上取得了新的最佳結果，包括將CNN/DailyMail摘要的ROUGE-L提高到40.51（絕對改善2.04），Gigaword摘要的ROUGE-L提高到35.75（絕對改善0.86），CoQA生成式問答的F1分數提高到82.5（絕對改善37.1），SQuAD問題生成的BLEU-4提高到22.12（絕對改善3.75），以及DSTC7基於文件的對話回應生成的NIST-4提高到2.67（人類表現為2.65）。
論文連結：https://arxiv.org/pdf/1905.03197.pdf
9. ERNIE
論文名稱：ERNIE: Enhanced Language Representation with Informative Entities
發布時間：2019/05/17
發布單位：北京清華大學、華為
簡單摘要：把知識圖譜一起整合在BERT上
閱讀重點：Structured Knowledge Encoding、Heterogeneous Information Fusion、Knowledgeable Encoder
中文摘要：神經語言表徵模型，例如在大規模文本語料庫上預先訓練的BERT，能夠從純文本中捕捉豐富的語義模式，並進行微調以持續提升各種自然語言處理任務的性能。但是現有的預訓練語言模型很少考慮將知識圖譜（KGs）納入其中，而KGs可以提供豐富的結構化知識事實，有助於更好地理解語言。我們認為KGs中的訊息性實體可以增強語言表徵的外部知識。所以我們同時利用大規模文本語料庫和知識圖譜來訓練一個增強語言表示模型（ERNIE），它能同時充分利用詞彙、句法和知識訊息。實驗結果表明，ERNIE在各種知識驅動任務上取得了顯著的改善，同時在其他常見的自然語言處理任務上與最先進的模型BERT相當。
論文連結：https://arxiv.org/pdf/1905.07129.pdf
10. XLNet
論文名稱：XLNet: Generalized Autoregressive Pretraining for Language Understanding
發布時間：2019/06/19
發布單位：Google、卡內基麥隆大學
簡單摘要：autoregressive和autoencoding的好處我全都要
閱讀重點：permutation language modeling、content和query stream attention、partial prediction、怎麼套用Transformer-XL
中文摘要：利用模型雙向上下文建模的能力，像BERT這樣基於去噪自編碼的預訓練方法比基於自回歸語言建模的方法表現更好。但是BERT依靠對輸入進行遮罩處理，忽略了遮罩位置之間的依賴關係，存在預訓練和微調之間的差異。鑑於這些優點和缺點，我們提出了XLNet，這是一種通用的自回歸預訓練方法，（1）通過最大化分解順序所有排列的期望概率來實現學習雙向上下文，（2）使用自回歸的形式克服了BERT的限制。此外XLNet融合了Transformer-XL的思想，在預訓練中做了整合。實驗結果顯示，在可比較的實驗設置下，XLNet在20個任務上表現優於BERT，其中包括問答、自然語言推理、情感分析和文件排序等。
論文連結：https://arxiv.org/pdf/1906.08237.pdf
11. RoBERTa
論文名稱：RoBERTa: A Robustly Optimized BERT Pretraining Approach
發布時間：2019/07/26
發布單位：Facebook(Meta)、華盛頓大學
簡單摘要：我用了更多資源、更猛的方法訓練一個更猛的BERT
閱讀重點：dynamic masking、next sentence prediction重要嗎。
中文摘要：語言模型的預訓練帶來了顯著的性能提升，但仔細比較不同方法的成效是具有挑戰性的事情。訓練過程耗費計算資源，且通常會使用不同大小的私有數據集，另外正如我們所展示的，超參數的選擇對最終結果有著顯著的影響。所以我們進行了一項BERT預訓練的複現研究，仔細測量了許多關鍵超參數和訓練數據大小對結果的影響。我們發現BERT是訓練不足的，實際上其可以超越其之後發表的每個模型的表現。我們最佳的模型在GLUE、RACE和SQuAD上取得了最先進的結果。這些結果凸顯了先前被忽視的設計選擇的重要性，並提出了對最近論文改進來源的疑問。
論文連結：https://arxiv.org/pdf/1907.11692.pdf
12. ALBERT
論文名稱：ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
發布時間：2019/07/26
發布單位：Google、Toyota
簡單摘要：我把BERT參數減少，然後加上了一個酷酷的自監督式學習
閱讀重點：factorized embedding parameterization、cross-layer parameter sharing、inter-sentence coherence loss
中文摘要：在預訓練自然語言表徵時，增加模型大小通常會提升後續任務的表現。但是當模型進一步增加時，由於GPU/TPU記憶體限制和訓練時間變長，進一步的提升會變得更加困難。為了解決這些問題，我們提出了兩種參數減少的技術，以降低記憶體消耗並增加BERT的訓練速度。全面的實驗證據顯示，我們提出的方法使模型與原始BERT相比更具可擴展性。我們還使用了一種自監督損失函數，專注於模型句子間的一致性，並展示它能穩定地幫助具有多句輸入的後續任務。因此我們最佳的模型在GLUE、RACE和SQuAD基準測試上取得了新的最先進結果，同時與BERT-large相比具有更少的參數。
論文連結：https://arxiv.org/pdf/1909.11942.pdf
13. DistilBERT
論文名稱：DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter
發布時間：2019/10/02
發布單位：Hugging Face
簡單摘要：利用知識蒸餾訓練更小的BERT。
閱讀重點：Teacher-Student的架構、distillation loss
中文摘要：隨著大規模預訓練模型在自然語言處理中變得更加普遍，將這些大模型應用在邊緣運算或有限計算資源的情況下仍然具有挑戰性。在這項工作中，我們提出了一種方法來預訓練一個較小的通用語言表徵模型，稱為DistilBERT，然後可以對其進行微調，使其在各種任務上表現的和大型模型一樣好。儘管大多數先前的工作都探討了使用蒸餾方法來構建特定任務模型，我們在預訓練階段利用知識蒸餾，並展示了可以將BERT模型的尺寸減少40%，同時保留了97%的語言理解能力並且速度提升了60%。為了利用大型模型在預訓練過程中學到的歸納偏差，我們引入了三重損失，結合了語言模型、蒸餾和餘弦距離損失，讓我們可以以更便宜的價格預訓練更小、更快、更輕的模型，並且在概念驗證實驗和在設備比較研究中展示了其在設備上計算的能力。
論文連結：https://arxiv.org/pdf/1910.01108.pdf
14. T5
論文名稱：Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
發布時間：2019/10/23
發布單位：Google
簡單摘要：把NLU和NLG全部都當成seq2seq任務來訓練吧
閱讀重點：input and output format、架構比較、預訓練任務目標、ensemble效果比較
中文摘要：遷移式學習在NLP中嶄露頭角，其指的是模型先在數據豐富的任務上進行預訓練，然後再微調用於後續任務，這種方式已成為一種強大的技術。遷移式學習的有效性催生了多種方法、理論和實踐。所以本文通過引入一個統一框架，將所有基於文本的語言問題轉換成文本到文本的格式，來探索NLP的遷移式學習技術。我們的系統性研究比較了數十種語言理解任務的預訓練目標、架構、無標註數據集、遷移式方法等因素。通過將我們探索的見解與規模和新的“巨大清理爬取語料庫”相結合，我們在許多涵蓋摘要、問答、文本分類等領域的基準測試中取得了最先進的結果。
論文連結：https://arxiv.org/pdf/1910.10683.pdf
15. BART
論文名稱：BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension
發布時間：2019/10/29
發布單位：Facebook(Meta)
簡單摘要：把BERT(encoder)跟GPT(decoder)拼起來不香嗎
閱讀重點：模型架構、pre-training任務設計、machine translation額外的encoder
中文摘要：我們提出了BART，一種用於預訓練序列到序列模型的去噪自編碼器。BART的訓練方式是（1）利用任意的雜訊函數破壞文本，以及（2）學習模型來重建原始文本。其使用了標準的基於Transformer的神經機器翻譯架構，其概念可以視為將BERT（因為具有雙向編碼器）、GPT（具有從左到右的解碼器）和許多其他近期預訓練方案的泛化。我們評估了多種加入雜訊的方法，發現通過隨機重排原始句子的順序以及使用一種新的內填充方案（將文本片段替換為單個遮罩標記）可以獲得最佳性能。另外BART在進行文本生成的微調時特別有效，對於理解任務也表現得相當良好。在GLUE和SQuAD上與RoBERTa的性能相匹配，在一系列摘要對話、問答和摘要任務上實現了新的最先進結果，在僅目標語言預訓練的情況下，ROUGE可以高達6。BART相比於後向翻譯系統為機器翻譯帶來了1.1 BLEU的提升。最後我們還通過BART框架內復制其他預訓練方案的消融實驗，以更好地衡量哪些因素最影響最終任務的表現。
論文連結：https://arxiv.org/pdf/1910.13461.pdf
16. Reformer
論文名稱：Reformer: The Efficient Transformer
發布時間：2020/01/13
發布單位：Google
簡單摘要：讓Transformer運算更快、使用記憶體更有效
閱讀重點：locality sensitive hashing attention、reversible Transformer、chunking
中文摘要：大型Transformer模型在許多任務上常常取得最先進的成果，但訓練這些模型，尤其是在處理長序列時，可能的成本過高。所以我們引入了兩種提高Transformer效率的技術。首先我們將點積注意力機制替換為局部敏感哈希，將其複雜度從O(L²)降低到O(Llog L)，其中L為序列長度。此外我們使用可逆的殘差層代替標準的殘差層，這使得在訓練過程中只需要存儲激勵值一次，而不是N次，其中N是層數。最終產生的模型，Reformer，在長序列上的效能與Transformer模型相當，同時具有更高的記憶體效率和更快的速度。
論文連結：https://arxiv.org/pdf/2001.04451.pdf
17. Scaling Laws
論文名稱：Scaling Laws for Neural Language Models
發布時間：2020/01/23
發布單位：OpenAI
簡單摘要：最早的LLM規模定律全面分析
閱讀重點：算力、資料、參數大小對模型性能影響、L(N, D) Equation、critical batch size、Early Stopping Step
中文摘要：我們研究了語言模型在交叉熵損失上的實證擴展規律。損失會隨著模型大小、數據集大小和用於訓練的計算量呈現冪律變化，某些趨勢跨度超過七個量級。其他如網絡寬度或深度等架構細節，在很大範圍內影響較小。另外我們提出簡單的方程式控制了過擬合與模型/數據集大小之間的依賴關係，以及訓練速度與模型大小之間的依賴關係。這些關係讓我們能夠確定固定計算預算的最佳分配方式，讓較大的模型能更有效地利用樣本。因此最有效的計算高效訓練方式涉及在相對較少的數據上訓練非常大的模型，在收斂之前明顯停止訓練。
論文連結：https://arxiv.org/pdf/2001.08361.pdf
18. Dense Passage Retrieval (DPR)
論文名稱：Dense Passage Retrieval for Open-Domain Question Answering
發布時間：2020/04/10
發布單位：Facebook(Meta)、華盛頓大學、普林斯頓大學
簡單摘要：RAG的前身，弄個效率更高的檢索模型來對應開放式問題吧
閱讀重點：dual-encoder、dot-product similarity、positive and negative passages
中文摘要：開放領域的問答依賴於有效的段落檢索，以選擇候選文本，傳統的稀疏向量空間模型（如TF-IDF或BM25）是已被實踐的方法。在這項工作中，我們展示了檢索可以僅使用密集表徵來實現，透過一個簡單的雙編碼器框架，從少量問題和段落中學習嵌入。在廣泛的開放領域問答數據集上評估時，我們的密集檢索器在前20個段落檢索準確度方面表現優於Lucene-BM25系統，絕大部分提升9%-19%絕對值，並幫助我們的端到端問答系統在多個開放領域問答基準上建立了新的最先進水平。
論文連結：https://arxiv.org/pdf/2004.04906.pdf
19. Longformer
論文名稱：Longformer: The Long-Document Transformer
發布時間：2020/04/10
發布單位：Allen Institute
簡單摘要：讓self-attention從次方減到線性複雜度
閱讀重點：sliding window attention、dilated sliding window、global attention
中文摘要：Transformer-based模型由於其自注意力操作的特性，無法處理長序列，其計算複雜度隨著序列長度呈平方級數增長。為解決此限制，我們引入了Longformer，其注意力機制能夠線性地隨著序列長度增長，輕鬆處理包含數千個標註或更長的文件。Longformer的注意力機制可直接替換標準的自注意力機制，結合局部窗口注意力和面向任務的全局注意力。另外與以往長序列Transformer相比，我們在字符級語言模型方面評估了Longformer，在text8和enwik8上取得了最先進的成果。與大多數以往工作不同的是，我們還對Longformer進行了預訓練，並在多個下游任務上進行微調。我們的預訓練Longformer在長文檔任務上一貫優於RoBERTa，並在WikiHop和TriviaQA上設定了新的最先進成果。最後我們引入了Longformer-Encoder-Decoder（LED），這是Longformer的變體，用於支持長文檔的生成序列到序列任務，在arXiv摘要數據集上展示了其有效性。
論文連結：https://arxiv.org/pdf/2004.05150.pdf
20. Retrieval-Augmented Generation (RAG)
論文名稱：Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
發布時間：2020/05/22
發布單位：Facebook(Meta)、倫敦大學學院、紐約大學
簡單摘要：結合資料庫檢索，讓LLM變得更強、回答訊息更正確
閱讀重點：RAG-sequence和RAG-token model，retriever和generator架構
中文摘要：大型預訓練語言模型已證實在其參數中儲存事實知識，並在微調後在下游自然語言處理任務中取得了最先進的成果。然而它們訪問和精確操作知識的能力仍然有限，在知識密集型任務上，它們的表現落後於特定任務架構。此外為其決策提供出處訊息和更新其世界知識，仍是開放性的研究問題。雖然具有可微訪問機制的預訓練模型，能夠使用明確的非參數化記憶，但到目前為止，這些模型僅用於探討摘要性的下游任務。所以我們探索了一種用於檢索增強生成（RAG）的通用微調方法 — 這些模型結合了預訓練的參數化和非參數化記憶以進行語言生成。在RAG模型中，參數化記憶是一個預訓練的seq2seq模型，而非參數化記憶是維基百科的密集向量索引，其通過預訓練的神經檢索器進行訪問。另外我們比較了兩種RAG形式，一種在整個生成序列中條件於相同的檢索段落，另一種可以每個標註使用不同的段落。我們對一系列知識密集型自然語言處理任務進行了微調和評估，在三個開放領域的問答任務中取得了最先進的成果，優於參數化seq2seq模型和特定任務的檢索和提取架構。對於語言生成任務，我們發現RAG模型生成的語言更加具體、多樣且具有事實性，超過了最先進的僅參數化seq2seq基線。
論文連結：https://arxiv.org/pdf/2005.11401.pdf
21. GPT-3
論文名稱：Language Models are Few-Shot Learners
發布時間：2020/05/28
發布單位：OpenAI
簡單摘要：別再玩fine-tune了，in-context learning和錢錢才是王道
閱讀重點：limitations、不使用fine-tune原因、data contamination、in-context learning
中文摘要：最近的研究表明，通過對大量文本進行預訓練，然後在特定任務上進行微調，可以在許多自然語言處理任務和基準測試中取得顯著進展。儘管在架構上通常是通用任務的，但這種方法仍需要數千甚至數萬個特定任務的微調數據集。相比之下，人類通常可以僅憑幾個例子或簡單的指令來完成新的語言任務，而當前的自然語言處理系統在這方面仍然存在很大挑戰。所以在這裡，我們擴展語言模型，來大幅改善了通用任務、少量樣本的性能，有時甚至達到了與先前最先進的微調方法相競爭的水平。具體而言，我們訓練了GPT-3，其是一個自回歸語言模型，具有1750億參數，比之前的非稀疏語言模型多10倍，並在少樣本情況下測試其性能。對於所有任務，GPT-3在沒有任何梯度更新或微調的情況下應用，也就是任務和少量範例的情境，純粹通過與模型的文本交互來指定。GPT-3在許多自然語言處理數據集上表現出色，包括翻譯、問答和填空任務，以及一些需要即時推理或領域適應的任務，比如拼字、在句子中使用新詞或進行3位數的算術運算。但是同時我們還發現了一些數據集，GPT-3的少樣本學習仍然存在困難，以及一些GPT-3面臨與在大型Web文集上訓練相關的方法問題。最後我們發現GPT-3可以用來生成新聞文章樣本，人類評估者很難將其與人寫的文章區分。另外我們也討論了這一發現和GPT-3整體對社會的更廣泛影響。
論文連結：https://arxiv.org/pdf/2005.14165.pdf
22. Big Bird
論文名稱：Big Bird: Transformers for Longer Sequences
發布時間：2020/07/28
發布單位：Google
簡單摘要：把序列的二次依賴降到線性，來處理更長的context
閱讀重點：sparse attention、graph sparsification problem、Turing complete、internal和extended transformer construction
中文摘要：BERT是一種基於Transformers的模型，在自然語言處理方面表現優異。然而它們的核心限制之一是由於全注意力機制導致的序列長度對記憶的二次依賴。為了克服這個問題，我們提出了BigBird，它使用了稀疏注意力機制，將這種二次依賴減少為線性。使外我們證明了BigBird是序列函數的通用逼近器並具有圖靈完備性，並保留了二次全注意力模型的這些特性。透過我們的理論分析，我們發現了具有複雜度O(1)全局標記（例如CLS）在稀疏注意力機制中涵蓋整個序列部分的一些優點。這種稀疏注意力可以處理比以前相似硬體設置所能處理的序列長度多8倍的文本。而由於處理更長範圍的能力，BigBird在問答和摘要等各種自然語言處理任務上顯著提升了性能。最後我們還提出了在基因組數據上的新應用。
論文連結：https://arxiv.org/pdf/2007.14062.pdf
23. AutoPrompt
論文名稱：AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts
發布時間：2020/10/29
發布單位：加州大學爾灣分校、加州大學柏克萊分校
簡單摘要：使用梯度搜尋自動產生prompt效果有時甚至比fine-tune好
閱讀重點：gradient-based prompt search、automating label token selection
中文摘要：預訓練語言模型的卓越成功激勵了對這些模型在預訓練期間所學習的知識類型的研究。將任務重新設定為填空問題（例如，完形填空測試）是評估此類知識的自然方法，但編寫適合提示，仍受限於人工處理和猜測。所以為了解決這個問題，我們開發了AutoPrompt，一種基於梯度引導搜索的自動方法，用於創建各種任務的提示。使用AutoPrompt，我們展示了遮罩語言模型（MLMs）具有在沒有額外參數或微調的情況下進行情感分析和自然語言推理的潛力，有時性能與最近最先進的監督式模型相當。我們還展示了我們的提示從MLMs中獲得比LAMA基準測試上手動創建的提示更準確的事實知識，以及MLMs可以比監督式關係提取模型更有效地用作關係提取器。這些結果表明，自動生成的提示是現有探測方法的無參替代方案，隨著預訓練語言模型變得更加複雜和強大，這可能成為微調的替代方案。
論文連結：https://arxiv.org/pdf/2010.15980.pdf
24. LM-BFF
論文名稱：Making Pre-trained Language Models Better Few-shot Learners
發布時間：2020/12/31
發布單位：普林斯頓大學、麻省理工
簡單摘要：用prompting讓一般模型few-shot fine-tune也可以表現很好
閱讀重點：prompt-based fine-tuning、prompting format、automatic prompt generation
中文摘要：最近的GPT-3模型僅透過自然語言提示和少量任務演示作為輸入內容就達到了驚人的少數樣本效能。受到這些發現的啟發，我們在更實際的情境中研究少樣本學習，使用了計算效率高的較小語言模型進行微調。所以我們提出了LM-BFF — 更好的少樣本語言模型微調，這是一套用於在少量標註範例上微調語言模型的簡單且互補的技術。我們的方法包括（1）基於提示的微調，以及自動化提示生成的新型流程；和（2）一種精緻的策略，動態且選擇性地將演示整合到每個上下文中。最後我們對各種NLP任務進行了系統性評估，分析了少樣本的效能，包括分類和回歸。我們的實驗表明，我們的方法結合在這種資源有限的情況下明顯優於標準的微調程序，效能提升高達30%，平均提升率為11%。我們的方法對任務資源和領域專業知識做出了最小的假設，因此對於少樣本學習來說，是一種強大且無關任務的方法。
論文連結：https://arxiv.org/pdf/2012.15723.pdf
25. Prefix-Tuning
論文名稱：Prefix-Tuning: Optimizing Continuous Prompts for Generation
發布時間：2021/01/01
發布單位：史丹佛大學
簡單摘要：不fine-tune整個模型了，我們來針對特定任務優化prefix
閱讀重點：Prefix-tuning在autoregressive LM和encoder-decoder模型、與prompting關聯性
中文摘要：這篇論文提出了「前綴微調」，這是在自然語言生成任務中的一種輕量級替代方法，與微調不同的是，它凍結了語言模型參數，但優化了一個小的特定任務連續向量（稱為前綴）。前綴微調靈感來自提示，讓後續的標記可以關注這個前綴，就像它是「虛擬標記」一樣。我們將前綴微調應用於表格生成和摘要生成任務，發現通過只學習0.1%的參數，前綴微調在完整數據設置下獲得了可比的性能，在少量數據情況下優於微調，並在訓練過程中未見的主題的範例中表現更好。
論文連結：https://arxiv.org/pdf/2101.00190.pdf
26. Switch Transformers
論文名稱：Scaling to Trillion Parameter Models with Simple and Efficient Sparsity
發布時間：2021/01/11
發布單位：Google
簡單摘要：用Mixture of Experts架構可以有效設計更大的模型
閱讀重點：mixture of experts、switch routing、distributed switch implementation、scaling properties


2024-03-04 22:03:22.645 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.126 | Max budget: $10.000 | Current cost: $0.025, prompt_tokens: 7906, completion_tokens: 360
2024-03-04 22:03:22.651 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "改进大型语言模型在数值计算中的准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

ZK Section 9是什么？

Olivia

·

Follow

Published in

Cortex Labs

·
11 min read
·
Dec 5, 2022

大数据的爆炸式增长及其可用性推动了人工智能（AI）的发展。但人工智能模型在应用于现实世界的场景时需要格外谨慎，因为人工智能模型可能在关键应用中造成不正确或误导性的结果。人工智能模型的执行也会占用过多的资源，包括内存、磁盘和CPU/GPU。更不用说，在大多数情况下，结果本身不能被复制验证。所有的不足导致开发人员找到了一种被称为模型量化的通用解决方案。在量化过程之后，人工智能模型可以重现执行，用于推理。有了零知识证明（ZKP）系统之后，人工智能模型甚至可以在恒定的时间内快速地对结果进行验证。

目前，zk-SANRKS 的证明时间太慢，无法应用于现实世界的人工智能使用，许多项目一直在努力解决这个问题。 vCNN[1] 提出了一种新的高效可验证卷积神经网络框架，以提高 2020 年的证明性能。 ZEN[2] 团队提出了一种 SIMD 编译器优化，可以在大型有限域元素中编码多个 8 位整数，而不会产生压倒性的提取成本。同时，zkCNN[3] 创建了一个 ZKP 方案，允许 CNN 模型的所有者向其他人证明模型确实可以计算数据样本的预测，而不会泄露有关模型本身的任何信息。 Mystique[4] 提出了一种改进的用于矩阵乘法的 ZK 协议，与最先进的技术相比，它产生了 7* 的改进。并且在 2021 年，zk-ml[5] 发布了一个实现 zk-SNARK 电路的演示，其中证明了私有模型可以在公共数据集下具有一定的准确性。 2022 年，著名的 zk-SNARK 语言 circom 在 circomlib-ml[6] 和 zk-mnist[7] 中创建了机器学习库，用于基于区块链 DApp 的手绘数字识别。

AIGC设计

AIGC，也被称为AI-Generated Content，最近开始流行起来。该服务提供基于人工智能和深度学习的文本到图像生成功能。 DALL-E 2、Stable Diffusion 和 Midjourney 等项目都在 AIGC 上工作，侧重点略有不同。 CortexLabs 认为，如果我们能够将这些 AI 模型带入 Web3 的世界，将会大有裨益。

三个关键的利益相关者（AI 创造者、ML 工程师、ZKP 开发者）目前不互相交谈。但AI + ZKP + Blockchain 合作意义重大。

AI 艺术越来越受欢迎，AI 电影赢得了主要的国际奖项，但 AI 创作者缺乏对 Web3 的指导。同时，机器学习模型很难训练并产生惊人的结果。此外，ML 工程师不了解将算法转换为区块链友好格式的方法和要求。最后，ZKP 开发人员缺乏对 AIGC 模型功能和性能/生态系统/采用差距的可见性。

在 ETHSANFRANCISCO 2022 竞赛中，我们提出了 ZK Section 9，用于链上人工智能内容生成（AIGC）和 Succinct ZK Proofs。在撰写本文时，我们赢得了以下奖项：

ETHSanFrancisco 入围

ENS 的集成赏金

乐观主义的前 10 名已部署

通过ZK Section 9，可以用AI模型生成图像，用ZKP证明，将输出内容提交到区块链合约上。区块链可以轻松验证图像是由作曲家生成的。对于 CortexLabs，ZK Section 9 是进入 zkCVM 的主要基石：一个完整​​的链上 AI 模型的 zkRollup 解决方案。

这是演示文稿：https://docs.google.com/presentation/d/1CIxGfM_oySgWkgdNZqh-hoeH8C8zJDxnEpHx_VK6-KQ/。

机器学习模型庞大而多样，对于复杂的模型来说是巨大的，例如FastBERT[1]：~1800 MFLOPS（百万浮点运算），模型类型不同，例如自然语言处理、CNN、GAN。 ZKP 很难生成或操作：仪式、贡献、信标等。并且不要忘记速度。将庞大且不同的 AI 模型转换为 ZKP 友好格式是一项具有挑战性的工作。 Translator和后续的链上AI模型证明带来了几个需要解决的问题，我们已经开始攻克难关，虽然到现在还不完善。更多解决方案细节将在下一节介绍。

重点

正如开头提到的，从 AI 模型到 ZKP 电路的转换对开发人员来说一直是一个挑战。有很多要点要谈。

模型量化

多年来，人工智能量化得到了发展和优化。 Int8 量化已成为内存、计算资源和功率有限的流行方法。量化趋势不仅针对 TensorFlow、PyTorch 和 TVM 等机器学习框架，也针对硬件工具链。例如，来自 Coral 的 USB 加速器 TPU，具有 int8 精度的推理设备，包括 Intel 加速 DL Boost 指令，NVIDIA TensorRT，Xilinx DNNDK，以及许多其他用于机器学习的 int 边缘设备。

这些要求可能相当大，并且已经进行了大量研究。但是没有通用的一体化量化框架方案。许多目标设备和框架已经应用于模型推理，但每个执行者对量化目标的关注点不同。大多数量化甚至不是用于加速目的的全整数。

TVM 专注于目标设备部署，包括量化。 TVM 的内部中继表示是量化模型的起点。它的前端可以连接许多 ML 框架，包括 ONNX 和 PyTorch。

因此，我们使用 PyTorch 来训练 AIGC 模型并将其转换为 TVM IR 表示。然后，我们量化模型并将其转储到磁盘中。

翻译器

预发的ZKML论文或项目几乎都是model-specified schemes，zk-SNARKS的实现多种多样，无法适配任意AI模型。所以我们设计了一个统一的模型来绕过翻译程序：

从 TVM 中间中继 IR 解析，它是从 PyTorch、TensorFlow 等其他模型框架生成的。

构造一个临时模型表示，它可以转储到磁盘或从磁盘加载。

为 zk-SNARK 生成一致的 circom 代码。

深入研究翻译器，你会发现事情并没有那么简单。解析器应该接受从 TVM QAT 模型转储的任意 IR 表示。很难在模型通用性和误差容忍度之间取得平衡。至于自建的内部符号，我们参考了 MxNet 符号图表示，这种表示很容易和可扩展地应用模型转换。

大多数工作负载位于 circom 生成器处。首先，解析所有现有的 circom ML 运算符并存储有关运算符的必要信息，例如依赖文件路径、运算符参数和输入/输出。然后是时候将最后一个内部符号映射到正确的 circom 运算符生成器。符号和生成器不是一对一的映射，我们必须为所有支持的运算符编写有效的映射规则。最后是将适当的 circom 代码注入模板。

Circom 机器学习库

在此竞争案例中，仅量化整数目标是 ML circom 运算符，类似于英特尔 DL Boost 指令。我们参考 cvm-runtime 编写 ML-complete circom 运算符。 ZKP circom 约束与 CVM 运营商的设计略有不同，但基本相同。

此外，我们为 circom ML 运算符实现了一个不完整的推理引擎。 circom 程序正确性验证所必需的。

ZKP优化

ZKP 约束太大，无法在有限的时间内生成证明。以前的论文设计了很多类似SIMD的方法。但由于游戏时间限制，这些优化没有被考虑。我们在模型翻译器中进行了尝试，以减少生成的 circom 中的约束。

合约优化

最后一步，还有一个问题需要解决。那就是区块链上的合约 Gas limit。以太坊区块最大 Gas 限制为 8000K，以避免图灵停机和区块同步延迟问题。但是一个普通的AIGC模型生成32*32的图像尺寸是远远不够的。有几种解决方案：一种是像ZEN一样使用SIMD将许多输出元素嵌入到一个字段中。另一个是将模型输出截断为不同的部分，并在许多块中分别部署合约。我们尝试了后一种方法。

未来的工作

我们在 AIGC 的设计上做了一些关键的创新，但还不足以达到最终的目标。由于时间限制，有些点实现了，有些被忽略了或者不够完善。在这里，我们列出了一些可扩展的作品，这些作品可以在未来扩展。

ZK 友好量化

在 ZK 第 9 节项目中，量化应用了 TVM 和 PyTorch 的内部量化感知训练 (QAT) 方法。 QAT target是为机器学习加速器等特定设备设计的，这种设计不能很好地适应零知识证明。我们必须在我们的翻译器中制作一个临时符号表示，以便将许多融合通道应用于 ZK 兼容量化。这些通道可能包括批量大小调整、circom 运算符的形状适配器、更紧凑的常量融合等。

这些现有的 ML 框架具有不同的后端表示和不同的实现。对于我们统一的量化目标，我们希望统一模型中间表示 (IR) 成为现实。如果没有，我们就选择普适性最好的，足够稳定的，容量足够的。那么ONNX就摆在我们面前了。我们之前选择 NNVM 是因为它是最古老、最稳定的机器学习后端。然而，出于灵活性和容量目的，大多数现代 AI 框架都放弃了它并接受 ONNX 兼容方案作为表示。

至于量化过程，许多论文已经就此主题进行了研究。量化根据量化的场合和代价主要分为量化感知训练（QAT）和训练后量化（PTQ）。 CortexLabs 在 MRT 中使用了 PTQ 方法，并在 int32 最大量化上得到了不错的精度损失。将来，将 PTQ 从 MxNet 转换为 ONNX 格式是必要的，对于 QAT 实现也是如此。

推理机

在这个项目中，我们用python做了一个粗略的推理引擎。该引擎以 NumPy 格式和一些 MxNet ndarray 参考代码编写。由于缺乏代码细节检查和测试数据，此实现不足以进行交叉验证。幸运的是，CortexLabs 已经发布了一个经过良好测试的纯整数推理引擎：cvm-runtime，它是用 C++ 编写的，并使用 CPU、GPU 和形式化版本实现。未来，更多的测试用例和算子将被应用到这个推理引擎中，以提高安全性和可扩展性。

优化

ZKP 产生的约束自然是太大了，这对 ZKP 应用来说是个大问题。 ZKP 生成的约束数越多，ZKP 证明过程所花费的时间和计算资源就越多。 AI模型中一个简单的线性层会导致~10M的约束，后续的snarkJS证明过程在96核2.7GHz CPU、1.5T内存的机器上几乎消耗200G内存和一个小时的证明时间！此外，一个朴素的 ResNet 有 18 层，层约束之间的关系是乘法而不是加法。因此优化势在必行，幸运的是，之前的研究人员已经在这些方面付出了努力。

SIMD[2]

将多输入元素嵌入到一个大的 int256 字段中。这将使用搁浅编码进行矩阵乘法。

符号位分组[2]

使用 unsigned int 量化而不是整数，这种量化对 R1CS 更友好。 ZKP使用椭圆曲线密码学（ECC）生成证明，所有运算数据均为256位无符号整数。有符号的算子可以申请ZKP，但是约束会比无符号的大很多。

基于余数的验证[2]

有时除法运算符在 AI 模型中无法避免，它比加法、减法或乘法更复杂。使用一个额外的矩阵R来存储除法余数，并利用这个余数来避免除法。

项目架构

本节我们简单介绍一下项目架构，GitHub目录结构如下：

.
├── circuits/
│ ├── Arithmetic.circom
│ ├── circomlib/
│ ├── circomlib-matrix/
│ ├── operators
│ └── util.circom
├── contracts/
├── frontend/
├── integer_only_gan/
├── main.py
├── python/
└── README.md

interger_only_gan。

模型翻译器和推理引擎位于`python`中，cmd是`main.py`，使用command -h打印用法。

Circom ML 运营商位于电路/运营商。

前端演示位于 infrontend。

区块链合约调试和部署代码位于合约中。

未来的应用

我们这次比赛的目标是AIGC，但应用的未来远不止于此。就像 AI 模型的无限空间一样，我们的项目对扩展区块链的能力有着深远的影响：

（显示）视觉模型 -> AIGC

语言模型 -> 聊天机器人，写作助手

线性模型和决策树 -> 欺诈检测，Sybil 攻击预防

多模态模型 -> 推荐系统

并考虑了一些场景供参考：

将机器学习模型转换为零知识证明，使欠发达国家的人们能够通过链上 AIGC 或 ZK-ML 增强的无信任自由职业者创收。

共识中的治理技术很棘手。我们的工具可以通过允许基于 ML 的方法来增强现有的投票和女巫抵抗技术：想象一个由神经网络驱动的自我进化的 DAO 智能合约。

DEX 中的清洗交易检测器。

可证明的生物识别 ID。就像在世界币中一样。

可以验证链下世界数据的 AI 预言机。比如步数、健康数据、环境数据等。

人工智能竞赛。人们可以先提交他们的模型权重哈希，然后再显示输入。

GameFi NPC。我们可以使用 AI 角色来代替普通的老式脚本 NPC。

动态代币经济学。通过 AI 控制的代币经济学，我们可以拥有可能更好的算法稳定币。

AI DAO。 AI 可以参与 DAO 的决策。

自动交易员。尽管链上人工智能在与现实世界对冲基金的竞争中很可能会失败，但它可以成为一个展示。

DeFi 中的反欺诈。就像贷款协议和保险协议一样。

NFT。就像我们在这个项目中构建的一样。

自我进化的区块链。最终，ZKML 可用于根据收集的数据确定区块链的关键参数，例如区块间隔、区块大小和区块奖励。

更多的可能性在你的想象中。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
中文
人工智能
AI
Blockchain
Cortexlabs
Written by Olivia
94 Followers
·
Editor for 

Cortex Labs

Follow
More from Olivia and Cortex Labs

Olivia

in

Cortex Labs

一文读懂什么是ZK-Rollup?
区块链技术为个人和企业进行交易创造了新的信任基础，然而，从第一天起就面临一个基本问题 — 交易率低。比特币只支持每秒7次交易（TPS），而以太坊支持15次TPS。在如此低的TPS下，很难支持大规模的应用。这实质上创造了一个瓶颈，当有大量交易时，网络会被堵塞，导致交易费暴涨。
5 min read
·
Jan 25, 2022

5

Olivia

in

Cortex Labs

DeFi科普系列之（一）：Uniswap到底是怎么运转的？
作者：BisadeAsolo
12 min read
·
Mar 21, 2020

6

Olivia

in

Cortex Labs

DeFi科普系列之（三）深入理解Synthetix如何玩转合成资产
原文链接：
15 min read
·
May 9, 2020

24

Olivia

in

Cortex Labs

带你深刻理解MakerDAO运行原理：全面复盘312暴跌后的清算、拍卖、治理机制
原文链接：
21 min read
·
Apr 13, 2020

65

See all from Olivia
See all from Cortex Labs
Recommended from Medium

Editor @ Babylon

in

BabylonChain.io

Bitcoin Staking Guide for Babylon Testnet
The aim of this guide is to prepare you to participate in the staking process on the Babylon platform. The BTC staking web application…
7 min read
·
5 days ago

927

17

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Lists
Generative AI Recommended Reading
52 stories
·
781 saves
What is ChatGPT?
9 stories
·
310 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
322 saves
Natural Language Processing
1253 stories
·
733 saves

Ronan

in

Collab+Currency

Running Bittensor
By: Ronan Broadhead x Derek Edwards
25 min read
·
6 days ago

171

1

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

20K

574

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1071

Gowtham Oleti

Apps I Use And Why You Should Too.
Let’s skip past the usual suspects like YouTube, WhatsApp and Instagram. I want to share with you some less familiar apps that have become…
10 min read
·
Nov 15, 2023

18.6K

327

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:23.879 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.159 | Max budget: $10.000 | Current cost: $0.033, prompt_tokens: 10070, completion_tokens: 692
2024-03-04 22:03:23.882 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "使用大型语言模型进行数值计算的挑战".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

揭示零样本预测的机制：利用机器学习模型来理解大型语言模型（LLM）的决策过程

Ray Mi

·

Follow

May 31, 2023
引言

当代的机器学习领域，像ChatGPT这样的大型语言模型（LLM）正日益受到关注。它们在知识库、智能搜索机制、聊天机器人和内容创作等各种应用中展现出巨大的潜力。

在机器学习空间中，一个常见的挑战是获取用于验证假设和假定的高质量、代表性的数据。由于高成本、有限的可用性、数据清洁度问题、潜在的偏见以及安全和隐私方面的顾虑等多种障碍，收集这样的数据可能是艰巨的任务。

在与众多客户的讨论中，我注意到人们对于利用ChatGPT和其他LLM的担忧。这些担忧大多源于安全和隐私考虑，导致许多组织选择不使用这些模型。

我与许多客户谈过，了解他们公司对ChatGPT和LLM的看法，大多数公司因为安全和隐私的担忧而禁止使用ChatGPT。

由于将数据与LLM相连接是困难的，为什么我们不利用内容创作的能力来生成合成数据，并将这些数据作为机器学习项目的输入呢？

在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。简而言之，该模型利用其训练时所学的知识进行预测，并在很少或没有上下文的情况下做出假设。

在本文中您将看到：

如何设计正确的提示来从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测）。
创建合成数据并实施提示策略，以获得大量观察结果的回应。
利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策的基本原理。

本文是一系列多个实验中的第一篇，使用相似的业务案例进行演示。未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与业务逻辑和现有流程更紧密地对齐。请随我们一起踏上这个激动人心的大型语言模型潜力开发之旅，敬请关注。

应用案例

在加入DataRobot之前，我在汇丰银行担任全球风险分析经理/副总裁。我的主要职责是利用机器学习优化交易监测系统，并加强我们的反洗钱（AML）框架。为了说明我的工作，我将以AML为例。

什么是洗钱？

洗钱是指通过一系列复杂的银行转账或商业交易来掩盖非法获取资金的来源的非法过程。整个洗钱过程的方案以一种模糊且间接的方式将“洗净”的资金返还给洗钱者。

为什么洗钱是一个难题？

联合国的研究表明，全球洗钱金额估计占全球GDP的2–5%。 随着交易监测能力的成本上升以及监管压力增加，要求个人对合规程序失败承担更多责任，许多组织现在正在寻求突破性技术来解决这些挑战。

理解交易监测框架及其挑战：

简单来说，交易监测过程始于数据，其中包括交易细节和客户资料。银行然后在其交易监测系统（TMS）中应用业务规则。系统监测交易行为并生成一批可能可疑的警报。 然后，由专家团队手动调查这些警报，以确定它们是否真正可疑或仅仅是误报。这个过程可能具有挑战性且耗时，这就是创新技术可以在提高效率和效果方面发挥关键作用的地方。

机器学习如何帮助？

机器学习可以在这个过程中提供巨大的帮助。它可以利用历史交易数据、客户信息和过去的调查结果（无论是真警报还是误报）来预测每个新警报的风险水平。然后可以利用这些信息在手动调查之前对警报进行优先级排序。这不仅简化了流程，还确保及时处理最可能造成损害的问题。

大型语言模型（LLM）如何协助？

当数据收集具有挑战性或反洗钱（AML）团队正在创建新的监测规则时，LLM可以成为宝贵的工具。它们可以用于：a）生成合成数据，和b）预测警报是否可疑。这有助于更有效的监测规则，并协助高效处理警报，促进反洗钱框架的整体优化。

我们能够相信LLMs的辅助作用吗？

如果我们利用机器学习来模拟这些模型所做的决策，我们可以对LLMs产生-的洞察力进行验证和增强，从而对它们对我们的交易监测系统的贡献的可靠性产生信任。通过审查洞察力并理解LLMs预测背后的推理，我们可以验证和增强它们对我们的交易监测系统的贡献的可靠性。
实验过程

为了从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测），我设计了合适的提示语。

首先，我设计了一个简单的提示语，要求提供一个客户的30天交易摘要。ChatGPT给出了一些建议，但没有提供具体的数字数据。

然后，我修改了问题，使其更加精确和详细。我收到的回答非常出色和结构清晰。这种叙述在警报调查过程中非常常见，通常调查专家会利用这些信息来得出结论。

令人惊讶的是，ChatGPT甚至能够创建一个用于生成pandas数据帧的脚本，将其生成的合成信息纳入其中。完美！

当我提出另一个问题时，回答是准确的，但过于详细，缺乏直接性。

为了解决这个问题，我不得不对我的问题进行进一步的细化，使其更加具体地满足我的需求。

到目前为止，我们已经成功地使用了合理的提示策略从LLMs生成了合成数据和预测，甚至没有任何历史上下文。这显示了这些模型在从提示中生成有用、可操作的信息方面的潜力。

创建合成数据并实施提示策略以获取大量观测结果。

在这部分中，我简化了问题，只考虑了8个维度：（ACH-自动清算系统，Wire-电汇）×（交易金额，交易次数）×（实际活动，预期活动）。

我将这个新规则称为“与预期行为的Wire和ACH偏差”。

通过一些文本操作，我能够生成如下的提示语：

“在回答中只回答是或否，不要提供其他信息。这是问题的内容：我正在调查一起潜在的洗钱案件，客户的30天交易行为如下：Wire金额：$7148.0，Wire交易次数：5.0次；ACH金额：$15318.0，ACH交易次数：16.0次；该客户的预期行为是：Wire金额：$7486.0，Wire交易次数：8.0次；ACH金额：$4767.0，ACH交易次数：4.0次；基于实际和预期行为，这个案件是否可疑？”

以下是一个示例：

基于上述实验，我建立了一个包含300名客户的数据集。从每一行中，我生成了一个提示语，并从ChatGPT获得了一个“是”或“否”的回答。 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的一个重要因素。

这是数据集的前几行：

利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策背后的原理。

在对300条记录进行分析后，ChatGPT将其中180条分类为“是”（可疑）和120条分类为“否”（误报）。

让我们快速检查一下Wire交易金额的分布。

交易金额和每种交易类型的交易次数之间存在明显的相关性，这是符合预期和逻辑的。

DataRobot开发了许多模型，并根据首选指标（在本例中是AUC）对它们进行了排名。最优模型的ROC曲线显示了其有效区分ChatGPT“是”和“否”回答的能力。

通过利用基于SHAP的特征影响分析，我们发现尽管提示主要侧重于比较实际值和预期值（“比率”变量），但实际交易金额和交易次数（例如Txn Cnt ACH）也对预测有显著贡献。

让我们深入研究一下前几个关键特征的影响：

当ACH交易次数超过9次时，较高的值显著增加”是”预测的概率。
对于实际和预期Wire交易金额之间的比率，超过1的偏离值表示更高的风险，当该比率超过2时，风险显著增加。
与前一个情况相反，当ChatGPT评估实际和预期ACH交易次数之间的偏离时，低于预期值（<0.8）也引起怀疑。
当实际Wire交易金额超过8000美元时，风险水平突然上升。

为了提供更多见解，以下是基于SHAP的预测解释，揭示了影响ChatGPT预测的因素。

通过利用机器学习并探索LLM的内部工作原理，我们开启了无限的机遇。我们可以优化模型，提高其准确性，并利用它们的力量在各个行业和领域推动智能决策的发展。

结论

我还有其他想法要探索，但我将它们保留到未来的博客文章中。总结起来，从这个分析中得出的关键要点是：

大型语言模型（LLM）可以通过有效的提示策略进行零样本预测。
机器学习和预测洞察力对于理解LLM的预测和推理过程至关重要。
利用LLM生成合成数据可以极大地加快新想法的开发和评估，消除数据可用性限制和安全/隐私问题。

这些洞察力突出了LLM在各种应用中的潜力，并强调了利用机器学习技术进行预测分析的重要性。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Llm
Datarobot
Machine Learning
Trust
Written by Ray Mi
35 Followers

RVP of DataScience Practice, DataRobot

Follow
More from Ray Mi

Ray Mi

From Innovation to Implementation: Best Practices for Monitoring Generative AI in Business
Introduction
4 min read
·
Aug 11, 2023

11

Ray Mi

Unveiling the Mechanics of Zero-Shot Predictions: Harnessing Machine Learning Models to Understand…
Introduction
8 min read
·
May 30, 2023

7

Ray Mi

Future of Generative AI: A Frontline Practitioner’s Take on Adoption Trends
Introduction
8 min read
·
Jun 5, 2023

28

Ray Mi

Demystify Large Language Model and Generative AI (Part 2) : From GPT to ChatGPT, a Data Science…
Introduction
9 min read
·
Jun 14, 2023

35

See all from Ray Mi
Recommended from Medium

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.9K

44

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Lists
Predictive Modeling w/ Python
20 stories
·
966 saves
Practical Guides to Machine Learning
10 stories
·
1146 saves
Natural Language Processing
1253 stories
·
733 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
322 saves

Janna Lipenkova

in

Towards Data Science

Choosing the right language model for your NLP use case
A guide to understanding, selecting and deploying Large Language Models
15 min read
·
Sep 27, 2022

568

8

Raja Gupta

Generative AI for Beginners: Part 1 — Introduction to AI
Learn Generative AI by Spending 15 Minutes Daily for 8 Days
13 min read
·
Feb 8, 2024

1.2K

20

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

20K

574

Alexandru Lazar

in

ILLUMINATION

Ten Habits that will get you ahead of 99% of People
Improve your life and get ahead of your peers in 10 simple steps
9 min read
·
Nov 18, 2023

20K

356

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:24.779 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.202 | Max budget: $10.000 | Current cost: $0.043, prompt_tokens: 14007, completion_tokens: 215
2024-03-04 22:03:29.302 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.248 | Max budget: $10.000 | Current cost: $0.046, prompt_tokens: 15013, completion_tokens: 280
2024-03-04 22:03:29.309 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型的程序思维方法".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
中文摘要：這篇論文探討了深度學習中的「混合專家（MoE）」概念，這種模型每個輸入都選擇不同的參數，而不是共用相同的參數。這個稀疏激勵模型，擁有龐大的參數量，但計算成本保持不變。但儘管MoE有一些顯著的成功案例，但其廣泛應用受到了複雜性、通訊成本和訓練不穩定性的限制。所以我們提出Switch Transformer解決了這些問題。我們簡化了MoE路由演算法，設計了更直觀的改進模型，減少了通訊和計算成本。我們提出的訓練技術有助於解決不穩定問題，首次展示了大型稀疏模型可以使用更低精度（bfloat16）格式進行訓練。我們基於T5-Base和T5-Large設計的模型，在相同的計算資源下，預訓練速度提高了最多7倍。這些改進也適用於多語言環境，在101種語言中，我們在mT5-Base版本上實現了提升。最後我們將語言模型的規模提升到了兆參數級別，在「Colossal Clean Crawled Corpus」上進行預訓練，實現了比T5-XXL模型快4倍的速度。
論文連結：https://arxiv.org/pdf/2101.03961.pdf
27. Soft Prompts
論文名稱：The Power of Scale for Parameter-Efficient Prompt Tuning
發布時間：2021/04/18
發布單位：Google
簡單摘要：模型越大，Prompt tuning就能越接近Fine tuning效果
閱讀重點：prompt tuning、prompt desgin、unlearning span corruption、prompt ensembling、prompt可解釋性
中文摘要：這份研究探索了「提示調整」，這是一種簡單卻有效的機制，用於學習「軟性提示」，以條件化凍結的語言模型來執行特定的下游任務。不同於GPT-3使用的離散文本提示，軟性提示是通過反向傳播學習的，可以根據任意數量的標註範例進行調整。另外我們的端到端學習方法在「少樣本」學習方面遠優於GPT-3。更顯著的是，通過使用T5進行不同規模的模型大小消融實驗，我們發現隨著模型超過數十億參數，我們的方法「拉近了差距」，與模型調整（調整所有模型權重）的表現相匹敵。這一發現特別重要，因為大型模型的共享和服務成本高昂，使用一個凍結模型處理多個下游任務能夠減輕這種負擔。我們的方法可以看作是「前綴調整」的簡化版本，我們與該方法及其他類似方法進行了比較。最後我們發現，使用軟性提示來條件化凍結模型對於領域轉移的穩健性具有優勢，相較於完整模型的調整。
論文連結：https://arxiv.org/pdf/2104.08691.pdf
28. Rotary Position Embedding (RoPE)
論文名稱：RoFormer: Enhanced Transformer with Rotary Position Embedding
發布時間：2021/04/20
發布單位：追一科技
簡單摘要：目前在LLM上最普遍使用的embedding方式
閱讀重點：rotary position embedding、long-term decay性質、linear self-attention
中文摘要：這篇論文研究了位置編碼在Transformer結構中的有效性。它能夠為序列中不同位置的元素建立關聯，提供有價值的監督。我們首先探討了將位置訊息整合到基於Transformer的語言模型學習過程中的各種方法。接著我們提出了一種新方法，名為Rotary Position Embedding（RoPE），以有效利用位置訊息。具體而言，RoPE使用旋轉矩陣編碼絕對位置，同時在自注意力機制中結合了明確的相對位置依賴。值得注意的是，RoPE具有一些優勢，包括序列長度的靈活性、隨著相對距離增加而減弱的標註間依賴性，以及線性自注意力機制配備相對位置編碼的能力。最後我們在多個長文本分類基準數據集上評估了使用Rotary Position Embedding的增強Transformer，也稱為RoFormer。我們的實驗顯示它穩定地優於其他方法。此外我們提供了理論分析來解釋一些實驗結果。
論文連結：https://arxiv.org/pdf/2104.09864.pdf
29. LoRA
論文名稱：LoRA: Low-Rank Adaptation of Large Language Models
發布時間：2021/06/17
發布單位：Microsoft
簡單摘要：Fine-tune不了整個LLM，那fine-tune一點點就好
閱讀重點：low-rank adaptation、inference latency和adapter問題、LoRA應用到Transformer、practical benefits and limitations
中文摘要：這篇論文探討了自然語言處理的重要範式，即在通用領域數據上進行大規模預訓練，然後適應特定任務或領域。隨著我們預訓練更大型的模型，重新調整全部模型參數（fine-tuning）的成本變得越來越高。例如使用GPT-3 175B，部署獨立已微調好的模型實例成本過高。所以我們提出了低秩適應（LoRA）的方法，凍結預訓練模型權重，並將可訓練的秩分解矩陣注入到Transformer架構的每一層中，大大減少下游任務所需的可訓練參數數量。相較於使用Adam進行的GPT-3 175B的全模型重新調整，LoRA可將可訓練參數數量減少10,000倍，GPU記憶體需求減少3倍。除了可訓練參數更少、訓練吞吐量更高，並且不像適配器那樣存在額外的推理延遲，LoRA在RoBERTa、DeBERTa、GPT-2和GPT-3模型上，與全模型重新微調有相當或更優的結果。我們還對語言模型適應中的秩缺陷進行了實證研究，這有助於我們更好地理解LoRA的有效性。
論文連結：https://arxiv.org/pdf/2106.09685.pdf
30. Codex
論文名稱：Evaluating Large Language Models Trained on Code
發布時間：2021/07/07
發布單位：OpenAI
簡單摘要：會寫程式的GPT
閱讀重點： HumanEval、unbiased estimator、code fine-tuning
中文摘要：我們推出了Codex，這是一個在GitHub上公開可用的程式碼進行微調的GPT語言模型，並研究了它在Python程式碼編寫方面的能力。Codex的特定生產版本為GitHub Copilot提供支持。另外我們發布了一個名為HumanEval的新評估資料集，用於測量從文檔字符串合成程序的功能正確性。在這個評估資料集中，我們的模型解決了28.8%的問題，而GPT-3解決了0%，GPT-J解決了11.4%。此外我們發現從模型中重複取樣對於生成複雜提示的可行解決方案非常有效。使用這種方法，我們在每個問題中通過100次取樣解決了70.2%的問題。仔細研究我們的模型顯示了它的一些限制，包括難以處理描述一長串操作的文檔字符串以及綁定操作到變量的困難。最後我們討論了部署強大的程式碼生成技術可能帶來的潛在廣泛影響，涵蓋了安全性、保密性和經濟性。
論文連結：https://arxiv.org/pdf/2107.03374.pdf
31. FLAN
論文名稱：Finetuned Language Models Are Zero-Shot Learners
發布時間：2021/09/03
發布單位：Google
簡單摘要：instruction-tuning讓模型更了解你想幹嘛
閱讀重點：instruction-tuning、task clusters、instruction templates
中文摘要：這篇論文探討了改善語言模型零樣本學習能力的簡單方法。我們展示了指令微調的方法，即在語言模型上進行微調，使用一系列通過指令描述的任務，顯著提高了對未知任務的零樣本性能。我們拿一個擁有 137B 參數的預訓練語言模型，並在超過 60 個自然語言指令模板的幫助下，針對多個 NLP 任務進行微調。我們將這個經過指令微調的模型命名為 FLAN，在未見過的任務類型上進行評估。FLAN 大幅提升了其未修改版本的性能，並在我們評估的 25 個任務中，有 20 個超越了零樣本 175B GPT-3。FLAN 在 ANLI、RTE、BoolQ、AI2-ARC、OpenbookQA 和 StoryCloze 等任務上甚至大幅優於少樣本的 GPT-3。消融研究顯示，微調資料集的數量、模型規模和自然語言指令是指令微調成功的關鍵因素。
論文連結：https://arxiv.org/pdf/2109.01652.pdf
32. T0
論文名稱：Multitask Prompted Training Enables Zero-Shot Task Generalization
發布時間：2021/10/15
發布單位：Hugging Face、布朗大學、BigScience…..
簡單摘要：prompt加上多任務學習，提升zero-shot能力
閱讀重點：held-out-task、unified prompt format
中文摘要：最近研究顯示大型語言模型在多種任務上能夠達到合理的零樣本泛化能力。有人假設這是因為語言模型在預訓練階段隱含地進行了多任務學習。所以我們提出一個系統，能將任何自然語言任務輕鬆轉換成人類可讀的提示形式，並在大量監督式數據集上進行測試。我們使用一個包含多種不同提示的監督式數據集，讓模型在全新任務上進行評估。我們對預訓練的編碼器-解碼器模型進行微調，其中涵蓋各種任務，並在多個標準數據集上實現了強大的零樣本性能，其往往超越了比自己大 16 倍的模型。此外，我們的方法在 BIG-bench 基準測試中也取得了強大表現，在某些任務上超越了比自己大 6 倍的模型。
論文連結：https://arxiv.org/pdf/2110.08207.pdf
33. RETRO
論文名稱：Improving language models by retrieving from trillions of tokens
發布時間：2021/12/08
發布單位：DeepMind
簡單摘要：有超大的資料庫可以檢索，我就可以以小搏大
閱讀重點：retrieval-enhanced autoregressive token models、使用BERT做retrieval neighbours、chunked cross-attention
中文摘要：我們通過條件設定於自回歸語言模型上，利用與先前標註相似的文件片段來檢索大型語料庫。基於使用一個 2 兆標記的資料庫，我們的「檢索增強變形器」（RETRO）在 Pile 數據集上獲得了與 GPT-3 和 Jurassic-1 相當的性能，儘管其使用的參數量少了 25 倍。在微調後，RETRO 的表現可轉化為問答等知識密集型任務。而 RETRO 將凍結的 Bert 檢索器、可微分編碼器和分塊交叉注意力機制結合在一起，基於比訓練過程中通常消耗的數據量多一個數量級來預測標記。另外通常我們會從頭開始訓練 RETRO，但也可以快速地將預訓練變形器與檢索進行 RETROfit，其同樣能取得良好表現。我們的工作為通過明確記憶在前所未有的規模上提升語言模型開辟了新途徑。
論文連結：https://arxiv.org/pdf/2112.04426.pdf
34. GLaM
論文名稱：GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
發布時間：2021/12/13
發布單位：Google
簡單摘要：用MoE架構設計LLM準確率更高、訓練速度更快
閱讀重點：gating module、MoE和dense models比較、數據品質影響、scaling studies
中文摘要：我們在自然語言處理領域中，透過增加數據、計算和參數量，提升了語言模型的規模。例如GPT-3在上下文學習任務上取得了出色的成果，這歸功於模型規模的擴大。但是訓練這些大型密集模型需要大量的計算資源。所以本文中我們提出並開發了一系列名為 GLaM（通用語言模型）的語言模型，採用了稀疏啟動的混合專家架構來擴展模型容量，同時與密集變體相比，大幅降低了訓練成本。最大的 GLaM 模型擁有 1.2 兆個參數，大約是 GPT-3 的 7 倍大小。它的訓練能耗只有 GPT-3 的三分之一，且推理時需要的計算量也減少了一半，同時在 29 個自然語言處理任務中實現了更好的零樣本和單樣本學習表現。
論文連結：https://arxiv.org/pdf/2112.06905.pdf
35. WebGPT
論文名稱：WebGPT: Browser-assisted question-answering with human feedback
發布時間：2021/12/17
發布單位：OpenAI
簡單摘要：可以上網查資料的GPT-3變得更強大
閱讀重點：environment design、資料demonstrations和comparisons、強化學習和reward modeling
中文摘要：我們使用基於文本的網頁瀏覽環境對 GPT-3 進行微調，讓它可以回答長篇問題並搜索網頁。透過設置一個可以由人類執行的任務，我們可以使用模仿學習訓練模型，並通過人類反饋來優化回答的品質。為了讓人類更容易對事實準確性進行評估，模型必須在瀏覽時收集相關參考來支持它們的答案。另外我們在 ELI5 數據集上訓練和評估模型，該數據集包含 Reddit 用戶提出的問題。我們最佳的模型是通過行為複製微調 GPT-3 後，使用拒絕採樣與預測人類喜好的獎勵模型進行比較得到的。對於這個模型，人類在 56% 的情況下更喜歡這個模型的答案，而在 69% 的情況下更喜歡 Reddit 上得票最高的答案。
論文連結：https://arxiv.org/pdf/2112.09332.pdf
36. Chain-of-Thought
論文名稱：Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
發布時間：2022/01/28
發布單位：Google
簡單摘要：給答案要給詳解，讓LLM回答變得更有邏輯、更正確
閱讀重點：chain-of-Thought Prompting、討論CoT有效原因
中文摘要：我們探索了如何通過生成一系列中間推理步驟，即”思維鍊”，來顯著提高大型語言模型執行複雜推理的能力。特別是我們展示了在足夠大的語言模型中，這種推理能力是如何通過一種稱為”思維鏈提示”的簡單方法自然產生的，該方法在提示中提供了一些思維鏈範例。在三個大型語言模型上的實驗表明，思維鏈提示提升了在一系列算術、常識和符號推理任務上的性能。實驗效果驚人，例如對一個具有 540 億參數的語言模型進行思維鏈提示，僅使用八個範例，在數學單詞問題的 GSM8K 基準上達到了最先進的準確率，甚至超過了經過微調的 GPT-3 與一個驗證器的表現。
論文連結：https://arxiv.org/pdf/2201.11903.pdf
37. AlphaCode
論文名稱：Competition-Level Code Generation with AlphaCode
發布時間：2022/02/08
發布單位：DeepMind
簡單摘要：寫程式打敗人類的LLM
閱讀重點：value conditioning & prediction、large scale sampling、filtering、clustering、能力限制
中文摘要：透過程式設計解決問題是一個強大且無所不在的工具。開發能協助程式設計師甚至獨立生成程式的系統，可以提高程式設計的生產力和可及性，但將人工智慧的創新納入其中一直是具有挑戰性的研究。近期的大型語言模型展現出了令人印象深刻的生成程式的能力，現在已能完成簡單的編程任務。然而這些模型在評估更複雜、未曾見過的問題時表現不佳，這些問題需要超越將指令翻譯成程式碼的技能，例如競技程式問題，需要理解算法和複雜的自然語言，至今仍然極具挑戰性。為了填補這個差距，我們引入了 AlphaCode，這是一個用於程式碼生成的系統，可以創建對這些需要更深入推理的問題提出新解。在 Codeforces 平台上模擬的編程競賽評估中，AlphaCode 在超過 5,000 名參與者的比賽中平均排名前 54.3%。我們發現三個關鍵因素對於獲得良好和可靠的性能至關重要：（1）用於訓練和評估的大規模、乾淨的競技程式數據集，（2）大型且高效取樣的 transformer 的架構，和（3）大規模模型取樣來探索搜索空間，然後根據程式行為將結果篩選為一小部分提交內容。
論文連結：https://arxiv.org/pdf/2203.07814.pdf
38. PaLM
論文名稱：PaLM: Scaling Language Modeling with Pathways
發布時間：2022/04/05
發布單位：Google
簡單摘要：訓練LLM的大型系統
閱讀重點：pathways system、discontinuous improvements
中文摘要：大型語言模型已被證明能夠在各種自然語言任務上取得卓越表現，使用了少樣本學習（few-shot learning），顯著減少了適應特定應用所需的特定訓練樣本數量。為了進一步了解規模對少樣本學習的影響，我們訓練了一個名為 Pathways Language Model（PaLM）的 5400 億參數的密集激勵 Transformer 語言模型。我們使用 Pathways 這個新的 ML 系統在 6144 個 TPU v4 芯片上進行了 PaLM 的訓練，該系統能夠實現跨多個 TPU Pod 的高效訓練。我們也展示了通過規模擴展所帶來的持續效益，PaLM 540B 在數百個語言理解和生成測試中實現了最新的少樣本學習結果。在其中一些任務中，PaLM 540B 實現了突破性的性能，優於一系列多步推理任務的微調最新技術，並在最近發布的 BIG-bench 測試中超越了人類的平均表現。大量的 BIG-bench 任務顯示模型規模的增大帶來了不連續的改進，這意味著隨著我們擴展到最大的模型，性能會急劇提高。我們也在各種測試中進行了展示，PaLM 在多語言任務和程式碼生成方面也具有強大的能力。此外我們還對偏見和惡意訊息進行了全面分析，並研究了模型規模對訓練數據記憶的程度。最後我們討論了與大型語言模型相關的道德考量，並探討了潛在的緩解策略。
論文連結：https://arxiv.org/pdf/2204.02311.pdf
39. InstructGPT
論文名稱：Training language models to follow instructions with human feedback
發布時間：2022/05/04
發布單位：OpenAI
簡單摘要：ChatGPT的前身，讓人類來教GPT-3社會化
閱讀重點：supervised policy、reward model訓練、用PPO優化針對reward model的policy
中文摘要：擴大語言模型的規模並不一定會使其更能理解用戶的意圖。舉例來說，大型語言模型可能產生不真實、惡意，或者對用戶沒有幫助的輸出。換句話說，這些模型與其用戶並不完全一致。所以在這篇論文中，我們展示了一種通過人類反饋來對語言模型進行微調，從而使其在各種任務中與用戶意圖保持一致的方法。我們首先從一組由標註者編寫的提示和透過 OpenAI API 提交的提示開始，收集了一組標註者展示所需模型行為的數據集，然後使用監督學習對 GPT-3 進行微調。接著我們收集了模型輸出的排名數據集，進一步使用來自人類反饋的強化學習對這個監督模型進行微調。我們稱最終生成的模型為 InstructGPT。在我們的提示分發的人工評估中，儘管其參數數量少了 100 倍，擁有 13 億參數的 InstructGPT 模型的輸出優於 175 億參數的 GPT-3 的輸出。此外 InstructGPT 模型在真實性上有所提高，在減少惡意輸出產生的同時，在公開 NLP 數據集上幾乎沒有性能退步。儘管 InstructGPT 仍然會犯一些簡單的錯誤，但我們的結果顯示，通過人類反饋進行微調是使語言模型與人類意圖保持一致的一個有前景的方向。
論文連結：https://arxiv.org/pdf/2203.02155.pdf
40. Zero-shot-CoT
論文名稱：Large Language Models are Zero-Shot Reasoners
發布時間：2022/05/24
發布單位：Google、東京大學
簡單摘要：加上一句「讓我們一步一步思考」，LLM能力就上升了
閱讀重點：zero-shot-CoT、reasoning extraction、answer extraction
中文摘要：這份論文關於大型預訓練語言模型（LLMs）在自然語言處理（NLP）中的使用。通常LLMs以少量範例即可學會新任務，而「思維鍊」（CoT）提示則是近期的技術，透過逐步的回答範例來引出複雜的多步推理，它在數學和符號推理中取得了最先進的成果。雖然LLMs在少樣本學習能力能成功，但我們展示了，其實際上只要在每個答案前加上「讓我們一步一步地思考」，LLMs也能表現出不錯的zero-shot推理能力。實驗結果顯示，我們的zero-shot-CoT在各種推理任務上明顯優於zero-shot LLMs，包括算術、符號推理和邏輯推理任務，無需手工製作少量範例即可達成，例如使用大型InstructGPT模型將MultiArith的準確性從17.7%提高到78.7%，GSM8K從10.4%提高到40.7%，同樣將其他預訓練大型模型PaLM的參數540B的改善程度也相近。單一提示在非常不同的推理任務中展示了它的多樣性，暗示了LLMs潛在的zero-shot能力，其表明可透過簡單提示提取高層次、多任務的廣泛認知能力。我們希望這份研究不僅成為具有挑戰性的推理基準的最小最強zero-shot基準，同時也強調了在製作微調數據集或少量範例之前，仔細探索和分析LLMs內隱藏的巨大zero-shot知識的重要性。
論文連結：https://arxiv.org/pdf/2205.11916.pdf
41. FlashAttention
論文名稱：FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
發布時間：2022/05/27
發布單位：史丹佛大學、紐約州立大學水牛城分校
簡單摘要：在GPU上讀寫速度更快的Transformers
閱讀重點：high bandwidth memory、SRAM、IO complexity analysis、block-sparse FlashAttention
中文摘要：這篇論文探討了Transformer模型在處理長序列時速度緩慢且需大量記憶體的問題，因為自注意力機制的時間和記憶體複雜度與序列長度呈二次方增加。雖然先前的研究嘗試以近似注意力方式解決此問題，但常常降低模型品質且無法明顯提升速度。所以我們主張缺乏的原因是使注意力機制IO感知，也就是考慮GPU記憶體層間的讀寫，基於此我們提出了FlashAttention，一種IO感知的精確注意力演算法，利用平鋪技術減少GPU高速記憶體（HBM）和GPU片上SRAM間的記憶體讀寫次數。我們分析了FlashAttention的IO複雜度，顯示其比標準注意力需要更少的HBM存取，並對一定SRAM尺寸來說是最優的。我們還將FlashAttention延伸到區塊稀疏注意力，得到比任何現有近似注意力方法更快的演算法。另外FlashAttention比現有基準模型訓練速度更快：BERT-large（序列長度512）相比MLPerf 1.1訓練速度記錄快了15％，GPT-2（序列長度1K）加速了3倍，長距離場景（序列長度1K-4K）提升了2.4倍。FlashAttention和區塊稀疏FlashAttention使Transformer模型能處理更長的上下文，提高了模型品質（GPT-2的困惑度提高了0.7，長文件分類提升了6.4個點），並具有全新能力：首次在Path-X挑戰中（序列長度16K，61.4%準確率）和Path-256（序列長度64K，63.1%準確率）超過隨機猜測的表現。
論文連結：https://arxiv.org/pdf/2205.14135.pdf
42. Chinchilla’s Law
論文名稱：Training Compute-Optimal Large Language Models
發布時間：2022/05/29
發布單位：DeepMind
簡單摘要：更全面的scaling law，訓練LLM所需資源定律
閱讀重點：optimal parameter/training tokens allocation、optimal model scaling、model size和training tokens最佳化方程式
中文摘要：我們研究了在特定計算預算下，訓練Transformer語言模型的最佳模型大小和標註數量。我們發現目前的大型語言模型訓練不足，這是近期將語言模型擴展的焦點，同時保持訓練數據量不變所致。通過訓練超過 400 個語言模型，參數範圍從 7,000 萬到超過 160 億，標註數量範圍從 50 億到 500 億，我們發現對於最佳計算訓練，模型大小和訓練標記數量應該等比例增加：模型大小每翻倍，訓練標記數量也應翻倍。我們通過訓練一個預測的計算最佳模型「Chinchilla」來測試這個假設，它使用與 Gopher 相同的計算預算，但擁有 700 億參數和 4 倍的數據量。Chinchilla 在大範圍的下游評估任務中一致且顯著地優於 Gopher（280B）、GPT-3（175B）、Jurassic-1（178B）和 Megatron-Turing NLG（530B）。這意味著 Chinchilla 在精細調整和推理過程中需要的計算量大大減少，極大地方便了下游應用。值得一提的是，Chinchilla 在 MMLU 基準測試中達到了 67.5% 的最高平均準確率，比 Gopher 提高了超過 7%。
論文連結：https://arxiv.org/pdf/2203.15556.pdf
43. Emergent Abilities
論文名稱：Emergent Abilities of Large Language Models
發布時間：2022/06/15
發布單位：Google、DeepMind、史丹佛大學、北卡羅萊大學
簡單摘要：為什麼LLM突然頓悟了？
閱讀重點：emergence in the few-shot prompting、emergence的可能原因、beyond scaling、未來可能方向
中文摘要：擴大語言模型已被證明可以預測性地提升在各種下游任務中的表現和樣本效率。在這篇論文討論了一個無法預測的現象，我們稱之為大型語言模型的「能力湧現」。如果它在較小的模型中不存在，但在較大的模型中存在。因此能力湧現無法僅僅通過推斷較小模型的性能來預測。這種新能力的存在代表著進一步的擴展語言模型的規模可能會進一步擴展其能力範圍。
論文連結：https://arxiv.org/pdf/2206.07682.pdf
44. LLM.int8()
論文名稱：LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale
發布時間：2022/08/15
發布單位：Facebook(Meta)、華盛頓大學、Hugging Face
簡單摘要：把float16/32精度的LLM轉成int8，GPU就跑得動了
閱讀重點：8-bit quantization、matrix nultiplication、vector-wise quantization、mixed-precision decomposition
中文摘要：大型語言模型被廣泛採用，但推斷過程需要大量GPU記憶體。所以我們開發了一種Int8矩陣乘法程序，適用於transformer中的前饋和注意力投影層，將推斷所需的記憶體減少了一半，同時保持完整的精確度表現。透過我們的方法，可以加載175B參數的16/32位檢查點，轉換為Int8，並立即使用，而不會有性能下降。這是因為我們理解和處理了transformer語言模型中高度系統化的新特徵，這些特徵主導了注意力和預測性能。為應對這些特徵，我們開發了LLM.int8()的兩部分量化程序。首先我們使用向量量化，為矩陣乘法中的每個內積使用單獨的歸一化常數，對大多數特徵進行量化。然而對於新出現的極端值，我們還包括一種新的混合精度分解方案，將這些特異特徵維度分離出一個16位矩陣乘法，而仍然有超過99.9%的值在8位中進行乘法。透過LLM.int8()，我們實證表明可以在具有175B參數的LLMs中進行推斷，而不會有任何性能下降。這一結果使得這樣的模型更加易於使用，例如在單個使用消費級GPU的服務器上使用OPT-175B/BLOOM。
論文連結：https://arxiv.org/pdf/2208.07339.pdf
45. ReAct
論文名稱：ReAct: Synergizing Reasoning and Acting in Language Models
發布時間：2022/10/06
發布單位：Google、普林斯頓大學
簡單摘要：結合思維鏈提示和行動計劃生成，防止LLM胡言亂語
閱讀重點：Synergizing Reasoning、Acting、knowledge-intensive reasoning tasks
中文摘要：大型語言模型（LLMs）在語言理解和互動決策方面展現了令人印象深刻的能力，但它們的推理能力（例如思維鏈提示）和行動能力（例如行動計劃生成）主要是作為獨立的主題來研究的。所以本文探討了LLMs以交叉方式生成推理跟蹤和特定任務的行動，讓兩者之間更協同：推理跟蹤幫助模型誘導、追蹤、更新行動計劃並處理異常情況，而行動則允許它與知識庫或環境等外部來源互動，收集額外訊息。我們的方法名為ReAct，在多種語言和決策任務上展示了比最先進基準更有效的效果，同時相較於沒有推理或行動元件的方法，具有更好的人類可解釋性和可信度。具體來說在問答（HotpotQA）和事實驗證（Fever）方面，ReAct通過與簡單的維基百科API互動，克服了思維鏈推理中出現的幻覺和錯誤傳播問題，生成了更具可解釋性的人類化任務解決軌跡，優於沒有推理跟蹤的基準。在兩個互動式決策基準（ALFWorld和WebShop）上，即使只提示了一兩個上下文示例，ReAct的成功率分別比模仿學習和強化學習方法提高了34％和10％。
論文連結：https://arxiv.org/pdf/2210.03629.pdf
46. Flan-PaLM
論文名稱：Scaling Instruction-Finetuned Language Models
發布時間：2022/10/20
發布單位：Google
簡單摘要：模型大小、任務數量、CoT對instruction finetuning很重要
閱讀重點：flan finetuning、scaling parameters ans tasks、finetuning with chain-of-thought
中文摘要：這篇論文探討了以指令形式進行微調語言模型，這種方法已證實能夠提高模型的性能並應對未見過的任務。所以我們聚焦於三個方面：(1) 擴展任務數量、(2) 擴大模型規模、(3) 在思維鏈維數據上進行微調。研究發現，使用這些方法對各種模型（PaLM、T5、U-PaLM）、提示設置（零樣本、少樣本、思維鏈）和評估基準（MMLU、BBH、TyDiQA、MGSM、開放式生成）的表現有顯著改善。例如使用1.8K個任務對Flan-PaLM 540B進行指令微調，其性能顯著優於PALM 540B（平均+9.4%）。Flan-PaLM 540B在一些基準測試中達到了最先進的性能，如在五樣本MMLU上達到了75.2%。此外我們還公開了Flan-T5的檢查點，即使與更大的模型（例如PaLM 62B）相比，它在少樣本測試中也表現出色。總體而言，指令微調是提升預訓練語言模型性能和可用性的通用方法。
論文連結：https://arxiv.org/pdf/2210.11416.pdf
47. GPTQ
論文名稱：GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers
發布時間：2022/10/31
發布單位：奧地利科技學院、蘇黎世聯邦理工學院
簡單摘要：把GPT quantize到2 bit還可以表現不錯的方法
閱讀重點：arbitrary order insigh、lazy batch-updates、Cholesky reformulation、extreme quantization
中文摘要：這篇論文探討了「生成式預訓練transformer模型」，也就是GPT或OPT模型，這些模型在處理複雜的語言模型任務方面表現出色，但同時也面臨著極高的計算和存儲成本。由於模型體積龐大，即使對於大型、高準確度的GPT模型進行推理也可能需要多個高性能的GPU，這限制了這些模型的可用性。儘管近期出現了針對模型壓縮的工作，但現有的壓縮技術在應用和性能方面受到GPT模型規模和複雜性的限制。所以本文提出了一種新的「GPTQ」方法，基於近似的二階訊息進行一次性的權重量化，讓其具有高準確性和高效率。具體而言，GPTQ可以在大約四個GPU小時內量化具有1750億參數的GPT模型，將位寬降低到每個權重3或4位元，相對於未壓縮基準模型幾乎沒有精度下降。我們的方法相對於先前提出的一次性量化方法，壓縮效果提升了一倍以上，另外其保持了準確性，使我們首次能夠在單個GPU內進行1750億參數模型的生成推理。此外我們還發現我們的方法在極端量化情況下仍能提供合理的精度，即將權重量化到2位元甚至三元量化水平。實驗表明，這些改進可以利用高端GPU（NVIDIA A100）獲得約3.25倍的端對端推理加速，使用成本更低的GPU（NVIDIA A6000）則可達到約4.5倍的加速。
論文連結：https://arxiv.org/pdf/2210.17323.pdf
48. SmoothQuant
論文名稱：SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models
發布時間：2022/11/18
發布單位：麻省理工、Nvidia
簡單摘要：免訓練的通用8-bit post-training quantization
閱讀重點：activations to weights的困難點、Transformer上的應用
中文摘要：這項研究針對大型語言模型（LLMs）展現出優異表現，但需要大量計算和記憶體資源的問題提出了解決方案。量化可以減少記憶體使用並加速推論速度。然而現有的方法無法同時保持精度和硬體效能。所以我們提出了SmoothQuant，一種無需訓練、保持精度且通用的後訓練量化（PTQ）解決方案，其可實現對LLMs的8位權重和8位激勵（W8A8）量化。基於權重易於量化而激勵難以量化的事實，SmoothQuant通過數學等效轉換，將激勵值中的極端值平滑處理，將量化困難度從激勵轉移到權重上。另外SmoothQuant可對LLMs中的所有矩陣乘法進行INT8權重和激勵的量化，包括OPT、BLOOM、GLM、MT-NLG和LLaMA等模型。最後我們展示了高達1.56倍的加速和2倍的記憶體減少，同時精度幾乎無損。SmoothQuant使得能在單個節點上運行530B的LLM。這項工作提供了一個簡便解決方案，可降低硬體成本並普及化LLMs。
論文連結：https://arxiv.org/pdf/2211.10438.pdf
49. Toolformer
論文名稱：Toolformer: Language Models Can Teach Themselves to Use Tools
發布時間：2023/02/09
發布單位：Facebook(Meta)、龐培法布拉大學
簡單摘要：會使用外部工具的LLM
閱讀重點：sampling API calls、executing API calls、filtering API calls、annotation with self-supervised learning
中文摘要：這份研究探討語言模型（LMs）在解決新任務時展現出的驚人能力，僅需少量範例或文本指令即可，並尤其在大規模下表現卓越。然而相反地，它們在基本功能上表現出困難，例如算術或事實查詢，這些功能在更簡單、更小型的模型中表現出色。所以在這篇論文中，我們展示了語言模型可以通過簡單的API，自我學習使用外部工具，實現兩者之間的最佳結合。我們引入了Toolformer，這是一個訓練過的模型，能夠決定調用哪些API、何時調用它們、傳遞什麼參數，以及如何最佳地將結果整合到未來的標記預測中。這是通過自我監督的方式完成的，每個API僅需少量範例即可。我們包含了一系列工具，包括計算機、問答系統、兩種不同的搜索引擎、翻譯系統和日曆。Toolformer在各種下游任務中取得了顯著提升的零樣本性能，通常與更大的模型競爭力相當，同時也不損害其核心語言模型能力。
論文連結：https://arxiv.org/pdf/2302.04761.pdf
50. LLaMA
論文名稱：LLaMA: Open and Efficient Foundation Language Models
發布時間：2023/02/27
發布單位：Facebook(Meta)
簡單摘要：最有名的開源LLM第一代
閱讀重點：pre-training data、architecture、efficient implementation
中文摘要：我們推出了LLaMA，這是一系列參數從7B到65B的基礎語言模型。我們使用公開可用的數據集訓練這些模型，並展示了可以在僅使用公開數據集的情況下訓練出最先進的模型，無需使用專有或無法取得的數據集。特別是LLaMA-13B在大多數基準測試中優於GPT-3（175B），而LLaMA-65B與最佳模型Chinchilla-70B和PaLM-540B競爭力相當。我們將所有模型釋出給研究社群使用。
論文連結：https://arxiv.org/pdf/2302.13971.pdf
51. GPT-4
論文名稱：GPT-4 Technical Report
發布時間：2023/05/15
發布單位：OpenAI
簡單摘要：目前世界上最強的LLM
閱讀重點：scaling、capabilities、limitations、risks & mitigations


2024-03-04 22:03:30.834 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.294 | Max budget: $10.000 | Current cost: $0.046, prompt_tokens: 15319, completion_tokens: 3
2024-03-04 22:03:30.843 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型的程序思维方法".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
中文摘要：我們開發了GPT-4，這是一個大規模、多模態模型，能夠接受圖像和文字輸入並生成文字輸出。雖然在許多現實情境中比不上人類的能力，但在各種專業和學術基準測試中，GPT-4表現出與人類相當的水平，包括在模擬的律師考試中取得了排名前10％左右的成績。GPT-4是一個基於Transformer的模型，預先訓練來預測文件中的下一個標記。後訓練對齊流程改進了模型的事實性和符合期望行為的表現。這個項目的核心部分是開發了在各種規模下都表現穩定的基礎設施和優化方法。這使我們能夠根據使用不到GPT-4 1/1,000的計算資源所訓練的模型，準確預測GPT-4的某些性能方面。
論文連結：https://arxiv.org/pdf/2303.08774.pdf
52. PaLM 2 Technical Report
論文名稱：PaLM 2 Technical Report
發布時間：2022/05/17
發布單位：Google
簡單摘要：PaLM第二代
閱讀重點：scaling laws、evaluation
中文摘要：我們推出了PaLM 2，這是一個全新的頂尖語言模型，具有更好的多語言和推理能力，並且比其前身PaLM更節省計算資源。PaLM 2是一個基於Transformer的模型，使用混合目標進行訓練。通過對英語和多語言的語言評估以及推理任務的廣泛評估，我們展示了PaLM 2在不同模型尺寸下，在後續任務上品質有顯著提高，同時相比PaLM表現出更快速和高效的推理。這種提高的效率使得模型更廣泛地應用，同時也能更快速地回應，讓互動更自然。PaLM 2展示了強大的推理能力，在BIG-Bench和其他推理任務上相比PaLM有顯著的提升。PaLM 2在一系列負責任的人工智慧評估中表現穩定，並且在推理時能夠控制惡意訊息，而無需額外負擔或影響其他功能。總體而言PaLM 2在各種任務和能力方面都達到了頂尖水平。在討論PaLM 2系列時，需要區分預訓練模型（各種大小），這些模型的微調變體，以及使用這些模型的用戶產品。特別是，用戶產品通常包括額外的前置和後置處理步驟。此外基礎模型可能隨著時間演變。因此不能期望用戶產品的表現完全與本報告中報告的結果相匹配。
論文連結：https://arxiv.org/pdf/2305.10403.pdf
53. Tree of Thoughts
論文名稱：Tree of Thoughts: Deliberate Problem Solving with Large Language Models
發布時間：2023/05/17
發布單位：DeepMind、普林斯頓大學
簡單摘要：以tree資料結構來做CoT
閱讀重點：thought decomposition、thought generator、state evaluator、BFS和DFS
中文摘要：我們發現語言模型在解決問題時有所限制，特別是在需要探索、策略規劃或者一開始的決策就相當重要的任務上。為了克服這些挑戰，我們引入了一個新的框架，名為「思維樹」(ToT)，它擴展了思維鏈的方法，讓語言模型能夠在推理時更有彈性。ToT允許語言模型在問題解決過程中，通過考慮多個不同的推理路徑和自我評估選擇來進行有意識的決策，進而做出更有效的全局選擇。我們的實驗顯示，ToT在需要非平凡計劃或搜索的三個新任務上顯著增強了語言模型的問題解決能力：24點遊戲、創意寫作和小型填字遊戲。例如在24點遊戲中，雖然只有使用思維鏈提示的GPT-4解決了4%的任務，但我們的方法成功率達到了74%。
論文連結：https://arxiv.org/pdf/2305.10601.pdf
54. QLoRA
論文名稱：QLoRA: Efficient Finetuning of Quantized LLMs
發布時間：2023/05/23
發布單位：華盛頓大學
簡單摘要：quantization+Lora讓我一張顯卡就可fine-tune LLM
閱讀重點：4-bit NormalFloat、double quantization、paged optimizers
中文摘要：我們提出了QLoRA，一種有效的微調方法，可以減少記憶體使用量，讓一個65B參數的模型在一個48GB的GPU上進行微調，同時保持完整的16位微調任務性能。QLoRA通過一種稱為Low Rank Adapters（LoRA）的方法，將梯度反向傳播到凍結的4位量化預訓練語言模型。我們最佳的模型家族名為Guanaco，在Vicuna基準測試中表現優於以往所有公開發布的模型，並僅需在單個GPU上進行24小時的微調即可達到ChatGPT 99.3%的性能水平。QLoRA引入了幾項創新，以節省記憶體而不影響性能：（a）4位NormalFloat（NF4），這是一種對於正常分佈權重的訓息理論最優的新數據類型；（b）雙重量化，通過量化量化常數來減少平均記憶體占用；（c）分頁優化器，管理記憶體峰值。我們使用QLoRA對1000多個模型進行微調，提供了對8個指令數據集、多種模型類型（LLaMA、T5）以及使用常規微調不可行的模型規模（例如33B和65B參數模型）的指令遵從和聊天機器人性能的詳細分析。我們的結果表明，QLoRA在一個小而高品質的數據集上進行微調，即使使用的模型比以前的模型更小，可以達到最新技術水準的性能。除此之外我們提供了基於人類和GPT-4評估的聊天機器人性能的詳細分析，並顯示GPT-4評估是一種便宜且合理的替代方法。此外我們發現當前的聊天機器人基準測試不能準確評估聊天機器人的性能水平。通過某些方面的分析，我們展示了Guanaco相對於ChatGPT的不足之處。最後我們釋出了所有模型和程式碼，包括4位訓練的CUDA核心。
論文連結：https://arxiv.org/pdf/2305.14314.pdf
55. Direct Preference Optimization (DPO)
論文名稱：Direct Preference Optimization: Your Language Model is Secretly a Reward Model
發布時間：2023/05/29
發布單位：史丹佛大學
簡單摘要：不用強化學習，也可以讓LLM社會化
閱讀重點：SFT phase、reward modelling phase、RL fine-tuning phase、deriving the DPO objective、theoretical analysis
中文摘要：這篇論文討論了大規模無監督語言模型（LMs），它們學習了廣泛的世界知識和一些推理技能，但由於完全無監督的訓練方式，要精確控制它們的行為很困難。現有的方法通過收集人類對模型生成的相對品質的標註，並將無監督LM進行微調以符合這些偏好，通常使用來自人類反饋的強化學習（RLHF）。但是RLHF是一個複雜且不穩定的過程，首先擬合一個反映人類偏好的獎勵模型，然後使用強化學習微調大型無監督LM以最大化這個估計的獎勵，同時不能遠離原始模型太遠。所以在本文中，我們提出了一種新的RLHF獎勵模型參數化方法，使我們能夠以閉合形式提取相應的最優策略，僅使用簡單的分類損失函數便能解決標準的RLHF問題。這種名為Direct Preference Optimization（DPO）的演算法穩定、高效且計算輕便，無需在微調期間對LM進行抽樣或進行重大超參數調整。我們的實驗顯示，DPO能夠優於或與現有方法一樣微調LM以符合人類偏好。特別是在控制生成物情緒方面，DPO微調優於基於PPO的RLHF，在摘要和單輪對話的回應品質方面與之相當或更好，同時實現了訓練的簡化。
論文連結：https://arxiv.org/pdf/2305.18290.pdf
56. Verify Step by Step
論文名稱：Let’s Verify Step by Step
發布時間：2022/05/31
發布單位：OpenAI
簡單摘要：透過監督LLM的每一步，讓LLM數學推理邏輯更強
閱讀重點：outcome-supervised reward models、process-supervised reward models、active learning用在PRM
中文摘要：近年來大型語言模型在進行複雜的多步推理方面取得了很大進步。然而即使是最先進的模型仍然經常產生邏輯錯誤。為了訓練更可靠的模型，我們可以採用結果監督或過程監督。結果監督提供對最終結果的反饋，而過程監督則提供對每個中間推理步驟的反饋。考慮到訓練可靠模型的重要性，以及人類反饋的高成本，仔細比較這兩種方法是很重要的。近期的研究已開始進行此比較，但仍有許多問題待解決。我們進行了自己的調查，發現過程監督在訓練模型解決來自具有挑戰性的MATH數據集的問題時，顯著優於結果監督。我們的過程監督模型能解決 MATH 測試集中代表性子集中 78% 的問題。此外我們展示了主動學習顯著提高了過程監督的效果。為了支持相關研究，我們還釋出了 PRM800K 數據集，其中包含了 80 萬個步驟級別的人類反饋標籤，用於訓練我們最佳的獎勵模型。
論文連結：https://arxiv.org/pdf/2305.20050.pdf
57. Phi-1
論文名稱：Textbooks Are All You Need
發布時間：2023/06/20
發布單位：Microsoft
簡單摘要：高品質的小數據勝過大數據和大模型
閱讀重點：importance of high-quality data、用transformer過濾datasets、synthetic textbook-quality datasets、data pruning
中文摘要：我們推出了 phi-1，一款針對程式碼的新型大型語言模型，規模遠小於競爭對手的模型：phi-1是一個基於 Transformer 的模型，擁有 13 億參數，在 8 個 A100 GPU 上訓練了 4 天，使用了來自網絡“教科書級別”的資料（60億標記）和使用 GPT-3.5 合成生成的教科書和練習題（10億標記）。儘管規模小，phi-1 在 HumanEval 上達到了 50.6% 的 pass@1 準確率，以及 MBPP 上的 55.5%。與 phi-1-base 相比（我們在編程練習數據集上進行微調之前的模型），phi-1 也展現了令人驚訝的新特性，以及與 phi-1-small（另一個具有 3.5 億參數的較小模型）相比的性能，後者在 HumanEval 上仍然達到了 45%。
論文連結：https://arxiv.org/pdf/2306.11644.pdf
58. LLaMA 2
論文名稱：Llama 2: Open Foundation and Fine-Tuned Chat Models
發布時間：2023/07/18
發布單位：Facebook(Meta)
簡單摘要：開源LLM第二代，可以和人對話了
閱讀重點：pretraining、supervised fine-tuning、RLHF、system message for multi-turn consistency、learnings and observations
中文摘要：這份研究中，我們開發並釋出了 Llama 2，一系列預訓練和微調的大型語言模型（LLMs），規模從 70 億到 700 億參數不等。我們的微調模型 Llama 2-Chat 針對對話場景進行了優化。在我們測試的大多數基準測試中，我們的模型優於開源對話模型，根據我們的人工評估，在幫助性和安全性方面，它們可能是閉源模型的合適替代品。最後我們提供了對 Llama 2-Chat 的微調和安全性改進的詳細描述，以便社群能夠建立在我們工作基礎上並促進LLMs的負責任發展。
論文連結：https://arxiv.org/pdf/2307.09288.pdf
59. Code Llama
論文名稱：Code Llama: Open Foundation Models for Code
發布時間：2023/08/24
發布單位：Facebook(Meta)
簡單摘要：會寫程式的開源LLM
閱讀重點：infilling、long context fine-tuning、instruction fine-tuning
中文摘要：我們釋出 Code Llama，這是基於 Llama 2 的一系列大型程式碼語言模型，具有開源模型中最頂尖的表現，包括填充能力、支援大型輸入內容，以及在程式設計任務中具有零樣本指令追蹤的能力。我們提供多個版本以涵蓋廣泛的應用：基礎模型（Code Llama）、Python 特化模型（Code Llama — Python）和指令追蹤模型（Code Llama — Instruct），分別擁有 7B、13B 和 34B 參數。所有模型訓練的序列長度為 16k tokens，並可改善長達 100k tokens 的輸入。7B 和 13B 的 Code Llama 和 Code Llama — Instruct 可根據周圍內容進行填充。Code Llama 在多個程式碼基準測試中達到了開源模型的最頂尖表現，分別在 HumanEval 和 MBPP 上得分高達 53% 和 55%。值得注意的是，Code Llama — Python 7B 在 HumanEval 和 MBPP 上優於 Llama 2 70B，而我們的所有模型也優於其他公開可用模型中的每一個，特別是在 MultiPL-E 上。我們以開放授權釋出 Code Llama，可用於研究和商業用途。
論文連結：https://arxiv.org/pdf/2308.12950.pdf
60. RLAIF
論文名稱：RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback
發布時間：2023/08/24
發布單位：Google
簡單摘要：讓社會化的LLM來社會化LLM
閱讀重點：preference labeling with LLMs、addressing position bias、distilled RLAIF、direct RLAIF、evaluation
中文摘要：強化學習從人類反饋中學習（RLHF）已被證明能有效讓大型語言模型（LLMs）與人類偏好保持一致。然而收集高品質的人類偏好標籤可能耗時且昂貴。前人所提出的AI反饋強化學習（RLAIF）提供了一種有希望的替代方案，它利用強大的現成LLM來生成偏好，取代了人類標註者。在摘要、有幫助的對話生成和無害對話生成等任務中，RLAIF獲得了與RLHF相當或更優的表現。此外在另一個實驗中，直接向LLM提供獎勵分數的提示方法，即使LLM偏好標註生成器與策略大小相同，也能比典型的RLAIF設置獲得更好的表現。最後我們對生成符合AI偏好的技術進行了廣泛研究。我們的結果表明，RLAIF能達到人類水平的性能，為克服RLHF的擴展性限制提供了潛在解決方案。
論文連結：https://arxiv.org/pdf/2309.00267.pdf
61. OPRO
論文名稱：Large Language Models as Optimizers
發布時間：2023/09/07
發布單位：DeepMind
簡單摘要：讓LLM自己來優化prompt吧
閱讀重點：natural language descriptions.、meta-prompt、exploration-exploitation trade-off、limitations
中文摘要：優化無所不在。雖然基於衍生的演算法在許多問題中效果很好，但應用於真實世界的挑戰在於缺乏梯度資訊。所以在這篇論文中，我們提出了「提示優化」（OPRO），這是一種善用大型語言模型（LLMs）作為優化器的簡單而有效方法，其中優化任務是以自然語言描述。在每個優化步驟中，LLM根據先前生成的解答和其值的提示生成新的解答，然後將新的解答評估並添加到提示中，供下一個優化步驟使用。我們首先展示了在線性回歸和旅行商問題上的OPRO效果，然後轉向提示優化，目標是找到最大化任務準確性的指令。通過多種LLMs，我們展示了OPRO優化的最佳提示在GSM8K上比人工設計的提示提高了多達8%，在Big-Bench Hard任務上提高了多達50%。
論文連結：https://arxiv.org/pdf/2309.03409.pdf
62. vLLM
論文名稱：Efficient Memory Management for Large Language Model Serving with PagedAttention
發布時間：2023/09/12
發布單位：加州大學柏克萊分校、史丹佛大學、加州大學聖地亞哥分校
簡單摘要：用虛擬記憶體和paging技術加速LLM運算
閱讀重點：memory challenges in LLM、PagedAttention、KV cache manager、decoding、distributed execution
中文摘要：將大型語言模型（LLMs）進行高吞吐服務需要一次處理足夠多的請求。然而現有系統存在問題，因為每個請求所需的鍵值緩存（KV緩存）記憶體龐大且動態增減。管理不當時，這種記憶體可能會因碎片化和重複而大量浪費，限制了批處理大小。為解決此問題，我們提出了PagedAttention，一種受到作業系統中經典虛擬記憶體和分頁技術啟發的注意力演算法。基於此演算法，我們構建了vLLM，一個LLM服務系統，實現了（1）KV緩存記憶體幾乎沒有浪費，以及（2）在請求內外靈活共享KV緩存，進一步減少記憶體使用。我們的評估顯示，與FasterTransformer和Orca等最新系統相比，vLLM可以將熱門LLMs的吞吐量提高2–4倍，並保持相同的延遲水平。對於更長的序列、更大的模型和更複雜的解碼演算法，改進效果更為顯著。
論文連結：https://arxiv.org/pdf/2309.06180.pdf
63. Mamba
論文名稱：Mamba: Linear-Time Sequence Modeling with Selective State Spaces
發布時間：2023/12/01
發布單位：卡內基麥隆大學、普林斯頓大學
簡單摘要：超越Transformer，基於state space models的新架構
閱讀重點：state space models、selective state space models、evaluation
中文摘要：我們的基礎模型大多採用Transformer架構及其核心的注意力模組，支持了許多深度學習的應用。為了解決Transformer在處理長序列時的計算效率問題，開發了許多次線性時間的架構，例如線性注意力、閘控卷積和循環模型以及結構化狀態空間模型（SSM）。然而它們在語言等重要模式上的表現不及注意力模型。我們發現這些模型的一個關鍵弱點在於它們無法進行基於內容的推理，並做了一些改進。首先我們將SSM參數設置為輸入的函數可以解決其在離散模式下的弱點，使模型能夠根據當前標註選擇性地在序列長度維度上傳播或遺忘訊息。接下來即使這種改變阻止了有效卷積的使用，我們設計了一種硬體感知的平行運算演算法。我們將這些選擇性的SSM整合到一個簡化的端到端神經網絡架構中，不使用注意力甚至MLP模組，讓Mamba具有快速的推斷速度（比Transformer高出5倍），在序列長度上線性擴展，並在現實數據上表現提高，可處理長達百萬長度的序列。作為通用的序列模型基礎，Mamba在語言、音頻和基因組等多種模式上均達到了最先進的性能。在語言模型方面，我們的Mamba-3B模型，無論是在預訓練還是下游評估中。優於相同大小的Transformer模型，並與比其兩倍大小的Transformer模型相匹配。
論文連結：https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf
64. ReST-EM
論文名稱：Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models
發布時間：2023/12/12
發布單位：DeepMind
簡單摘要：用LLM產生資料來訓練LLM
閱讀重點：expectation-maximization for RL、reinforced self-training、ablation studies、reasoning capabilities
中文摘要：透過人類生成的數據對語言模型進行微調一直是一種常見的做法。然而這些模型的性能往往受到高品質人類數據的數量和多樣性的限制。本文探討在我們可以獲得標量反饋的任務中是否能超越人類數據，例如在可以驗證正確性的數學問題上。為此我們研究了一種基於期望最大化的簡單自我訓練方法，稱為ReST-EM：（1）從模型生成樣本並使用二元反饋過濾它們，（2）在這些樣本上對模型進行微調，（3）重複這個過程幾次。在使用PaLM-2模型進行高級數學推理和程式碼基準測試時，我們發現ReST-EM隨著模型尺寸的增加表現出優勢，明顯超越僅使用人類數據進行微調。整體而言，我們的研究結果表明，通過反饋的自我訓練能夠顯著減少對人類生成數據的依賴。
論文連結：https://arxiv.org/pdf/2312.06585.pdf
65. Superalignment
論文名稱：Weak-to-Strong Generalization: Eliciting Strong Capabilities with Weak Supervision
發布時間：2023/12/14
發布單位：OpenAI
簡單摘要：要人類能監督超級AI，先從小LLM監督大LLM開始
閱讀重點：strong student model with weak supervision、 ground truth labels as a ceiling、performance gap recovered、limitations
中文摘要：廣泛使用的對齊技術，比如從人類反饋中進行強化學習（RLHF），依賴於人類監督模型行為的能力，例如評估模型是否忠實地遵從指令或生成安全的輸出。但是未來的超級人工智慧模型將表現出複雜的行為，對人類來說難以可靠地評估，對於人類對超級人工智慧模型進行弱監督，我們研究了這個問題的類比：弱模型監督是否能喚起更強大模型的全部能力？我們在自然語言處理、西洋棋和獎勵建模任務上使用了一系列GPT-4系列的預訓練語言模型進行測試。我們發現，當我們用弱模型生成的標註來簡單微調強大的預訓練模型時，它們的表現一直優於弱監督模型，我們稱之為弱到強泛化現象。然而僅僅通過簡單微調，我們仍然離完全發揮強大模型的能力很遠，這表明像RLHF這樣的技術在不進一步研究的情況下可能無法應對超級人工智慧模型的挑戰。我們發現簡單的方法通常能顯著提高弱到強泛化能力：例如當用GPT-2級別的監督模型和輔助的置信損失來微調GPT-4時，我們在NLP任務上可以接近GPT-3.5的性能水準。我們的結果表明，當前在解決對齊超級人工智慧模型方面是有可能取得實際進展的。
論文連結：https://cdn.openai.com/papers/weak-to-strong-generalization.pdf
66. FunSearch
論文名稱：Mathematical discoveries from program search with large language models
發布時間：2023/12/14
發布單位：DeepMind
簡單摘要：突破人類思維，LLM解決人類無法解的數學問題
閱讀重點：prompt、program database、distributed approach、解決extremal combinatorics和bin packing問題、discussion
中文摘要：大型語言模型（LLMs）展現出在解決從量化推理到理解自然語言等複雜任務方面的巨大能力。然而LLMs有時會出現混淆（或幻覺）問題，導致它們提出似是而非但不正確的陳述。這阻礙了當前大型模型在科學探索中的應用。所以我們提出了FunSearch（在函數空間中搜索）方法，這是一種基於將預先訓練的LLM與系統性評估器進行配對的進化程序。我們展示了這種方法的有效性，超越了現有LLM方法在重要問題上的最佳結果，拓展了現有基於LLM的方法的範疇。將FunSearch應用於極值組合數學的核心問題 — cap set問題，我們發現了超越已知的最佳結果的大型cap set的新構造，無論是在有限維度還是漸進情況下。這代表了首次使用LLMs解決已知開放問題的發現。另外我們展示了FunSearch的通用性，將其應用於一個演算法問題 — 在線裝箱問題，找到了改進廣泛使用基線的新啟發式方法。與大多數電腦搜索方法不同，FunSearch搜索描述如何解決問題的程序，而不是解決方案。除了是一種有效和可擴展的策略外，發現的程序往往比原始解決方案更易於理解，可以實現領域專家與FunSearch之間的反饋循環，並將這些程序應用於真實世界應用中。
論文連結：https://www.nature.com/articles/s41586-023-06924-6
小心得

其實我們可以從這66篇的論文裡面發現，發布這些革命性的論文的機構組織都是那幾個，公司部分像是Google、DeepMind、OpenAI、Meta、Microsoft，學校部分像是Stanford、Berkeley、CMU、Princeton、MIT。這樣的體系就構成了現今三局鼎力的局勢：

Google和DeepMind陣營 — Gemini、Bard
Microsoft和OpenAI陣營 —ChatGPT、Bing
Meta開源社群陣營 — Llama

除此之外我們還可以發現一件有趣的事情

Transformer到BERT/GPT相隔一年左右 → encoder-decoder/seq2seq時代
BERT/GPT到GPT-3相隔一年半左右 → prompting時代
GPT-3到FLAN相隔一年三個月左右 → instruction時代
FLAN到chain-of-thought相隔五個月左右 → CoT時代
chain-of-thought到ChaGPT發布相隔一年左右 → LLM時代

然後LLM領域就開始大爆發了

ChaGPT到Llama相隔3個月左右 → 開源LLM百花齊放時代
Llama到GPT-4相隔3個月左右 → multimodality時代
GPT-4到RLAIF相隔3個月左右 → LLM自己訓練自己時代
RLAIF到Superalignment相隔3個月左右 → ASI概念時代?

不僅在NLP領域，Image、Audio、Video、3D都全面爆發，而接下來2024年AI領域又會發展的比2023年來得快更多更多，為什麼呢？因為2023年開始一大票人開始崇尚e/acc (Effective Accelerationism)有效加速主義

Effective accelerationism - Wikipedia
Effective accelerationism, often abbreviated as " e/acc", is a 21st-century philosophical movement that explicitly…

en.wikipedia.org

所以接下來大家得坐穩了，準備迎接超級人工智慧的到來！

作者：劉智皓

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Deep Learning
Machine Learning
Llm
Aigc
Transformers

260

1

Written by 劉智皓 (Chih-Hao Liu)
406 Followers

豬屎屋ML Engineer，熱愛AI Model/Research、5G 3GPP/ETSI/O-RAN Spec、Linux Programming，是一個什麼都想學的工作狂。喜歡popping、旅遊和吃壽司~ 🤗

Follow
More from 劉智皓 (Chih-Hao Liu)

劉智皓 (Chih-Hao Liu)

66個擴散模型Diffusion Models經典論文
75 min read
·
Dec 24, 2023

9

劉智皓 (Chih-Hao Liu)

機器學習_學習筆記系列(11)：正則化(Regularization)、Lasso Regression 和Ridge Regression
…
7 min read
·
Feb 3, 2021

35

劉智皓 (Chih-Hao Liu)

從申請到畢業：雙主修和輔系攻略！
繼上一次轉系的文後，我也來寫寫關於雙主修和輔系相關的文，在過去也很多學弟妹問過我相關的問題，像是YY系要雙什麼系才有競爭力，或是我OO系我想雙XX系課表要怎麼排。所以我在這篇文，會針對雙輔的心態、心路歷程、課表安排等等去寫。另外本篇就不介紹雙輔是什麼、要修多少學分之類的，這個看學…
9 min read
·
Oct 22, 2020

158

1

劉智皓 (Chih-Hao Liu)

機器學習_學習筆記系列(13)：交叉驗證(Cross-Validation)和MSE、MAE、R2
到目前為止我們讓機器學習和驗證的方式都一樣，都是按照特定比例，然後隨機抽取一些資料當作我們的測試集，而剩下的就是我們的訓練集。然而我們可以發現一些問題，假設我們今天想要讓機器學習分辨貓跟狗，但是我們今天很不幸的，剛好隨機抽樣，拿去訓練的都是狗的圖片，拿去測試的都是貓的圖片，我們就…
7 min read
·
Feb 7, 2021

26

See all from 劉智皓 (Chih-Hao Liu)
Recommended from Medium

Cobus Greyling

T-RAG = RAG + Fine-Tuning + Entity Detection
The T-RAG approach is premised on combining RAG architecture with an open-source fine-tuned LLM and an entities tree vector database. The…
5 min read
·
Feb 15, 2024

831

8

James Nguyen

in

Data Science at Microsoft

Forget RAG: Embrace agent design for a more intelligent grounded ChatGPT!
The Retrieval Augmented Generation (RAG) design pattern has been commonly used to develop a grounded ChatGPT in a specific data domain…
6 min read
·
Nov 18, 2023

1.8K

20

Lists
Predictive Modeling w/ Python
20 stories
·
966 saves
Practical Guides to Machine Learning
10 stories
·
1146 saves
Natural Language Processing
1253 stories
·
733 saves
data science and AI
40 stories
·
92 saves

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.9K

44

Mastering LLM (Large Language Model)

LLM Training: A Simple 3-Step Guide You Won’t Find Anywhere Else!
Discover How Language Models are Trained in 3 Easy Steps
6 min read
·
Oct 1, 2023

248

3

Geronimo

Finetuning Llama 2 and Mistral
A beginner’s guide to finetuning LLMs with QLoRA
17 min read
·
Nov 6, 2023

807

16

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:31.089 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.308 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 4272, completion_tokens: 289
2024-03-04 22:03:31.094 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "使用大型语言模型进行数值计算的挑战".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

大语言模型数据隐私的解决之道：全同态加密

Ingonyama 中文

·

Follow

Sep 24, 2023

--

原文链接：https://medium.com/@ingonyama/solving-llm-privacy-with-fhe-3486de6ee228

人工智能的崛起令人叹为观止。从基本算法到最先进的形式 — 大语言模型（LLM），如 ChatGPT 和 Copilot — 人工智能处于技术演进的前沿。

随着这些模型与用户互动并处理大量数据和提示，数据隐私的问题就变得非常重要。亚马逊和苹果等公司已经限制员工访问ChatGPT等公共API，以防止因人工智能交互而导致的数据泄露。此外，可以合理地预期，很快将出台法规来要求一定程度的用户隐私保护。

我们如何确保与这些模型的交互、提问和共享的数据保持隐私呢？

全同态加密 (FHE) 深度解读

在密码学领域，全同态加密是一个突破性的概念。它的魅力在于神奇的特性：它允许对加密数据进行计算，而无需先解密，实现对敏感信息的隐私推理。

借助这种特性可以确保两个重要的事情：数据在处理过程中保持安全，以及对模型的知识产权（IP）的完全保护。

隐私推理与知识产权保护

如今，”隐私 “和 “用户体验 “似乎是鱼和熊掌不可兼得。人们往往为了更好的体验，将自己的信息托管到第三方公司。我们相信，这些第三方公司可以平衡好隐私与优质的服务，而不必在隐私性更高但缺少功能的本地解决方案或牺牲隐私以获得丰富功能的服务之间做出选择。

全同态加密能够在完全保护模型知识产权的情况下实现隐私推理。通过对加密数据进行计算，它可以确保提示词完全保密，同时还能保护大语言模型的知识产权。

传统加密技术与全同态加密技术

在传统加密领域，如果对加密数据进行有意义的运算，首先需要对其进行解密。但是解密就意味着易受到攻击，哪怕是一瞬间。
相比之下，全同态加密可以直接对密文进行运算，确保敏感信息在整个运算过程中保持隐私。

全同态加密的重要性

全同态加密的重要性不仅限于理论。想象一下云计算服务，可以在不解密数据的情况下进行数据处理，或者医疗数据库可以在不获取敏感患者详细信息的情况下进行分析。全同态加密的潜在应用非常广泛且多样化，包括安全投票系统和对加密数据库进行隐私搜索等。

全同态加密的数学理论

全同态加密利用容错学习（LWE）问题，这是一种格子密码学技术，具有抗量子性。在容错学习中，利用随机噪声使数据变得不可读，除非拥有秘钥。对加密数据进行算术运算是可能的，但这通常会增加噪声水平。如果连续进行过多的运算，任何人都无法读取数据，包括持有密钥的人。

这就是部分同态加密（SHE）。要将部分同态加密转换为全同态加密，需要一种能降低噪音水平的操作。这种操作被称为 “自举”（Bootstrapping），多种全同态加密方案都采用了自举操作。在本文中，我们将重点讨论环面上的全同态加密方案(Torus FHE)，它利用数学环面的代数结构来实现 全同态加密。

环面全同态加密的优势

尽管每种全同态加密方案都有自己的优缺点，但在实际场景中，TFHE目前拥有更高效的实现。TFHE的另一个重要优势在于其可编程自举（Programmable Bootstrapping，PBS），它将通常的自举操作扩展到包括对单变量函数的计算，例如在机器学习领域中至关重要的激活函数。

TFHE 的一个劣势是要求在计算中每执行一次算术运算都要执行一次 PBS 操作，而其他方案则允许在自举操作之间批量执行一些操作。

关于全同态加密推理时间的假设与逼近

为了估计使用全同态加密进行大语言模型推理所需的时间，我们做出了一些假设：

每个令牌所需的算术操作次数大约是模型中参数数量的1–2倍。这是一个下限，因为每个令牌都使用了整个模型，我们将假设这个下限足够接近实际需求。
大语言模型中的每个算术操作都可以映射到TFHE中的一个算术操作。这基本上是两种方案中变量类型大小的说明。我们假设对于大语言模型来说，INT4变量足够，并且对于TFHE来说是可行的。
大语言模型中的每个算术操作都需要映射到全同态加密中的一个算术操作。这意味着我们不能在未加密的情况下运行模型的一部分。Zama最近的一篇博文考虑了不使用这个假设的FHE推理，其中大部分模型由用户在本地执行，没有任何加密，只有一个小部分（例如单个注意力头）在模型的公司服务器上使用全同态加密运行。我们认为，这种方法实际上并没有保护模型的知识产权，因为在这种情况下，用户可以只运行缺失的头部，并且只有轻微的精度损失，如此处所示，或者对缺失部分进行相对廉价的训练，以获得与原始模型相当的结果。
TFHE中的每个算术操作都需要进行一次PBS（可编程自举）。PBS是TFHE计算的主要瓶颈。
目前最先进的TFHE实现是FPT。这是一种FPGA实现，以每35微秒计算一次PBS。
在大语言模型中使用全同态加密的挑战

随着最新技术的进展，目前最好的全同态加密实现可以在仅需35微秒的时间内执行一次算术操作。然而，当考虑到像GPT2这样复杂的模型时，单个令牌需要进行惊人的15亿次操作。这意味着每个令牌的处理时间约为52,000秒。

为了更好地理解，对于语言模型来说，一个令牌可以表示一个字符或一个完整的单词等内容。想象一下与一个语言模型进行交互，其中响应时间需要一两个星期！这样的延迟显然对于实时通信或模型的任何实际应用都是不可行的。

这显示了在当前的全同态加密技术下，对于大规模的语言模型来说，实现实时推理仍然是一个巨大的挑战。尽管全同态加密在数据保护方面具有重要意义，但在需要高度计算密集型的任务中，其性能限制可能使其难以应用于实际场景。对于实时交互和快速响应的需求，可能需要探索其他的安全计算和隐私保护解决方案。

潜在的解决方案

为了使全同态加密应用到大语言模型中，以下是一个可能的路线图：

使用多机器实现并行处理：
从每个令牌的52,000秒开始。
通过部署10,000个并行机器，我们将时间缩短到每个令牌的5秒。请注意，大语言模型确实可以高度并行化，目前的推理通常在数千个或更多的GPU核心上并行执行。

2. 过渡到先进的硬件：

从改进后的每个令牌的5秒开始。
切换到GPU或ASIC，我们可以实现每个令牌0.1秒的处理时间。虽然GPU可以在速度上提供更直接的收益，但ASIC在速度和功耗方面都可以提供更高的收益，例如ZPU就是这样的例子。

正如图所示，使用现有的数据加速技术，通过全同态加密可以实现大语言模型的私有推理。一个大型但可行的初始投资可以支持建立足够大的数据中心来实现这一目标。然而，这种可能性仍然是微乎极微的，并且对于更大的大语言模型，如Copilot（120亿参数）或GPT3（1750亿参数），仍存在差距需要弥补。

对于Copilot来说，较小的令牌吞吐量就足够了，因为它生成的是代码输出，通常比人类语言更简洁。如果我们将吞吐量要求降低8倍，那么Copilot也能达到可行性的目标。

最后的差距可以通过组合更大规模的并行化、更好的实现以及在全同态加密中进行引导的更高效算法来弥补。在Ingonyama，我们相信算法是弥合这一差距的重要组成部分，我们的团队目前正专注于算法的研究和开发。

结束语

全同态加密的安全性和大语言模型的计算能力的结合可以重新定义人工智能交互，确保效率和隐私两者兼顾。虽然存在一些挑战，但通过持续的研究和创新，我们可以实现与AI模型（如ChatGPT）的交互既具有即时性又具有隐私性的未来。这将为用户提供更高效和安全的体验，并推动人工智能技术在各个领域的广泛应用。

关注我们的进展

Twitter: https://twitter.com/Ingo_zk

Github: https://github.com/ingonyama-zk

YouTube: https://www.youtube.com/@ingo_zk

LinkedIn: https://www.linkedin.com/company/ingonyama

加入我们：https://www.ingonyama.com/careers

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
密碼學
人工智能
大语言模型
ChatGPT
Github Copilot

--

Written by Ingonyama 中文
18 Followers
Follow

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:35.271 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.328 | Max budget: $10.000 | Current cost: $0.020, prompt_tokens: 6003, completion_tokens: 477
2024-03-04 22:03:35.272 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "改进大型语言模型在数值计算中的准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

Footprint Analytics x Future3 Campus联合发布AI与Web3研究报告

Future3 Campus

·

Follow

29 min read
·
Dec 5, 2023

--

GPT的横空出世将全球的目光吸引至大语言模型，各行各业都尝试着利用这个“黑科技”提高工作效率，加速行业发展。Future3 Campus携手Footprint Analytics共同深入研究AI与Web3结合的无限可能，联合发布了《AI与Web3数据行业融合现状、竞争格局与未来机遇探析》研报。该研报分为上下两篇，本文为上篇，由Footprint Analytics研究员Lesley、Shelly共同编撰。

摘要：

LLM 技术的发展让人们更加关注 AI 与 Web3 的结合，新的应用范式正在逐步展开。本文中，我们将重点研究如何利用 AI 提升 Web3 数据的使用体验和生产效率。
由于行业尚处早期阶段和区块链技术的特性，Web3 数据行业面临着诸多挑战，包括数据来源、更新频率、匿名属性等，使得利用 AI 解决这些问题成为新关注点。
LLM 相对于传统人工智能的可扩展性、适应性、效率提升、任务分解、可访问性和易用性等优势，为提高区块链数据的体验和生产效率提供了想象空间。
LLM 需要大量高质量数据进行训练，而区块链领域垂直知识丰富且数据公开，可以为 LLM 提供学习素材。
LLM 也可以帮助生产和提升区块链数据的价值，例如数据清洗、标注、生成结构化数据等。
LLM 不是万灵药，需要针对具体业务需求进行应用。既要利用 LLM 的高效率，同时也要注意结果的准确性。

AI 与 Web3 的发展与结合

1.1 AI 的发展历史

人工智能（AI）的历史可以追溯到上个世纪 50 年代。自 1956 年起，人们开始关注人工智能这一领域，逐渐发展出了早期的专家系统，帮助专业领域解决问题。此后，机器学习的兴起，拓展了 AI 的应用领域，AI 开始更广泛地应用在各行各业。到如今，深度学习和生成式人工智能爆发，带给了人们无限可能性，其中的每一步都充满了不断的挑战与创新，以追求更高的智能水平和更广泛的应用领域。

图 1：AI 发展历程

2022 年 11 月 30 日，ChatGPT 面世，首次展示了 AI 与人类低门槛、高效率交互的可能性。ChatGPT 引发了对人工智能的更广泛探讨，重新定义了与 AI 互动的方式，使其变得更加高效、直观和人性化，也推动了人们对更多生成式人工智能的关注，Anthropic（Amazon）、DeepMind（Google）、Llama 等模型也随后进入人们的视野。与此同时，各行各业的从业者也开始积极探索 AI 会如何推动他们所在领域的发展，或者寻求通过与 AI 技术的结合在行业中脱颖而出，进一步加速了 AI 在各个领域的渗透。

1.2 AI 与 Web3 的交融

Web3 的愿景从改革金融体系开始，旨在实现更多的用户权力，并有望引领现代经济和文化的转变。区块链技术为实现这一目标提供了坚实的技术基础，它不仅重新设计了价值传输和激励机制，还为资源分配和权力分散提供了支持。

图 2：Web3 发展历程

早在 2020 年，区块链领域的投资公司 Fourth Revolution Capital（4RC）就曾指出，区块链技术将和 AI 结合，通过对金融、医疗、电子商务、娱乐等全球行业的去中心化，以实现对现有行业的颠覆。

目前，AI 与 Web3 的结合，主要是两大方向：

利用 AI 去提升生产力以及用户体验。
结合区块链透明、安全、去中心化存储、可追溯、可验证的技术特点，以及 Web3 去中心化的生产关系，解决传统技术无法解决的痛点或者激励社区参与，提高生产效率。

市场上 AI 与 Web3 的结合有以下的一些探索方向：

图 3：AI 与 Web3 结合全景图
数据：区块链技术可以应用在模型数据存储上，提供加密数据集，保护数据隐私和记录模型使用数据的来源、使用情况，以及校验数据的真实性。通过访问和分析存储在区块链上的数据，AI 可以提取有价值的信息，并用于模型训练和优化。同时，AI 也可以作为数据生产工具，去提高 Web3 数据的生产效率。
算法：Web3 中的算法可以为 AI 提供更安全、可信和自主控制的计算环境，为 AI 体统提供加密保障，在模型参数上，内嵌安全防护栏，防止系统被滥用或者恶意操作。AI 可以与 Web3 中的算法进行交互，例如利用智能合约执行任务、验证数据和执行决策。同时，AI 的算法也可以为 Web3 提供更智能化和高效的决策和服务。
算力：Web3 的分散式计算资源可以为 AI 提供高性能的计算能力。AI 可以利用 Web3 中的分散式计算资源进行模型的训练、数据分析和预测。通过将计算任务分发到网络上的多个节点，AI 可以加快计算速度，并处理更大规模的数据。

在本文中，我们将重点探索如何利用 AI 的技术，去提升 Web3 数据的生产效率以及使用体验。

Web3数据现状

2.1 Web2 & Web3 数据行业对比

作为 AI 最核心的组成部分“数据”，在 Web3 跟我们熟悉的 Web2 很着很多的区别。差异主要是在于 Web2 以及 Web3 本身的应用架构导致其产生的数据特征有所不同。

2.1.1 Web2 & Web3 应用架构对比

图 4：Web2 & Web3 应用架构

在 Web2 架构中，通常是由单一实体（通常是一家公司）来控制网页或者 APP，公司对于他们构建的内容有着绝对的控制权，他们可以决定谁可以访问其服务器上的内容和逻辑，以及用户拥有怎样的权益，还可以决定这些内容在网上存在的时长。不少案例表明，互联网公司有权改变其平台上的规则，甚至中止为用户提供服务，而用户对此无法保留所创造的价值。

而 Web3 架构则借助了通用状态层（Universal State Layer）的概念，将一部分或者全部的内容和逻辑放置在公共区块链上。这些内容和逻辑是公开记录在区块链上的，可供所有人访问，用户可以直接控制链上内容和逻辑。而在 Web2 中，用户需要帐户或 API 密钥才能与区块链上的内容进行交互。用户可以直接控制其对应的链上内容和逻辑。不同于 Web2，Web3 用户无需授权帐户或 API 密钥就能与区块链上的内容进行交互（特定管理操作除外）。

2.1.2 Web2 与 Web3 数据特征对比

图 5：Web2 与 Web3 数据特征对比

Web2 数据通常表现为封闭和高度受限的，具有复杂的权限控制，高度成熟、多种数据格式、严格遵循行业标准，以及复杂的业务逻辑抽象。这些数据规模庞大，但互操作性相对较低，通常存储在中央服务器上，且不注重隐私保护，大多数是非匿名的。

相比之下，Web3 数据更加开放，访问权限更广泛，尽管成熟度较低，以非结构化数据为主，标准化较为罕见，业务逻辑抽象相对简化。Web3 的数据规模相对 Web2 较小，但它具有较高的互操作性（比如 EVM 兼容），并可分散或集中存储数据，同时强调用户隐私，用户通常采用匿名方式进行链上交互。

2.2 Web3 数据行业现状与前景，以及遇到的挑战

在 Web2 时代，数据如石油的“储量”般珍贵，访问和获取大规模数据一直是极大的挑战。在 Web3 中，数据的开放性和共享性一下子让大家觉得“石油到处都是”，使得 AI 模型能够更轻松地获取更多的训练数据，这对于提高模型性能和智能水平至关重要。但对 Web3 这个“新石油” 的数据处理依然有很多问题待解决，主要有以下几个：

数据来源：链上数据“标准”繁杂分散，数据处理花费大量人工成本

处理链上数据时，需要反复执行耗时而劳动密集的索引过程，需要开发者和数据分析师花费大量时间和资源来适应不同链、不同项目之间的数据差异。链上数据行业缺乏统一的生产和处理标准，除了记录到区块链账本上的，events，logs，and traces 等都基本上是项目自己定义和生产（或生成）的，这导致非专业交易者很难辨别并找到最准确和可信的数据，增加了他们在链上交易和投资决策中的困难。比如，去中心化交易所 Uniswap 和 Pancakeswap 就有可能在数据处理方法和数据口径上存在差异，过程中的检查和统一口径等工序进一步加大了数据处理的复杂性。

数据更新：链上数据体量大且更新频率高，难以及时地处理成结构化数据

区块链是时刻变动的，数据更新以秒甚至毫秒级别计。数据的频繁产生和更新使其难以维持高质量的数据处理和及时的更新。因此，自动化的处理流程是十分重要的，这也是对于数据处理的成本和效率的一大挑战。Web3 数据行业仍处于初级阶段。随着新合约的层出不穷和迭代更新，数据缺乏标准、格式多样，进一步增加了数据处理的复杂性。

数据分析：链上数据的匿名属性，导致数据身份难以区分

链上数据通常不包含足够的信息来清晰识别每个地址的身份，这使得数据在与链下的经济、社会或法律动向难以联动。但是链上数据的动向与现实世界紧密相关，了解链上活动与现实世界中特定个体或实体的关联性对于特定的场景比如数据分析来说十分重要。

随着大语言模型（LLM）技术引发的生产力变更讨论，能否利用 AI 来解决这些挑战也成为 Web3 领域的一个焦点关注之一。

AI 与 Web3 数据碰撞产生的化学反应

3.1 传统 AI 与 LLM 的特征对比

在模型训练方面，传统 AI 模型通常规模较小，参数数量在数万到数百万之间，但为了确保输出结果的准确性，需要大量的人工标注数据。LLM 之所以如此强大，部分原因在于其使用了海量的语料拟合百亿、千亿级以上的参数，极大地提升了它对自然语言的理解能力，但这也意味着需要更多的数据来进行训练，训练成本相当高昂。

在能力范围和运行方式上，传统 AI 更适合特定领域的任务，能够提供相对精准和专业的答案。相比之下，LLM 更适合通用性任务，但容易产生幻觉问题，这意味着在一些情况下，它的回答可能不够精确或专业，甚至完全错误。因此，如果需要和客观，可信任，和可以追溯的结果，可能需要进行多次检查、多次训练或引入额外的纠错机制和框架。

图 6：传统 AI 与大模型语言模型 （LLM）的特征对比

3.1.1 传统 AI 在 Web3 数据领域的实践

传统 AI 已经在区块链数据行业展现了其重要性，为这一领域带来了更多创新和效率。例如，0xScope 团队采用 AI 技术，构建了基于图计算的群集分析算法，通过不同规则的权重分配来帮助准确识别用户之间的相关地址。这种深度学习算法的应用提高了地址群集的准确性，为数据分析提供了更精确的工具。Nansen 则将 AI 用于 NFT 价格预测，通过数据分析和自然语言处理技术，提供有关 NFT 市场趋势的见解。另一方面，Trusta Labs使用了基于资产图谱挖掘和用户行为序列分析的机器学习方法，以增强其女巫检测解决方案的可靠性和稳定性，有助于维护区块链网络生态的安全。另一方面，Trusta Labs 采用了图挖掘和用户行为分析的方法，以增强其女巫检测解决方案的可靠性和稳定性，有助于维护区块链网络的安全。Goplus 在其运营中利用传统人工智能来提高去中心化应用程序（dApps）的安全性和效率。他们收集和分析来自 dApp 的安全信息，提供快速风险警报，帮助降低这些平台的风险敞口。这包括通过评估开源状态和潜在恶意行为等因素来检测 dApp 主合同中的风险，以及收集详细的审计信息，包括审计公司凭证、审计时间和审计报告链接。Footprint Analytics 则使用 AI 生成生产结构化数据的代码，分析 NFT 交易 Wash trading 交易以及机器人账户筛选排查。

然而，传统 AI 拥有的信息有限，专注于使用预定的算法和规则执行预设任务，而 LLM 则通过大规模的自然语言数据学习，可以理解和生成自然语言，这使其更适合处理复杂且巨量的文本数据。

最近，随着 LLM 取得了显著进展，人们对 AI 与 Web3 数据的结合，也进行了一些新的思考与探索。

3.1.2 LLM 的优势

LLM 相对于传统人工智能具有以下优势：

可扩展性：LLM 支持大规模数据处理

LLM 在可扩展性方面表现出色，能够高效处理大量数据和用户互动。这使其非常适合处理需要大规模信息处理的任务，如文本分析或者大规模数据清洗。其高度的数据处理能力为区块链数据行业提供了强大的分析和应用潜力。

适应性：LLM 可学习适应多领域需求

LLM 具备卓越的适应性，可以为特定任务进行微调或嵌入行业或私有数据库，使其能够迅速学习和适应不同领域的细微差别。这一特性使 LLM 成为了解决多领域、多用途问题的理想选择，为区块链应用的多样性提供了更广泛的支持。

提高效率：LLM 自动化任务提高效率

LLM 的高效率为区块链数据行业带来了显著的便利。它能够自动化原本需要大量人工时间和资源的任务，从而提高生产力并降低成本。LLM 可以在几秒内生成大量文本、分析海量数据集，或执行多种重复性任务，从而减少了等待和处理时间，使区块链数据处理更加高效。

任务分解：可以生成某些工作的具体计划，把大的工作分成小步骤

LLM Agent 具备独特的能力，即可以生成某些工作的具体计划，将复杂任务分解为可管理的小步骤。这一特性对于处理大规模的区块链数据和执行复杂的数据分析任务非常有益。通过将大型工作分解成小任务，LLM 可以更好地管理数据处理流程，并输出高质量的分析。

这一能力对于执行复杂任务的 AI 系统至关重要，例如机器人自动化、项目管理和自然语言理解与生成，使其能够将高级任务目标转化为详细的行动路线，提高任务执行的效率和准确性。

可访问性和易用性：LLM 以自然语言提供用户友好互动

LLM 的可访问性使更多用户能够轻松与数据和系统进行互动，让这些互动更加用户友好。通过自然语言，LLM 使数据和系统更容易访问和交互，无需用户学习复杂的技术术语或特定命令，例如，SQL，R，Python 等来做数据获取和分析。这一特性拓宽了区块链应用的受众范围，让更多的人能够访问和使用 Web3 应用和服务，不论他们是否精通技术，从而促进了区块链数据行业的发展和普及。

3.2 LLM 与 Web3 数据的融合

图 7：区块链数据与 LLM 的融合

大型语言模型的培训需要依赖大规模数据，通过学习数据中的模式来建立模型。区块链数据中蕴含的交互和行为模式是 LLM 学习的燃料。数据量和质量也直接影响 LLM 模型的学习效果。

数据不仅仅是 LLM 的消耗品，LLM 还有助于生产数据，甚至可以提供反馈。例如，LLM 可以协助数据分析师在数据预处理方面做出贡献，如数据清洗和标注，或者生成结构化数据，清除数据中的噪声，凸显有效信息。

3.3 增强 LLM 的常用技术解决方案

ChatGPT 的出现，不仅向我们展示了 LLM 解决复杂问题的通用能力，同时也引发了全球范围的，对在通用能力上去叠加外部能力的探索。这里包括，通用能力的增强（包括上下文长度、复杂推理、数学、代码、多模态等）以及外部能力的扩充（处理非结构化数据、使用更复杂的工具、与物理世界的交互等）。如何将 crypto 领域的专有知识以及个人的个性化私有数据嫁接到大模型的通用能力上，是大模型在 crypto 垂直领域商业化落地的核心技术问题。

目前，大多数应用都集中在检索增强生成（RAG）上，比如提示工程和嵌入技术，已经存在的代理工具也大多都聚焦于提高 RAG 工作的效率和准确性。市场上主要的基于 LLM 技术的应用栈的参考架构有以下几种：

Prompt Engineering
图 8：Prompt Engineering

当前，大多数从业者在构建应用时采用基础解决方案，即 Prompt Engineering。这一方法通过设计特定的 Prompt 来改变模型的输入，以满足特定应用的需求，是最方便快捷的做法。然而，基础的 Prompt Engineering 存在一些限制，如数据库更新不及时、内容冗杂、以及对输入上下文长度（In-Context Length）的支持和多轮问答的限制。

因此，行业内也在研究更先进的改进方案，包括嵌入（Embedding）和微调（Fine-tuning）。

嵌入（Embedding）

嵌入（Embedding）是一种广泛应用于人工智能领域的数据表示方法，能高效捕获对象的语义信息。通过将对象属性映射成向量形式，嵌入技术能够通过分析向量之间的相互关系，快速找到最有可能正确的答案。嵌入可以在 LLM 的基础上构建，以利用该模型在广泛语料上学到的丰富语言知识。通过嵌入技术将特定任务或领域的信息引入到预训练的大模型中，使得模型更专业化，更适应特定任务，同时保留了基础模型的通用性。

用通俗的话来讲，嵌入就类似于你给一个经过综合训练的大学生一本工具书，让他拿着拥有特定任务相关知识的工具书去完成任务，他可以随时查阅工具书，然后可以解决特定的问题。

微调（Fine-tuning）
图 9：Fine Tuning

微调（Fine-tuning）与嵌入不同，通过更新已经预训练的语言模型的参数，使其适应特定任务。这种方法允许模型在特定任务上表现出更好的性能，同时保持通用性。微调的核心思想是调整模型参数，捕捉与目标任务相关的特定模式和关系。但微调的模型通用能力上限仍然受限于基座模型本身。

用通俗的话来讲，微调就类似于给经过综合训练的大学生上专业知识课程，让他掌握除了综合能力以外的专业课知识，能自行解决专业板块的问题。

重新训练 LLM

当前的 LLM 虽然强大，但不一定能够满足所有需求。重新训练 LLM 是一种高度定制化的解决方案，通过引入新数据集和调整模型权重，使其更适应特定任务、需求或领域。然而，这种方法需要大量计算资源和数据，并且管理和维护重新训练后的模型也是挑战之一。

Agent 模型
图 10：Agent 模型

Agent 模型是一种构建智能代理的方法，它以 LLM 作为核心控制器。这个系统还包括几个关键组成部分，以提供更全面的智能。

Planning，规划：将大任务分成小任务，这样更容易完成
Memory，反思：通过反思过去的行为，改进未来的计划
Tools，工具使用：代理可以调用外部工具获取更多信息，如调用搜索引擎、计算器等

人工智能代理模型具备强大的语言理解和生成能力，能够解决通用问题，进行任务分解以及自我反思。这使得它在各种应用中都有广泛的潜力。然而，代理模型也存在一些局限性，例如受到上下文长度的限制、长期规划和任务拆分容易出错、输出内容的可靠性不稳定等问题。这些局限性需要长期不断的研究和创新，以进一步拓展代理模型在不同领域的应用。

以上的各种技术并不是相互排斥的，它们可以在训练和增强同一个模型的过程中一起使用。开发者可以充分发挥现有大语言模型的潜力，尝试不同的方法，以满足日益复杂的应用需求。这种综合使用不仅有助于提高模型的性能，还有助于推动 Web3 技术的快速创新和进步。

然而，我们认为，虽然现有的 LLM 已经在 Web3 的快速发展中发挥了重要作用，但在充分尝试这些现有模型（如 OpenAI、Llama 2 以及其他开源 LLM）之前，我们可以从浅入深，从 prompt engineering 和嵌入等 RAG 策略入手，谨慎考虑微调和重新训练基础模型。

3.4 LLM 如何加速区块链数据生产的各个流程

3.4.1 区块链数据的一般处理流程

当今，区块链领域的建设者逐渐认识到数据产品的价值。这一价值覆盖了产品运营监控、预测模型、推荐系统以及数据驱动的应用程序等多个领域。尽管这一认知逐渐增强，但作为数据获取到数据应用中不可或缺的关键步骤，数据处理往往被忽视。

图 11：区块链数据处理流程
将区块链原始非结构化数据，如 events 或 logs 等，转换为结构化的数据

区块链上的每一笔交易或事件都会生成 events 或 logs，这些数据通常是非结构化的。这一步骤是获取数据的第一入口，但数据仍然需要被进一步处理以提取有用信息，得到结构化的原始数据。这包括整理数据、处理异常情况和转化为通用格式。

将结构化的原始数据，转换为具有业务意义的抽象表

在得到结构化原始数据后，需要进一步进行业务抽象，将数据映射到业务实体和指标上，比如交易量、用户量等业务指标，将原始数据转化为对业务和决策有意义的数据。

从抽象表中，计算提取业务指标

有了抽象的业务数据后，可以在业务抽象的数据上进行进一步计算，就可以得出各种重要的衍生指标。例如交易总额的月增长率、用户留存率等核心指标。这些指标可以借助 SQL、Python 等工具实现，更加有可能帮助监控业务健康、了解用户行为和趋势，从而支持决策和战略规划。

3.4.2 区块链数据生成流程加入 LLM 后的优化

LLM 在区块链数据处理中可以解决多个问题，包括但不限于以下内容：

处理非结构化数据：

从交易日志和事件中提取结构化信息：LLM 可以分析区块链的交易日志和事件，提取其中的关键信息，如交易金额、交易方地址、时间戳等，将非结构化数据转化为的带有业务意义的数据，使其更易于分析和理解。
清洗数据，识别异常数据：LLM 可以自动识别和清洗不一致或异常的数据，帮助确保数据的准确性和一致性，从而提高数据质量。

进行业务抽象：

将原始链上数据映射到业务实体：LLM 可以将原始区块链数据映射到业务实体，例如将区块链地址映射到实际用户或资产，从而使业务处理更加直观和有效。
处理非结构化链上内容，打标签：LLM 可以分析非结构化数据，如 Twitter 情感分析结果，将其标记为正面、负面或中性情感，从而帮助用户更好地理解社交媒体上的情感倾向。

自然语言解读数据：

计算核心指标：基于业务抽象，LLM 可以计算核心业务指标，如用户交易量、资产价值、市场份额等，以帮助用户更好地了解其业务的关键性能。
查询数据：LLM 可以通过 AIGC，理解用户意图，生成 SQL 查询，使用户能够以自然语言提出查询请求，而不必编写复杂的 SQL 查询语句。这增加了数据库查询的可访问性。
指标选择、排序和相关性分析：LLM 可以帮助用户选择、排序和分析不同的多个指标，以更好地理解它们之间的关系和相关性，从而支持更深入的数据分析和决策制定。
产生业务抽象的自然语言描述：LLM 可以根据事实数据，生成自然语言摘要或解释，以帮助用户更好地理解业务抽象和数据指标，提高可解释性，并使决策更具合理性。

3.5 目前用例

根据 LLM 自身的技术以及产品体验优势，它可以被应用到不同的链上数据场景，技术上从易到难可以将这些场景分成四类：

数据转换：进行数据增强、重构等操作，如文本摘要、分类、信息抽取。这类应用开发较快，但更适合通用场景，不太适合大量数据的简单批量化处理。
自然语言接口：将 LLM 连接知识库或工具，实现问答或基本工具使用的自动化。这可以用于构建专业聊天机器人，但其实际价值受其所连接的知识库质量等其他因素影响。
工作流自动化：使用 LLM 实现业务流程的标准化和自动化。这可以应用于较复杂的区块链数据处理流程，如解构智能合约运行过程、风险识别等。
协助机器人与助手辅助系统：辅助系统是在自然语言接口的基础上，集成更多数据源和功能的增强系统，大幅提高用户工作效率。
图 12：LLM 应用场景

3.6 LLM 的局限性

3.6.1 行业现状：成熟应用、正在攻克的问题以及尚未解决的挑战

在 Web3 数据领域，尽管已经取得了一些重要的进展，但仍然面临一些挑战。

相对成熟的应用：

使用 LLM 进行信息处理：LLM 等 AI 技术已成功用于生成文本摘要、总结、解释等工作，帮助用户从长篇文章、专业报告中提取关键信息，提高了数据的可读性和可理解性。
使用 AI 解决开发问题：LLM 已经应用于解决开发过程中的问题，例如替代StackOverflow 或搜索引擎，为开发者提供问题解答和编程支持。

有待解决与正在探索的问题：

利用 LLM 生成代码：行业正在努力将 LLM 技术应用于自然语言到 SQL 查询语言的转换，以提高数据库查询的自动化和可理解性。然而，过程中会有很多困难，比如在某些情境下，生成的代码要求极高的准确性，语法必须百分之百正确，以确保程序能够无 bug 运行，并获得正确的结果。难点还包括确保问题回答的成功率、正确率，以及对业务的深刻理解。
数据标注问题：数据标注对于机器学习和深度学习模型的训练至关重要，但在 Web3 数据领域，特别是处理匿名的区块链数据时，标注数据的复杂性较高。
准确性和幻觉（Hallucination）问题：AI 模型中幻觉的出现可能受多因素影响，包括有偏见或不足的训练数据、过度拟合、有限的上下文理解、缺乏领域知识、对抗性攻击和模型架构。研究人员和开发者需要不断改进模型的训练和校准方法，以提高生成文本的可信度和准确性。
利用数据进行业务分析和文章输出：将数据用于业务分析和生成文章仍然是一个具有挑战性的问题。问题的复杂性、需要精心设计的提示（prompt）、以及高质量的数据、数据量、减少幻觉问题的方法都是待解决的问题。
根据业务领域自动索引智能合同数据以进行数据抽象：自动为不同业务领域的智能合同数据建立索引以进行数据抽象仍然是一个未解决的问题。这需要综合考虑不同业务领域的特点，以及数据的多样性和复杂性。
处理时序数据，表格文档数据等更复杂的模态：DALL·E 2 等多模态模型非常擅长在文字生成图像、语音等常见模态。而在区块链以及金融领域需要特别地对待一些时序数据，而非简单地把文本向量化就能解决。联和时序数据与文本，跨模态联合训练等，是实现数据智能分析以及应用的重要研究方向。

3.6.2 为何只靠 LLM 不能完美解决区块链数据行业的问题

作为语言模型，LLM 更适用于处理对流畅度要求较高的场景，而在追求准确性方面，可能需要对模型进行更进一步的调整。在将 LLM 应用于区块链数据行业时，以下框架可提供一些参考。

图 13：区块链数据行业下 LLM 输出的流畅性、准确性和用例风险

在评估 LLM 在不同应用中的适用性时，关注流畅度和准确性是至关重要的。流畅度指的是模型的输出是否自然、通顺，准确性则表示模型的答案是否准确。这两个维度在不同应用场景中有不同的要求。

对于流畅度要求较高的任务，如自然语言生成、创意写作等，LLM 通常能够胜任，因为其在自然语言处理方面的强大性能使其能够生成流畅的文本。

区块链数据面临着数据解析、数据处理、数据应用等多方面的问题。LLM 拥有卓越的语言理解和推理能力，使其成为与区块链数据互动、整理和概括的理想工具。然而，LLM 并不能解决所有区块链数据领域的问题。

在数据处理方面，LLM 更适合快速迭代和探索性处理链上数据，不断尝试新的处理方法。然而，LLM 在生产环境中的详细核对等任务方面仍存在一些限制。典型的问题是 token 长度不够，无法应对长上下文的内容。耗时的 prompt，回答不稳定影响下游任务进而导致成功率不稳定的问题，以及执行大批量任务的效率不高。

其次，LLM 处理内容的过程中很可能出现幻觉问题。据估计，ChatGPT 的幻觉概率约为 15% 至 20%，而由于其处理过程的不透明性，很多错误难以察觉。因此，框架的建立和专家知识的结合变得至关重要。此外，LLM 结合链上数据还是有很多挑战：

链上数据实体类型多、数量庞大，以何种形式投喂给 LLM，有效地运用在具体的商业化场景，类似其他垂直行业，需要更多研究和探索。
链上数据包括结构化和非结构化数据，目前行业大多数数据解决方案，都是基于对业务数据的理解。解析链上数据的过程中，用 ETL 去过滤，清洗，补充和复原业务逻辑，进一步把非结构化数据整理为结构化数据，可以为后期多种业务场景提供更高效的分析。比如，结构化的 DEX trades，NFT marketplace transactions，wallet address portfolio 等，就具有前面提到的高质量，高价值，准确和真实等特点，可以给通用 LLM 提供高效的补充。

被误解的 LLM

LLM 可以直接处理非结构化数据，因此结构化数据将不再被需要？

LLM 通常基于海量文本数据预训练而来，天然适合处理各类非结构化的文本数据。然而，各个行业已经拥有大量结构化数据，尤其 Web3 领域中解析后的数据。如何有效的利用这些数据，增强 LLM，是一个行业的热门研究课题。

对于 LLM，结构化数据仍然具有以下的优势：

海量：大量的数据储存在各种应用背后的数据库和其他标准格式里面，特别是私有数据。每个公司和行业都还有大量 LLM 没有用于预训练的墙内数据。
已有：这些数据不需要重新生产，投入成本极低，唯一的问题是怎么用起来。
高质量和高价值：领域内长期积累的，蕴含专家的专业知识，通常都沉淀到了结构化数据里面，用于产学研。结构化数据的质量是数据可用性的关键，其中包括数据的完整性、一致性、准确性、唯一性和事实性。
高效率：结构化数据以表格、数据库或其他规范格式存储，模式是预先定义的，并且在整个数据集中保持一致。这意味着数据的格式、类型和关系都是可预测和可控的，使得数据的分析和查询更加简单和可靠。而且，行业已经有成熟的 ETL 及各种数据处理和管理工具，使用起来也更加高效和便捷。LLM 可以通过 API，把这些数据使用起来。
准确性和事实性：LLM 的文本数据，基于 token 概率，目前还不能稳定的输出确切的答案，产生的幻觉问题一直是 LLM 要解决的核心根本问题。对于很多行业和场景，会形成安全和可靠性问题，比如，医疗，金融等。结构化数据，正是可以辅助和矫正LLM 这些问题的一个方向。
体现关系图谱，和特定业务逻辑：不同类型的结构化数据，可以以特定的组织形式（关系型数据库，图数据库等），输入到 LLM，解决不同类型的领域问题。结构化数据使用标准化的查询语言（如 SQL），使得对数据进行复杂的查询和分析变得更加高效和准确。知识图谱 (Knowledge Graph) 可以更好地表达实体之间的关系，也更容易进行关联查询。
使用成本低：不用 LLM 每次重新从底层重新训练整个底座模型，可以结合 Agents 和LLM API 等 LLM 赋能方式，更快更低成本的接入 LLM。

目前市场上还有一些脑洞大开的观点，认为 LLM 在处理文本信息和非结构化信息方面的能力极强，只需将原始数据，包括非结构化数据，简单导入到 LLM，就能达到目的。这个想法类似于要求通用 LLM 解数学题，在没有专门构建数学能力模型的情况下，大多数 LLM 可能会在处理简单的小学加减题时出错。反而，建立类似数学能力模型，和图像生成模型的 Crypto LLM 垂直模型，才是解决 LLM 在 Crypto 领域更落地的实践。

4.2 LLM 可以从新闻、推特等文字信息推测内容，人们不再需要链上数据分析来得出结论？

LLM 虽然可以从新闻、社交媒体等文本中获得信息，但直接从链上数据中获得的洞察仍然是不可或缺的，主要原因有:

链上数据是原始的第一手资讯，而新闻和社交媒体中的信息可能存在片面性或误导性。直接分析链上数据可以减少信息偏差。尽管利用 LLM 进行文本分析存在理解偏差的风险，但直接分析链上数据可以减少误读。
链上数据包含全面的历史交互和交易记录，分析可以发现长期趋势和模式。链上数据还可以展现整个生态系统的全貌，如资金流向、各方关系等。这些宏观的洞察有助于更深入地理解状况。而新闻和社交媒体信息通常更零散且短期。
链上数据是开放的。任何人都可以验证分析结果，避免信息的不对称。而新闻和社交媒体未必都如实披露。文本信息和链上数据可以相互验证。综合两者可以形成更立体和准确的判断。

链上数据分析仍是不可或缺的。LLM 从文本中获取信息具有辅助作用，但不能取代直接分析链上数据。充分利用两者优势才能取得最佳效果。

4.3 利用 LangChain、LlamaIndex 或其他 AI 工具，在 LLM 的基础上构建区块链数据解决方案非常容易？

LangChain 和 LlamaIndex 等工具为构建自定义的简单 LLM 应用提供了便利，使快速搭建成为可能。然而，将这些工具成功应用于实际生产环境中涉及到更多的挑战。构建一个高效运行、保持高质量的 LLM 应用是一项复杂的任务，需要深入理解区块链技术和 AI 工具的工作原理，并有效地将它们整合在一起。这对于区块链数据行业来说，是一项重要但具有挑战性的工作。

在这个过程中，必须认识到区块链数据的特性，它要求极高的精准性和可重复校验性。一旦数据通过 LLM 进行处理和分析，用户对其准确性和可信度有很高的期望。这与 LLM 的模糊容错性之间存在着潜在的矛盾。因此，在构建区块链数据解决方案时，必须仔细权衡这两方面的需求，以满足用户的期望。

当前市场上，虽然已经有了一些基础工具，但这个领域仍在快速演进和不断迭代。类比于 Web2 世界的发展历程，从最初的 PHP 编程语言到更成熟、可扩展的方案如 Java、Ruby、Python，以及 JavaScript 和 Node.js 等，再到 Go 和 Rust 等新兴技术，都经历了不断的演变。AI 工具也在不断变化，新兴的 GPT 框架如 AutoGPT，Microsft AutoGen，及最近OpenAI 自己推出的 ChatGPT 4.0 Turbo 的 GPTs 和 Agents 等只是展示了未来可能性的一部分。这表明，区块链数据行业和 AI 技术都还有许多发展空间，需要不断努力和创新。

当前在应用 LLM 时，有两个陷阱需要特别注意：

期望值过高：很多人认为 LLM 可以解决一切问题，但实际上 LLM 有明显的局限性。它需要大量的计算资源，训练成本高昂，而且训练过程可能不稳定。对 LLM 的能力要有现实的期望，明白它在某些场景下表现出色，如自然语言处理和文本生成，但在其他领域可能无法胜任。
忽视业务需求：另一个陷阱是强行应用 LLM 技术，而不充分考虑业务需求。在应用 LLM 之前，务必明确具体的业务需求。需要评估 LLM 是否是最佳技术选择，并做好风险评估和控制。强调 LLM 的有效应用需要根据实际情况慎重考虑，避免误用。

尽管 LLM 在许多领域都具备巨大潜力，但开发者和研究者在应用 LLM 时需要保持谨慎，采取开放的探索态度，以找到更适合的应用场景并最大程度地发挥其优势。

关于Footprint Analytics

Footprint Analytics是一家区块链数据解决方案提供商。借助尖端的人工智能技术，我们提供 Crypto 领域首家支持无代码数据分析平台以及统一的数据 API，让用户可以快速检索超过 30 条公链生态的 NFT，GameFi 以及 钱包地址资金流追踪数据。

关于Future3 Campus

Future3 Campus是由万向区块链实验室和HashKey Capital共同发起的Web3.0创新孵化平台，重点聚焦Web3.0 Massive Adoption、DePIN、AI三大赛道，以上海、粤港澳大湾区、新加坡为主要孵化基地，辐射全球Web3.0生态。同时，Future3 Campus将推出首期5000万美金的种子基金用于Web3.0项目孵化，真正服务于Web3.0领域的创新创业。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
区块链
AI
大语言模型
Web3

--

Written by Future3 Campus
13 Followers

Empowering the Web3.0 Innovation. Incubation platform powered by Wanxiang Blockchain Labs and HashKey Capital

Follow

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:48.489 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.341 | Max budget: $10.000 | Current cost: $0.012, prompt_tokens: 3408, completion_tokens: 555
2024-03-04 22:03:48.499 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "使用大型语言模型进行数值计算的挑战".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

draftai

·

Follow

42 min read
·
Aug 2, 2023

大语言模型部署应用与基础设施成本优化

1. 引言

ChatGPT、LLaMa、Bard 等大语言模型(LLMs)取得了非常巨大突破，迅速在公众领域流行起来。LLMs所展现的强大文本生产能力让用户惊叹不已，属于划时代的产品。这些模型拥有数十亿甚至数千亿个参数，因而这些模型通常的部署和维护成本都惊人的高昂。这类大模型的的训练和推理都需要大量的计算资源和内存资源，企业需要投入海量的基础设施成本（不管是云服务还是自建机房都非常贵)，来保证大模型能够稳定提供服务。

那么有没有办法花小钱办大事呢？ 当然有。

本文旨在提供一些策略、提示和技巧，您可以在部署基础架构时应用这些策略、提示和技巧来优化基础架构。我们将重点探讨这些内容：

大模型部署与应用时将会面临的基础架构挑战
如何降低大模型部署与应用的成本

2. 大模型部署与应用的挑战

LLMs遵循规模效应，也就是说参数越大，效果越好。因此它们一般需要海量GPU计算资源才能获得最佳性能。通常会面临以下的挑战：

2.1 高计算量

部署 LLM 是一个充满挑战的任务，因为它们需要大量计算资源来执行推理，尤其是模型用于实时应用程序（例如聊天机器人或虚拟助手）为甚。 以 ChatGPT 为例，大多数情况下它能够在几秒钟内处理和响应用户查询。尤其是繁忙时段瞬间涌入海量用户会使得推理时间会变长。还有其他因素可能会延迟推理，例如问题的复杂性、生成响应所需的信息量等等。总而言之，大模型要提供实时服务，它必须能够实现高吞吐量和低延迟。

2.2 大存储量

由于模型参数规模从数百万到数千亿，LLM 的存储也是一个充满挑战的问题。由于大模型规模太大，所以无法直接将整个模型存储在单个存储设备。 例如，OpenAI 的 GPT-3 模型有 1750亿 个参数，仅其权重参数存储就需要超过 300GB 的存储空间。 此外，它还需要至少具有 16GB 显存的 GPU 才能高效运行（意味着起码是T4级别以上的N卡)。 因此，在单个设备上存储和运行如此大的模型对于许多用户场景来说是不切实际的。整体来说， LLM 的存储容量存在三个主要问题：

内存限制 : LLMs需要大量内存，因为它们要处理大量信息。部署此类模型的一种方法是使用分布式系统，模型分布在多个服务器节点上。这种系统允许将推理任务切分分配到多台服务器上，实现负载均衡和推理加速。这类系统通常架构都比较复杂，需要大量的专业知识来设置和维护这些分布式机器。模型越大，需要的服务器就越多，这也增加了部署成本。还有一种复杂的场景就是，如何将大模型部署在手机等内存较小的设备上。
模型规模 : 如果输入查询又长又复杂，即便运行在大内存显卡上的模型推理过程中也很容易耗尽内存。即使对于 LLM 的基本推理，也需要多个加速器或多节点计算集群（例如多个 Kubernetes Pod）。
可扩展性 : 大模型通常使用模型并行化（MP）进行扩展，这涉及将模型分成更小的部分并将其分布在多台机器上。每台机器处理模型的不同部分，并将结果组合起来产生最终输出。该技术有助于大模型训练，但也需要仔细考虑机器之间的通信开销。
2.3 网络带宽

如上所述，LLM 必须使用 MP 进行扩展。但我们发现的问题是，模型并行化 在单节点集群中是有较好效果，但在多节点集群中，由于网络通讯开销，导致推理效率不高。

2.4 成本与能耗

如上文所述，部署和使用 LLM 的成本可能很高，包括硬件和基础设施的成本，尤其是在推理过程中使用 GPU 或 TPU 等资源来实现低延迟和高吞吐量时。对小公司和个人来说，这是一个非常大的挑战。

LLMs的费用估算以及碳足迹｜ 来源[1]

根据 NVIDIA[2]的说法，80–90% 的机器学习工作负载是推理带来的。同样，根据 AWS[3] 的数据，推理占云中机器学习需求的 90%。

在22年12月份，chatGPT 的运行成本约为每天 100,000 美元或每月 300 万美元。随着ChatGPT的大获成功，GPT-4的推出等，估计现在(23年7月)估计要比当时(22年12月)高出一个数量级了

关于ChatGPT成本的推文 | 来源[4]

3. 优化大模型基础设施成本的策略

在本节中，我们将探讨并讨论前一节中讨论的挑战的可能解决方案和技术。

首先以AWS作为云供应商，来实现大模型推理的工作流作为例子：

AWS上的大模型推理的工作流 | 来源[5]

您可以按照以下的步骤尽可能高效地部署大模型。

3.1 云计算预算评估与规划

使用云计算服务可以提供动态、按需使用包括CPU,GPU,TPU在内的各种强大的计算资源。云计算服务灵活且可扩展性强，但是在使用云服务的时候，首先你需要为自己的项目制定一个项目预算，这样能够让你的基础设施投入更加合理可控。 云服务提供商如AWS、Azure和google cloud提供了一系列部署LLM的产品，包括虚拟机、容器和无服务器计算。但是尽管如此，建议还是需要根据自己业务情况进行研究和计算，选择更加合理的云服务解决方案。例如，你必须核实以下三个方面信息：

模型尺寸
关于要使用的硬件的详情
合理的推理产品方案 根据上述三个方面的信息，可以计算出你需要多少加速计算能力，从而规划并执行适合你自身业务的大模型部署。

大模型的MLOps工具[6]

3.1.1 计算模型大小

您可以根据以下表格，折算自己模型大概需要多少多少FLOPs算力，从而确定要在云平台上找到相相应的GPU。

预估计算FLOPs[7]
另外这个工具[8]也可以帮你计算模型在训练和推理过程中所需的FLOPs。

一个用于计算训练和推理所需的FLOPs的工具[9]

3.1.2 选择合适的硬件

当你计算出所需的FLOPs，就可以继续选择GPU。确保你了解GPU所提供的功能。例如，查看下面的图片以了解情况。可以参考以下A100的GPU规格，选择符合预算的显卡。最新的H100芯片可以访问这个链接[10]

NVIDIA提供的GPU规格清单[11]

3.1.3 选择正确的推理产品

Amazon SageMake[12]r是一个机器学习云服务产品，提供多种推理选项，以适应不同的工作负载。例如，如果您需要：

实时推理, 适用于低延迟或高吞吐量的在线推理，支持最大6 MB的负载大小和60秒的处理时间。
无服务器推理,适用于间歇性或不可预测的流量模式，并支持高达4 MB的负载大小和60秒的处理时间。在无服务器推理中，模型根据流量弹性伸缩，自动扩容或者缩容。
批量处理 ，适用于大型数据集的离线处理，适合以GB为单位的负载大小和以天为单位的处理时间的场景。
异步推理 ，适用于排队具有大负载和长处理时间的请求，支持最大1 GB的负载和最长一小时的处理时间. 。同样支持弹性伸缩。

为了更好地理解并满足您的要求，请查看下方的图片。

选择模型部署类型[13]

当满足以上所有要点时，您可以将模型部署在任何云服务上。

3.1.4 小结：
1 设定预算
2 计算模型的大小
3 计算模型所需的FLOPs
4 找到合适的GPU
5 选择适当的推理类型
6 研究各个云计算平台提供的定价
7 找到适合您需求和预算的服务
8 部署
3.2 优化模型以提供服务

在上一节中，我们讨论了不同规模的LLM的规模如何部署。如果当我们的模型过大时，可以采用模型编译、模型压缩和模型分片等策略。这些技术可以在保持准确性的同时减小模型的大小，部署起来更容易，与之同时会显著降低相关费用。

优化LLMs以进行部署的不同技术或策略[14]

3.2.1 模型压缩

模型压缩的目标是通过利用硬件特定优化，如减少内存占用、改善计算并行性和减少延迟，来提高LLM推理的性能和效率。模型压缩能够帮助你尝试不同的技术组合，为各种任务设定性能基准，并找到适合预算的方案。模型压缩一般涉及几个步骤：

计算图优化(Graph optimization): 使用剪枝和量化等优化技术对高级LLM图进行转换和优化，以降低模型的计算复杂度和内存占用。这样，模型变得更小，同时保持其准确性。
硬件感知优化(Hardware-specific optimization): 在优化过的LLM计算图基础上进一步实现硬件优化。Amazon Sagemaker为各种流行的ML框架提供了基于硬件优化的模型服务容器以及SDK，包括XGBoost，scikit-learn，PyTorch，TensorFlow和Apache MXNet。

AWS Sagemaker Neo的工作原理[15]

以下是一些必须了解的模型压缩技术。

3.2.1.1 模型量化

模型量化（MQ）是一种减少机器学习模型大小和计算复杂性的技术。在模型量化中，我们将模型的权重和激活函数从浮点数（例如32位）转换为更小的数据类型（例如8位整数）。这样做的原因是，更小的数据类型需要更少的存储空间和计算资源。

这个过程可以类比为我们在生活中的经验。比如，你有一张非常详细的地图，这张地图上的每一条街道、每一棵树都画得非常清楚。但是，这张地图非常大，你无法把它放进口袋里。于是，你决定制作一张简化版的地图，只标注主要的街道和地标。这样，你的地图就变小了，可以放进口袋里，但是它仍然包含了你需要的主要信息。

在模型量化中，我们也是这样做的。我们将模型的权重和激活函数简化，使其变小，但仍然尽可能地保留了原始模型的信息。

然而，这种简化过程确实可能会导致一些信息的丢失，这就是所谓的量化误差。这种误差可能会对模型的精度产生影响。但是，通过一些技术，如重新校准（re-calibration）和量化感知训练（quantization-aware training），我们可以在一定程度上减小这种影响。这些技术可以帮助模型在量化过程中适应信息的丢失，从而在减小模型大小的同时，尽可能地保持模型的精度。 PyTorch 提供了模型量化的能力。PyTorch 提供了一套完整的量化工具，包括动态量化（Dynamic Quantization）、静态量化（Static Quantization）以及量化感知训练（Quantization Aware Training）。

动态量化：这种方法只量化模型的权重，而不量化激活。这种方法的优点是实现简单，不需要对模型进行任何修改，但可能不如其他方法减少模型大小和提高性能。
静态量化：也称为（Post-training quantization)。这种方法在训练后进行，它包括权重和激活的量化，以及模型的重校准。这种方法可以进一步减小模型大小和提高性能，但需要更多的步骤来实现。
量化感知训练：也称为(Hybrid quantization). 这种方法在训练过程中引入量化，使模型能够适应量化带来的误差。这种方法可以在减小模型大小和提高性能的同时，保持或提高模型的精度。

PyTorch 提供了一系列的 API 和教程来帮助开发者实现模型量化。这些工具可以帮助你将模型量化，使其更适合在资源有限的设备上运行。

虽然模型量化有很多优点，如减小模型大小、减少计算需求、提高推理速度等，但是它也有一些潜在的缺点：

精度下降：量化过程可能会导致一些信息的丢失，这可能会对模型的精度产生影响。虽然有一些技术可以减小这种影响，但在某些情况下，精度的下降可能是无法避免的。
实现复杂：实现模型量化可能需要对模型进行一些修改，这可能会增加实现的复杂性。例如，你可能需要进行量化感知训练，或者对模型进行重校准。
硬件兼容性：虽然模型量化可以帮助模型在资源有限的设备上运行，但并非所有的硬件都支持量化模型。在某些硬件上，运行量化模型可能不会带来预期的性能提升。
模型兼容性：并非所有的模型都适合量化。某些模型可能在量化后的性能下降较大，或者无法进行有效的量化。

因此，虽然模型量化是一种强大的工具，但在使用它时，你需要考虑到这些潜在的问题，并根据你的具体需求和条件来决定是否使用模型量化。

3.2.1.2 模型剪枝

模型剪枝（Model Pruning）是一种优化技术，它的目标是通过移除模型中的一部分参数（例如神经网络中的神经元或连接）来减小模型的大小和计算需求，同时尽可能地保持模型的性能。

模型剪枝的基本思想是，模型中的一些参数对模型的性能贡献很小，因此可以安全地移除它们。例如，在神经网络中，我们可以移除那些权重很小的连接，因为它们对模型的输出影响很小。

模型剪枝有很多种方法，包括：

权重剪枝：这种方法移除那些权重值小于某个阈值的连接。这种方法的优点是实现简单，但可能会导致模型的结构变得不规则，从而影响硬件的优化。
单位剪枝：这种方法移除整个神经元或者卷积核。这种方法可以保持模型的结构规则，从而更适合硬件的优化，但可能会对模型的性能产生更大的影响。
结构剪枝：这种方法移除模型中的一部分结构，例如卷积层或者全连接层。这种方法可以大大减小模型的大小，但需要更复杂的算法来确定应该移除哪些结构。
稀疏剪枝：这种方法试图在保持模型性能的同时，最大化模型的稀疏性。这通常通过一些优化算法来实现，例如L1正则化。
动态剪枝：这种方法在模型的训练过程中动态地进行剪枝。这种方法的优点是可以根据模型的训练情况来调整剪枝的策略，但实现起来可能比较复杂。

下面是一个使用 PyTorch 进行权重剪枝的简单例子：

import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
# 创建一个简单的线性模型
model = nn.Linear(10, 10)
# 打印模型的权重
print('原始权重:')
print(model.weight)
# 使用 L1Norm 方法进行剪枝，剪掉 30% 的权重
prune.l1_unstructured(model, name="weight", amount=0.3)
# 打印剪枝后的权重
print('剪枝后的权重:')
print(model.weight)

在这个例子中，首先创建了一个简单的线性模型。然后，使用 prune.l1_unstructured 方法进行剪枝，剪掉了 30% 的权重。最后，打印出了剪枝后的权重。

这只是一个非常简单的例子，实际的剪枝过程可能会更复杂。例如，可能需要在剪枝后重新训练模型，以恢复模型的性能，也可能需要使用更复杂的剪枝方法，例如单位剪枝或结构剪枝。

你可以通过PyTorch的这个Colab[16]笔记本来更好地了解MP。

3.2.1.3 模型蒸馏

模型蒸馏是一种模型压缩技术，它的主要步骤如下：

训练教师模型：首先，需要训练一个大的模型，这个模型通常被称为教师模型。教师模型通常是一个深度的、复杂的模型，它可以在训练数据上达到很高的性能。
获取教师模型的输出：然后，使用教师模型对训练数据进行预测，获取教师模型的输出。这些输出通常包括类别的预测，以及预测的概率或者置信度。
训练学生模型：接着，训练一个小的模型，这个模型通常被称为学生模型。学生模型通常是一个浅度的、简单的模型，它的目标是学习教师模型的输出。在训练过程中，不仅要最小化学生模型的输出和数据的标签之间的差异，还要最小化学生模型的输出和教师模型的输出之间的差异。
评估学生模型：最后，评估学生模型的性能。如果学生模型的性能达到了我们的要求，那么就可以使用学生模型来替代教师模型了。

以BERT为例，模型蒸馏工作流程请参见下方的图片。

DistilBERT的蒸馏过程[17]

模型蒸馏的具体方法有很多种，以下是一些常见的方法：

软标签蒸馏：这是最常见的模型蒸馏方法，也是模型蒸馏的基础。在这种方法中，教师模型的输出（通常是概率分布）被用作学生模型的目标。这种方法可以帮助学生模型学习到教师模型的知识，包括类别之间的关系和对于某些难以分类的样本的不确定性。
特征蒸馏：在这种方法中，我们不仅要让学生模型学习到教师模型的输出，还要让学生模型学习到教师模型的中间特征。这种方法可以帮助学生模型学习到更深层次的知识，从而提高模型的性能。
关系蒸馏：在这种方法中，我们让学生模型学习到教师模型的输出之间的关系。例如，我们可以让学生模型学习到教师模型对于一对样本的相对预测。这种方法可以帮助学生模型学习到更复杂的知识，从而提高模型的性能。
注意力蒸馏：在这种方法中，我们让学生模型学习到教师模型的注意力分布。这种方法可以帮助学生模型学习到教师模型的注意力机制，从而提高模型的性能。

我们用一个使用 PyTorch 实现模型蒸馏的代码示例来加深理解。 在这个例子中，我们首先创建了一个教师模型和一个学生模型，然后使用自定义的损失函数进行模型蒸馏。

import torch
import torch.nn as nn
import torch.optim as optim
# 创建教师模型和学生模型
teacher = nn.Sequential(nn.Linear(784, 1200), nn.ReLU(), nn.Linear(1200, 10))
student = nn.Sequential(nn.Linear(784, 800), nn.ReLU(), nn.Linear(800, 10))
# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)
# 定义蒸馏的温度和权重
temperature = 2.0
alpha = 0.5
for epoch in range(100):  # 进行 100 个训练周期
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        # 计算教师模型的输出
        teacher_outputs = teacher(inputs)
        teacher_probs = torch.nn.functional.softmax(teacher_outputs / temperature, dim=1)
        # 计算学生模型的输出
        student_outputs = student(inputs)
        student_probs = torch.nn.functional.softmax(student_outputs / temperature, dim=1)
        # 计算损失
        loss1 = criterion(student_outputs, labels)
        loss2 = criterion(student_probs.log(), teacher_probs)
        loss = alpha * loss1 + (1 - alpha) * loss2
        # 反向传播和优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

在这个例子中，首先创建了一个教师模型和一个学生模型。然后，定义了损失函数和优化器。还定义了蒸馏的温度和权重，这两个参数用于控制蒸馏的强度。

在训练过程中，首先计算教师模型的输出，然后将这些输出转换为概率分布。接着，我们计算学生模型的输出，然后将这些输出转换为概率分布。然后，计算两种损失：一种是学生模型的输出和数据标签之间的损失，另一种是学生模型的输出和教师模型的输出之间的损失。这两种损失的权重由 alpha 参数来控制。最后，进行反向传播和优化。

可以在这个链接中找到完整的代码和更详细的解释：Towards Data Science: Introduction to PyTorch Model Compression Through Teacher-Student Knowledge Distillation[18]。

3.2.2 LLM的硬件优化
选择适合LLM需求的硬件：大型语言模型（LLMs）通常需要大量的计算资源和存储空间。例如，如果我们模型是一个大型的Transformer模型，需要具有大量RAM和多个GPU的高性能服务器。另一方面，如果我们模型是一个小型的RNN模型，可能只需要一个具有适量RAM和一个GPU的普通服务器。选择合适的硬件可以确保我们模型能够有效地运行，同时避免浪费资源。
利用专用硬件：专用硬件，如TPU（张量处理单元），是专门为深度学习任务设计的硬件加速器。TPU在处理张量运算（这是深度学习模型的基础）方面非常高效。例如，Google的BERT模型就是在TPU上训练的。此外，推理时可以考虑使用加速线性代数（XLA）。XLA是一种优化编译器，可以将TensorFlow的计算图优化为高效的机器代码，从而提高性能。
使用优化的库：优化的库，如TensorFlow、PyTorch或JAX，可以利用硬件特性来加速计算。例如，TensorFlow可以自动地将计算任务分配到多个GPU上，从而提高性能。PyTorch则提供了一种动态计算图的特性，可以更灵活地构建和修改模型。JAX则提供了一种函数转换的特性，可以更容易地实现复杂的优化算法。
调整批次大小：在推理过程中，适当调整批次大小可以最大化硬件利用率并提高推理速度。例如，如果GPU有足够的内存，可以增大批次大小，这样可以让GPU同时处理更多的数据，从而提高性能。但是，如果批次大小太大，可能会导致内存溢出。因此，我们需要根据硬件条件和模型需求来调整批次大小。
持续监控和优化：在部署过程中，需要持续监控模型的性能，包括推理速度、内存使用情况、GPU利用率等。如果发现性能有问题，可能需要调整硬件配置，例如增加RAM、增加GPU、升级存储设备等。也可能需要优化模型或代码，例如减小模型大小、优化计算图、减少数据传输等。
3.3 成本效益(Cost Efficient,CE) 的可扩展性

以下是我们可以在控制成本的同时扩展大型自然语言处理模型的方法：

选择合适的推理选项：例如，我们可以选择使用AWS SageMaker或Google Cloud AI Platform，这些服务可以根据需求动态分配资源，从而在需求较少时降低部署成本。
优化推理性能：我们可以通过使用硬件加速，如GPU或TPU，以及优化推理代码来提高推理性能。例如，我们可以使用TensorRT或OpenVINO这样的库来优化我们的模型，使其能够更有效地在GPU或TPU上运行。
使用缓存：如果我们的模型需要处理大量的重复请求，我们可以使用缓存来提高性能和降低成本。例如，我们可以使用Redis或Memcached这样的缓存服务来存储我们的模型的推理结果。当我们收到一个相同的请求时，我们可以直接从缓存中获取结果，而不需要再次运行模型。这样可以显著减少我们的计算需求，从而降低成本。
4. 结论

我们总结一下全文的流程

设定预算：明确我们的财务预算，以便在部署大型语言模型时做出明智的决策。
计算模型大小：理解我们的模型的规模，以便选择合适的硬件和服务。
使用模型压缩技术：通过修剪、量化和蒸馏等技术，可以减少部署所需的内存和计算资源。
利用云计算服务：AWS、Google Cloud和Microsoft Azure等云服务提供了经济高效且可扩展的解决方案。
采用无服务器计算：无服务器计算提供了按使用付费的模式，可以降低运营成本并实现自动扩展。
优化硬件加速：例如，我们可以使用GPU来加速模型的训练和推理，从而提高效率。
定期监控资源使用：通过监控，我们可以识别哪些资源被低效使用，或者哪些实例被过度配置，从而找到降低成本的机会。
持续优化模型和硬件：我们需要不断地优化我们的模型和硬件配置，以实现高效的推理。
更新软件和安全补丁：保持软件和安全补丁的最新状态，以确保我们的系统的安全。

在本文中，我们探讨了部署大型语言模型时面临的挑战，以及与之相关的基础设施成本。同时，我们也提出了解决这些问题的技术和策略。

在我们讨论的所有解决方案中，风爷最推荐的是弹性和无服务器推理。虽然模型压缩是一种有效的方法，但是当需求很高时，即使是较小的模型也可能需要大量的资源。因此，需要一个可以根据需求动态调整资源的解决方案，这就是弹性和无服务器推理的优势。

当然，这些推荐可能并不适合所有的情况，你需要根据你自己的需求和问题来选择最合适的方法。风爷希望这些讨论可以帮助你在部署大型语言模型时降低基础设施成本。

#AIGC #LLMs #Infra #AWS #大模型

智写AI

智写AI是免费万能的ai写作聊天机器人。ai免费帮你写作文、写论文、写材料、写文案、周报月报、公务员材料、行政报告、写英语作文、写小说剧本、写短视频脚本、写营销文案等等，还能写代码。它能教你python、java、C#、C、javscript、Golang编程、系统架构设计、系统开发。它还能教你简历制作、简历模版，给你做心理咨询、给你讲故事、陪你玩文字游戏等。

References 参考文献
Large Language Model Training in 2023[19]
https://d1.awsstatic.com/events/Summits/reinvent2022/AIM405_Train-and-deploy-large-language-models-on-Amazon-SageMaker.pdf[20]
Top 10 AI Chip Makers of 2023: In-depth Guide[21]
https://www.nvidia.com/en-us/data-center/dgx-a100/[22]
LLaMA: A foundational, 65-billion-parameter large language model[23]
https://arxiv.org/pdf/2203.15556.pdf[24]
https://huggingface.co/docs/transformers/model_doc[25]
https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2TokenizerFast[26]
https://sunniesuhyoung.github.io/files/LLM.pdf[27]
https://twitter.com/tomgoldsteincs/status/1600196995389366274?lang=en[28]
https://arxiv.org/pdf/1910.02054.pdf[29]
https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html[30]
Jaime Sevilla et al. (2022), “Estimating Training Compute of Deep Learning Models”. Published online at epochai.org[31]. Retrieved from: ‘https://epochai.org/blog/estimating-training-compute[32]‘ [online resource]
https://arxiv.org/abs/2001.08361[33]
https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf[34]
https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html[35]
https://aws.amazon.com/sagemaker/neo/[36]
https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/7126bf7beed4c4c3a05bcc2dac8baa3c/pruning_tutorial.ipynb[37]
https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a[38]
https://aws.amazon.com/blogs/machine-learning/train-175-billion-parameter-nlp-models-with-model-parallel-additions-and-hugging-face-on-amazon-sagemaker/[39]
Improving Language Model Behavior by Training on a Curated Dataset[40]
https://towardsdatascience.com/how-to-deploy-large-size-deep-learning-models-into-production-66b851d17f33[41]
https://huggingface.co/blog/large-language-models[42]
https://aws.amazon.com/blogs/machine-learning/deploy-large-models-on-amazon-sagemaker-using-djlserving-and-deepspeed-model-parallel-inference/[43]
Large Language Models Can Self-Improve[44]
https://spot.io/resources/cloud-cost/cloud-cost-optimization-15-ways-to-optimize-your-cloud/[45]
https://dataintegration.info/choose-the-best-ai-accelerator-and-model-compilation-for-computer-vision-inference-with-amazon-sagemaker[46]
https://medium.com/data-science-at-microsoft/model-compression-and-optimization-why-think-bigger-when-you-can-think-smaller-216ec096f68b[47]
https://medium.com/picsellia/how-to-optimize-computer-vision-models-for-edge-devices-851b20f7cf03[48]
https://huggingface.co/docs/transformers/v4.17.0/en/parallelism#which-strategy-to-use-when[49]
https://medium.com/@mlblogging.k/9-libraries-for-parallel-distributed-training-inference-of-deep-learning-models-5faa86199c1f[50]
https://towardsdatascience.com/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880[51]
参考资料

[1]

来源: https://sunniesuhyoung.github.io/files/LLM.pdf

[2]

NVIDIA: https://www.hpcwire.com/2019/03/19/aws-upgrades-its-gpu-backed-ai-inference-platform/

[3]

AWS: https://aws.amazon.com/blogs/aws/amazon-ec2-update-inf1-instances-with-aws-inferentia-chips-for-high-performance-cost-effective-inferencing/

[4]

来源: https://twitter.com/tomgoldsteincs/status/1600196995389366274?lang=en

[5]

来源: https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html

[6]

大模型的MLOps工具: https://neptune.ai/blog/mlops-tools-for-nlp-projects

[7]

预估计算FLOPs: https://arxiv.org/pdf/2203.15556.pdf

[8]

这个工具: https://www.lesswrong.com/posts/HvqQm6o8KnwxbdmhZ/estimating-training-compute-of-deep-learning-models

[9]

一个用于计算训练和推理所需的FLOPs的工具: https://www.lesswrong.com/posts/HvqQm6o8KnwxbdmhZ/estimating-training-compute-of-deep-learning-models

[10]

这个链接: https://www.nvidia.com/en-sg/data-center/h100/

[11]

NVIDIA提供的GPU规格清单: https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf

[12]

Amazon SageMake: https://aws.amazon.com/pm/sagemaker/?trk=b92e5bb5-847d-49ae-bd86-21239cc9ac5e&sc_channel=ps&ef_id=CjwKCAjwzo2mBhAUEiwAf7wjkpU15inCoHRO6RFplymcFt_4vahy0S3NV44y0bZjEymm-0nDJCjK4BoCIPAQAvD_BwE:G:s&s_kwcid=AL!4422!3!532425958059!e!!g!!amazon%20sagemaker!11543056255!112002968389

[13]

选择模型部署类型: https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html

[14]

优化LLMs以进行部署的不同技术或策略: https://d1.awsstatic.com/events/Summits/reinvent2022/AIM405_Train-and-deploy-large-language-models-on-Amazon-SageMaker.pdf

[15]

AWS Sagemaker Neo的工作原理: https://aws.amazon.com/sagemaker/neo/

[16]

Colab: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/7126bf7beed4c4c3a05bcc2dac8baa3c/pruning_tutorial.ipynb

[17]

DistilBERT的蒸馏过程: https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a

[18]

Towards Data Science: Introduction to PyTorch Model Compression Through Teacher-Student Knowledge Distillation: https://towardsdatascience.com/model-distillation-and-compression-for-recommender-systems-in-pytorch-5d81c0f2c0ec

[19]

Large Language Model Training in 2023: https://research.aimultiple.com/large-language-model-training/

[20]

https://d1.awsstatic.com/events/Summits/reinvent2022/AIM405_Train-and-deploy-large-language-models-on-Amazon-SageMaker.pdf: https://d1.awsstatic.com/events/Summits/reinvent2022/AIM405_Train-and-deploy-large-language-models-on-Amazon-SageMaker.pdf

[21]

Top 10 AI Chip Makers of 2023: In-depth Guide: https://research.aimultiple.com/ai-chip-makers/

[22]

https://www.nvidia.com/en-us/data-center/dgx-a100/: https://www.nvidia.com/en-us/data-center/dgx-a100/

[23]

LLaMA: A foundational, 65-billion-parameter large language model: https://arxiv.org/pdf/2302.13971.pdf

[24]

https://arxiv.org/pdf/2203.15556.pdf: https://arxiv.org/pdf/2203.15556.pdf

[25]

https://huggingface.co/docs/transformers/model_doc: https://huggingface.co/docs/transformers/model_doc

[26]

https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2TokenizerFast: https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2TokenizerFast

[27]

https://sunniesuhyoung.github.io/files/LLM.pdf: https://sunniesuhyoung.github.io/files/LLM.pdf

[28]

https://twitter.com/tomgoldsteincs/status/1600196995389366274?lang=en: https://twitter.com/tomgoldsteincs/status/1600196995389366274?lang=en

[29]

https://arxiv.org/pdf/1910.02054.pdf: https://arxiv.org/pdf/1910.02054.pdf

[30]

https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html: https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html

[31]

epochai.org: http://epochai.org/

[32]

https://epochai.org/blog/estimating-training-compute: https://epochai.org/blog/estimating-training-compute

[33]

https://arxiv.org/abs/2001.08361: https://arxiv.org/abs/2001.08361

[34]

https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf: https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf

[35]

https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html: https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html

[36]

https://aws.amazon.com/sagemaker/neo/: https://aws.amazon.com/sagemaker/neo/

[37]

https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/7126bf7beed4c4c3a05bcc2dac8baa3c/pruning_tutorial.ipynb: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/7126bf7beed4c4c3a05bcc2dac8baa3c/pruning_tutorial.ipynb

[38]

https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a: https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a

[39]

https://aws.amazon.com/blogs/machine-learning/train-175-billion-parameter-nlp-models-with-model-parallel-additions-and-hugging-face-on-amazon-sagemaker/: https://aws.amazon.com/blogs/machine-learning/train-175-billion-parameter-nlp-models-with-model-parallel-additions-and-hugging-face-on-amazon-sagemaker/

[40]

Improving Language Model Behavior by Training on a Curated Dataset: https://openai.com/blog/improving-language-model-behavior/

[41]

https://towardsdatascience.com/how-to-deploy-large-size-deep-learning-models-into-production-66b851d17f33: https://towardsdatascience.com/how-to-deploy-large-size-deep-learning-models-into-production-66b851d17f33

[42]

https://huggingface.co/blog/large-language-models: https://huggingface.co/blog/large-language-models

[43]

https://aws.amazon.com/blogs/machine-learning/deploy-large-models-on-amazon-sagemaker-using-djlserving-and-deepspeed-model-parallel-inference/: https://aws.amazon.com/blogs/machine-learning/deploy-large-models-on-amazon-sagemaker-using-djlserving-and-deepspeed-model-parallel-inference/

[44]

Large Language Models Can Self-Improve: https://openreview.net/pdf?id=NiEtU7blzN

[45]

https://spot.io/resources/cloud-cost/cloud-cost-optimization-15-ways-to-optimize-your-cloud/: https://spot.io/resources/cloud-cost/cloud-cost-optimization-15-ways-to-optimize-your-cloud/

[46]

https://dataintegration.info/choose-the-best-ai-accelerator-and-model-compilation-for-computer-vision-inference-with-amazon-sagemaker: https://dataintegration.info/choose-the-best-ai-accelerator-and-model-compilation-for-computer-vision-inference-with-amazon-sagemaker

[47]

https://medium.com/data-science-at-microsoft/model-compression-and-optimization-why-think-bigger-when-you-can-think-smaller-216ec096f68b: https://medium.com/data-science-at-microsoft/model-compression-and-optimization-why-think-bigger-when-you-can-think-smaller-216ec096f68b

[48]

https://medium.com/picsellia/how-to-optimize-computer-vision-models-for-edge-devices-851b20f7cf03: https://medium.com/picsellia/how-to-optimize-computer-vision-models-for-edge-devices-851b20f7cf03

[49]

https://huggingface.co/docs/transformers/v4.17.0/en/parallelism#which-strategy-to-use-when: https://huggingface.co/docs/transformers/v4.17.0/en/parallelism#which-strategy-to-use-when

[50]

https://medium.com/@mlblogging.k/9-libraries-for-parallel-distributed-training-inference-of-deep-learning-models-5faa86199c1f: https://medium.com/@mlblogging.k/9-libraries-for-parallel-distributed-training-inference-of-deep-learning-models-5faa86199c1f

[51]

https://towardsdatascience.com/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880: https://towardsdatascience.com/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Llm
AI
Written by draftai
0 Followers

draftai is a AI based writting brand. Visit chat.draftai.cn learn more.

Follow
Recommended from Medium

Leonie Monigatti

in

Towards Data Science

Intro to DSPy: Goodbye Prompting, Hello Programming!
How the DSPy framework solves the fragility problem in LLM-based applications by replacing prompting with programming and compiling
·
13 min read
·
5 days ago

1.8K

8

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.9K

111

Lists
Generative AI Recommended Reading
52 stories
·
781 saves
What is ChatGPT?
9 stories
·
310 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
322 saves
Natural Language Processing
1253 stories
·
733 saves

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.9K

44

Cobus Greyling

T-RAG = RAG + Fine-Tuning + Entity Detection
The T-RAG approach is premised on combining RAG architecture with an open-source fine-tuned LLM and an entities tree vector database. The…
5 min read
·
Feb 15, 2024

831

8

Andrew Zuo

Gemini 1.5 Pro Is Insane
I recently hooked up Google’s Gemini Pro. And right after I did OpenAI put out this press release:
·
5 min read
·
Feb 24, 2024

855

16

Raja Gupta

Generative AI for Beginners: Part 1 — Introduction to AI
Learn Generative AI by Spending 15 Minutes Daily for 8 Days
13 min read
·
Feb 8, 2024

1.2K

20

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-04 22:03:48.545 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.377 | Max budget: $10.000 | Current cost: $0.036, prompt_tokens: 11973, completion_tokens: 135
2024-03-04 22:03:52.842 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-04 22:03:52.859 | ERROR    | metagpt.utils.common:wrapper:488 - Exception occurs, start to serialize the project, exp:
Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\common.py", line 497, in wrapper
    return await func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\roles\role.py", line 482, in run
    rsp = await self.react()
          ^^^^^^^^^^^^^^^^^^
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-16k in organization org-uNIHl8OdY75ltR3N8pdUe7Hl on tokens per min (TPM): Limit 60000, Used 55198, Requested 9979. Please try again in 5.177s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\common.py", line 483, in wrapper
    result = await func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\team.py", line 133, in run
    await self.env.run()
Exception: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\common.py", line 497, in wrapper
    return await func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\roles\role.py", line 482, in run
    rsp = await self.react()
          ^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\Desktop\MetaGPT\Role\Researcher.py", line 104, in react
    msg = await super().react()
          ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\roles\role.py", line 452, in react
    rsp = await self._act_by_order()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\roles\role.py", line 439, in _act_by_order
    rsp = await self._act()
          ^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\Desktop\MetaGPT\Role\Researcher.py", line 73, in _act
    summaries = await asyncio.gather(*todos)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\Desktop\MetaGPT\Action\SearchInWeb.py", line 235, in run
    summary = await self._aask(prompt, [system_text])
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\actions\action.py", line 67, in _aask
    return await self.llm.aask(prompt, system_msgs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\base_llm.py", line 50, in aask
    rsp = await self.acompletion_text(message, stream=stream, timeout=timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\tenacity\_asyncio.py", line 88, in async_wrapped
    return await fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\tenacity\_asyncio.py", line 47, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\tenacity\__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\tenacity\_asyncio.py", line 50, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 134, in acompletion_text
    async for i in resp:
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\provider\openai_api.py", line 90, in _achat_completion_stream
    response: AsyncStream[ChatCompletionChunk] = await self.aclient.chat.completions.create(
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\resources\chat\completions.py", line 1295, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1536, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1315, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1378, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1418, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1378, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1418, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1392, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo-16k in organization org-uNIHl8OdY75ltR3N8pdUe7Hl on tokens per min (TPM): Limit 60000, Used 55198, Requested 9979. Please try again in 5.177s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}


