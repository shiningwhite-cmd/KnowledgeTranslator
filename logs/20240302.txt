2024-03-02 14:36:47.028 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:36:47.030 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:36:47.030 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:36:47.030 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:36:49.151 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:36:49.151 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:36:49.221 | DEBUG    | metagpt.roles.role:_observe:397 - David(Researcher) observed: ['user: 在线语音社交...']
2024-03-02 14:36:49.221 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=0
2024-03-02 14:36:49.221 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do CollectLinks(CollectLinks)
2024-03-02 14:46:11.473 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:46:11.473 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:46:11.473 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:46:11.473 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:46:12.713 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:46:12.713 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:46:12.730 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:46:12.731 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:46:12.731 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:46:12.731 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2", "keyword3", ...].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is:

2024-03-02 14:46:14.557 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 226, completion_tokens: 37
2024-03-02 14:46:14.557 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-02 14:46:35.371 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:46:35.371 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:46:35.372 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:46:35.372 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:46:36.613 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:46:36.613 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:46:36.629 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:46:36.630 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:46:36.630 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:46:36.630 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2", "keyword3", ...].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is:

2024-03-02 14:46:39.717 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 226, completion_tokens: 37
2024-03-02 14:46:39.717 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:47:24.185 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:47:24.185 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:47:24.185 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:47:24.185 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:47:25.448 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:47:25.448 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:47:25.464 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:47:25.465 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:47:25.465 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:47:25.465 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract 1 or 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2", "keyword3", ...].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is:

2024-03-02 14:47:27.238 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 231, completion_tokens: 33
2024-03-02 14:47:27.238 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:48:05.360 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:48:05.360 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:48:05.360 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:48:05.360 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:48:06.585 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:48:06.585 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:48:06.602 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:48:06.602 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:48:06.602 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:48:06.602 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract 1 or 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is:

2024-03-02 14:48:08.539 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 226, completion_tokens: 33
2024-03-02 14:48:08.539 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:49:06.243 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:49:06.243 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:49:06.243 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:49:06.243 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:49:07.472 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:49:07.472 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:49:07.490 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:49:07.490 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:49:07.490 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:49:07.491 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract ** less than 2 ** keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is:

2024-03-02 14:49:09.168 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 227, completion_tokens: 32
2024-03-02 14:49:09.168 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:49:48.078 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:49:48.078 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:49:48.078 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:49:48.078 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:49:49.312 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:49:49.312 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:49:49.328 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:49:49.329 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:49:49.329 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:49:49.329 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-02 14:49:50.664 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-02 14:49:50.664 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:50:13.477 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:13.477 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:13.477 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:50:13.477 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:50:14.710 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:14.710 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:14.741 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:50:14.741 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:50:14.741 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:50:14.741 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-02 14:50:16.288 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-02 14:50:16.288 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:50:19.357 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:19.357 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:19.357 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:50:19.357 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:50:20.613 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:20.614 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:20.630 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:50:20.630 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:50:20.630 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:50:20.630 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-02 14:50:22.151 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-02 14:50:22.151 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:50:24.488 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:24.488 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:24.488 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:50:24.488 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:50:25.730 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:25.730 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:25.746 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:50:25.746 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:50:25.747 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:50:25.747 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-02 14:50:27.264 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-02 14:50:27.265 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 14:50:31.360 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:31.360 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:31.361 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 14:50:31.361 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 14:50:32.603 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 14:50:32.603 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 14:50:32.620 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['user: Large Language Model...']
2024-03-02 14:50:32.620 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 14:50:32.621 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 14:50:32.621 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-02 14:50:34.120 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-02 14:50:34.121 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 15:09:37.290 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 15:09:37.291 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 15:09:37.291 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 15:09:37.291 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 15:12:40.648 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 15:12:40.648 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 15:12:40.649 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 15:12:40.649 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 15:13:11.700 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 15:13:11.700 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 15:13:11.701 | DEBUG    | metagpt.config:_ensure_workspace_exists:227 - WORKSPACE_PATH set to C:\Users\sxb23\Desktop\MetaGPT\workspace
2024-03-02 15:13:11.701 | DEBUG    | metagpt.config:__init__:85 - Config loading done.
2024-03-02 15:13:12.955 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 15:13:12.955 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 15:13:13.001 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 15:13:13.002 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 15:13:13.027 | DEBUG    | metagpt.environment:publish_message:108 - publish_message: {"id":"78b341380b064547b74ee4f1d69759d8","content":"Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.","role":"Human","cause_by":"metagpt.actions.add_requirement.UserRequirement","sent_from":"","send_to":["<all>"]}
2024-03-02 15:13:13.027 | DEBUG    | metagpt.team:run:130 - max n_round=0 left.
2024-03-02 15:13:13.027 | DEBUG    | metagpt.roles.role:_observe:397 - David(Researcher) observed: ['Human: Large Language Model...']
2024-03-02 15:13:13.027 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=0
2024-03-02 15:13:13.027 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do CollectLinks(CollectLinks)
2024-03-02 15:13:13.048 | DEBUG    | metagpt.roles.role:_observe:397 - Johnson(Extractor) observed: ['Human: Large Language Model...']
2024-03-02 15:13:13.048 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=0
2024-03-02 15:13:13.048 | INFO     | Role.Extractor:_act:36 - Johnson(Extractor): to do KeywordExtract(KeywordExtract)
2024-03-02 15:13:13.048 | DEBUG    | Action.KeywordExtract:run:71 - # Requirements
1. The keywords you interested in should be proper nouns or the words which are more difficult to understand.
2. The given text is shown in the "Original Text" section, you should extract less than 2 keywords from the text.
3. "Example" section provides you an example of keyword extraction, you can learn from it.
4. Please respond in the following JSON format: ["keyword1", "keyword2"].

# Example
### Original Text
In this work, we present xxxx, a large language model augmented with tools for knowledge retrieval for mathematical reasoning.
### Result
["large language model", "knowledge retrieval"]

# Original Text
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.

# Result
your result is (no more than 2 keywords):

2024-03-02 15:13:14.282 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 232, completion_tokens: 13
2024-03-02 15:13:14.282 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[KeywordExtract], state=-1
2024-03-02 15:13:14.283 | DEBUG    | metagpt.environment:publish_message:108 - publish_message: {"id":"d4d7693e87364727a9d585b44ecea141","content":"[\"Large Language Models\", \"program-of-thoughts approach\"]","role":"Extractor","cause_by":"Action.KeywordExtract.KeywordExtract","sent_from":"","send_to":["<all>"]}
2024-03-02 15:13:14.423 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 112, completion_tokens: 15
2024-03-02 15:13:15.367 | INFO     | metagpt.config:get_default_llm_provider_enum:124 - LLMProviderEnum.OPENAI Model: gpt-3.5-turbo-16k
2024-03-02 15:13:15.367 | INFO     | metagpt.config:get_default_llm_provider_enum:126 - API: LLMProviderEnum.OPENAI
2024-03-02 15:13:15.371 | DEBUG    | Action.SearchInWeb:run:142 - ### Requirements
1. The keywords related to your research topic and the search results are shown in the "Search Result Information" section.
2. Provide up to 4 queries related to your research topic base on the search results.
3. Please respond in the following JSON format: ["query1", "query2", "query3", ...].

### Search Result Information
#### Keyword: 大型语言模型
 Search Result: [{'title': 'ChatGPT — LLM 模型（大型语言模型）. 中國 — 了解ChatGPT 的 ...', 'link': 'https://medium.com/chatgpt-learning-asia/chatgpt-llm-%E6%A8%A1%E5%9E%8B-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-2947b198fc8e', 'snippet': 'May 12, 2023 ... ChatGPT — LLM 模型（大型语言模型）. LLM（大型语言模型）是这些模型中最著名的。 用于使用自然语言处理(NLP) 算法和称为Transformers 的AI 训练技术解决\xa0...'}, {'title': '设置开源大型语言模型: - 作者花了几个晚上设置一台家用笔记本电脑 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%BA%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-81ec2bf5842a', 'snippet': '7 days ago ... - 在本地使用开源模型，例如Code Llama LLM，可以对Python 代码进行实验和交叉检查。 “运行”与“训练”大型语言模型的重要性: - 与训练模型相比，在笔记本\xa0...'}, {'title': '从「文化技术」理解大型语言模型- LM Po - Medium', 'link': 'https://medium.com/@edmond.po/%E4%BB%8E%E6%96%B0%E6%96%87%E5%8C%96%E6%8A%80%E6%9C%AF%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B2%BB%E7%90%86-bb7239eb4c8b', 'snippet': 'Jul 14, 2023 ... 人工智能(AI) 的最新进展，特别是在大型语言模型(Large Language Model — LLM) 领域（例如OpenAI 的ChatGPT 和Google 的LaMDA），引发了有关这些系统\xa0...'}, {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... 在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。'}, {'title': 'RAG 檢索增強生成— 讓大型語言模型更聰明的秘密武器. 看完文章後 ...', 'link': 'https://medium.com/infuseai/rag-retrieval-augmented-generation-introduction-a5854cb6393e', 'snippet': 'Nov 5, 2023 ... I. RAG 檢索增強生成. 檢索增強生成（Retrieval-Augmented Generation, RAG）是一種結合了搜尋檢索和生成能力的自然語言處理架構。透過這個架構，模型可以\xa0...'}, {'title': 'Building Large Language Model-powered AI Applications | by Xin ...', 'link': 'https://medium.com/mlearning-ai/building-large-language-model-powered-ai-applications-96780d67c64a', 'snippet': 'May 8, 2023 ... I want to survey building AI applications powered by large language models and related emerging technologies.'}, {'title': 'Mastering LLM (Large Language Model) – Medium', 'link': 'https://medium.com/@masteringllm', 'snippet': 'Read writing from Mastering LLM (Large Language Model) on Medium. Dedicated to knowledge sharing and simplified explanations for LLM .'}, {'title': 'TAIDE 模型介紹— 帶有台灣味的大型語言模型. 看完文章後歡迎按鼓勵 ...', 'link': 'https://medium.com/infuseai/taide-model-introduction-f14d1334bf17', 'snippet': 'Nov 26, 2023 ... TAIDE 模型是一個針對台灣文化特色和需求定制的生成式人工智慧對話引擎。它整合了台灣獨有的語言、價值觀、和風俗習慣，目的是強化台灣在科技領域的實力與\xa0...'}]

#### Keyword: 数值计算错误
 Search Result: [{'title': '租赁大数据看板建设过程中数据清洗及程度思考| 人人都是产品经理', 'link': 'https://www.woshipm.com/data-analysis/4998713.html', 'snippet': '如果只是想客观看看市场行情，或者该字段并不是太重要的数据，只是走势有参考作用，则可以考虑删除对应的数据，以免造成困扰，避免空值导致计算结果偏差或报错。 四、错误\xa0...'}, {'title': '市场数据预言机的可靠性和安全性. 让我们聊一聊可靠性的话题… | by ...', 'link': 'https://pythchinese.medium.com/pyth-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%A2%84%E8%A8%80%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7-f9de664e5d01', 'snippet': 'May 13, 2022 ... ... 数据的。 每个数据发布者Bᵢ 发生程序错误的概率。我们通过寻找历史价格序列中的极端异常情况来计算这个概率，例如价格为0 或价格与聚合价格相差一个\xa0...'}, {'title': '學習記錄. Question | by 肚子又餓了٩(ŏ﹏ŏ、)۶ | Medium', 'link': 'https://medium.com/@superwang0603/%E5%AD%B8%E7%BF%92%E8%A8%98%E9%8C%84-8a76d93dab05', 'snippet': 'Feb 23, 2023 ... 这是因为fit_transform 方法会根据训练数据计算标准化所需的统计特性，然后将训练数据标准化。 ... 错误，提示需要先使用fit 方法计算训练数据的均值和标准\xa0...'}, {'title': '产品经理在数据分析过程中常用的Excel技能| 人人都是产品经理', 'link': 'https://www.woshipm.com/data-analysis/5748189.html', 'snippet': '下图所示的这个公式就是一个iferror的使用案例，当蓝色选中部分的最终计算结果是一个错误值的时候，即运算无法正常进行，出现报错时，整个公式最终的返回值就是0。用这个\xa0...'}, {'title': '从用户视角，讨论电商数据产品的设计理念| 人人都是产品经理', 'link': 'https://www.woshipm.com/pd/5697865.html', 'snippet': '... 数据来计算；; 以数据作为未来目标，猜想未来，例如通过数据趋势猜想未来变化，和制定目标。 数据是该人群工作场景中的基础。以一份错误的数据作为依据，会导致产生错误\xa0...'}, {'title': '交通| GAMS快速入门及其在运输问题求解的应用. 推文作者：AmieeXue', 'link': 'https://medium.com/@operations_r/%E4%BA%A4%E9%80%9A-gams%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%8F%8A%E5%85%B6%E5%9C%A8%E8%BF%90%E8%BE%93%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3%E7%9A%84%E5%BA%94%E7%94%A8-347532daf9e', 'snippet': 'Jul 3, 2023 ... 美元符号后面是数字错误代码，在回显打印后进行解释。下面是几个例子 ... 可以通过提供用于计算数据的公式而不是明确输入它们，来节省时间并减少输入\xa0...'}, {'title': 'LEO 中的定点运算- aleo123_io - Medium', 'link': 'https://medium.com/@aleo123_io/leo-%E4%B8%AD%E7%9A%84%E5%AE%9A%E7%82%B9%E8%BF%90%E7%AE%97-305e1b7d0cbc', 'snippet': 'Apr 4, 2023 ... 同时, 最大表示错误被计算为(1/S)/2，所以在这个例子中，它是(1/25)/2=1/64=0.015625。 因此，一个更宽泛的倍数因子使我们能够有更准确的数字表达\xa0...'}, {'title': 'A/B测试算法揭秘第二篇：如何分析试验数据（上） | 人人都是产品经理', 'link': 'https://www.woshipm.com/pmd/380883.html', 'snippet': '第I 类错误（弃真错误）：原假设为真时拒绝原假设；第I 类错误的概率记为α(alpha) ... 例如，我们根据某次假设检验的样本数据计算得出显著性水平p=0.04；这个值意味着\xa0...'}]


2024-03-02 15:13:17.051 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.011 | Max budget: $10.000 | Current cost: $0.010, prompt_tokens: 3132, completion_tokens: 55
2024-03-02 15:13:17.741 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
大型语言模型 数值计算错误

### The online search results
0: {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... 未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与 ... 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的\xa0...'}
1: {'title': '从「文化技术」理解大型语言模型- LM Po - Medium', 'link': 'https://medium.com/@edmond.po/%E4%BB%8E%E6%96%B0%E6%96%87%E5%8C%96%E6%8A%80%E6%9C%AF%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B2%BB%E7%90%86-bb7239eb4c8b', 'snippet': 'Jul 14, 2023 ... 像LLM这样的技术擅长在训练数据中模仿语言模式。然而，产生新颖见解需要 ... · 新的「文化技术」既带来好处（传播知识），也带来风险（传播错误信息）。'}
2: {'title': 'GPT-4，OpenAI的断崖式领先，人类的专属技能不多了| 人人都是产品 ...', 'link': 'https://www.woshipm.com/ai/5782495.html', 'snippet': '... 大型语言模型，以及大多数最先进的(SOTA) 模型：. GPT-4，OpenAI的断崖式领先 ... 遵循GPT、GPT-2和GPT-3的研究路径，OpenAI的深度学习方法利用更多数据和更多计算来创建越来\xa0...'}
3: {'title': '如何利用AI学习区块链知识- Moonbeam 中文- Medium', 'link': 'https://medium.com/moonbeam-%E4%B8%AD%E6%96%87/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8ai%E5%AD%A6%E4%B9%A0%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9F%A5%E8%AF%86-7f1e4d7e152f', 'snippet': 'May 24, 2023 ... ... 错误的识别方面提供帮助。ChatGPT的出现为开发者提供了便利性 ... Kapa.ai结合了技术知识来源的语义检索系统，并由包括GPT-4在内的大型语言模型提供支持。'}
4: {'title': 'Unlocking Cloud Security: The 6 Pillars of Cloud Protection | by ECF ...', 'link': 'https://medium.com/@ecfdataus/unlocking-cloud-security-the-6-pillars-of-cloud-protection-f47767e3319c', 'snippet': 'Dec 27, 2023 ... Users take care of their data and access, and providers make sure the infrastructure and platform are secure. This shared responsibility model\xa0...'}
5: {'title': '人工智能简史（Draft）. 追溯机器人思维的兴起| by Conan Xin | Medium', 'link': 'https://conanxin.medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2-draft-35531f6449b2', 'snippet': 'May 27, 2023 ... 积累足够的数据、计算和能量以将现有模型开发到足够的阈值需要什么？ 换 ... 大型语言模型中自发地出现了。在此之前，心智理论被认为是一种明显的人类\xa0...'}
6: {'title': 'GPT-4V连小学生都不如？最新基准测试错误率竟高达90%：红绿灯 ...', 'link': 'https://www.woshipm.com/ai/5931690.html', 'snippet': '自然语言处理（NLP）和计算机视觉（CV）的结合，不仅促成了大型视觉语言模型（LVLM）的诞生，而且显著提高了图像推理任务的性能。 但是，LVLM仍面临着一些挑战，如语言幻觉\xa0...'}
7: {'title': 'Kai：科技进化的临界点已经到来！ - Future3 Campus - Medium', 'link': 'https://medium.com/@Future3Campus/kai-%E7%A7%91%E6%8A%80%E8%BF%9B%E5%8C%96%E7%9A%84%E4%B8%B4%E7%95%8C%E7%82%B9%E5%B7%B2%E7%BB%8F%E5%88%B0%E6%9D%A5-9cf3fb62c820', 'snippet': 'Aug 27, 2023 ... 但忽然有一天，大语言模型LLM的出现给了我们一个新的方向。这是一个关于科技爆发的重要特征，向我们证明前面所说的，它必定是源于几十年的技术试错和不同\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-02 15:13:18.860 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.016 | Max budget: $10.000 | Current cost: $0.006, prompt_tokens: 1874, completion_tokens: 15
2024-03-02 15:13:19.559 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
大型语言模型 程序错误

### The online search results
0: {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... 未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与 ... 随着交易监测能力的成本上升以及监管压力增加，要求个人对合规程序失败\xa0...'}
1: {'title': '从「文化技术」理解大型语言模型- LM Po - Medium', 'link': 'https://medium.com/@edmond.po/%E4%BB%8E%E6%96%B0%E6%96%87%E5%8C%96%E6%8A%80%E6%9C%AF%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B2%BB%E7%90%86-bb7239eb4c8b', 'snippet': 'Jul 14, 2023 ... 通过获取和传播知识，我们很容易受错误信息和操纵影响。书写和印刷等技术 ... I Built an App in 6 Hours that Makes $1,500/Mo. Copy my strategy! ·3\xa0...'}
2: {'title': '如何利用AI学习区块链知识- Moonbeam 中文- Medium', 'link': 'https://medium.com/moonbeam-%E4%B8%AD%E6%96%87/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8ai%E5%AD%A6%E4%B9%A0%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9F%A5%E8%AF%86-7f1e4d7e152f', 'snippet': 'May 24, 2023 ... ... 错误的识别方面提供帮助。ChatGPT的出现为开发者提供了便利性 ... Kapa.ai结合了技术知识来源的语义检索系统，并由包括GPT-4在内的大型语言模型提供支持。'}
3: {'title': 'ChatGPT 怎么注册最新详细教程新手小白一看就会- Lifesangkl ...', 'link': 'https://medium.com/@lifesangkl/chatgpt-%E6%80%8E%E4%B9%88%E6%B3%A8%E5%86%8C%E6%9C%80%E6%96%B0%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B-%E6%96%B0%E6%89%8B%E5%B0%8F%E7%99%BD%E4%B8%80%E7%9C%8B%E5%B0%B1%E4%BC%9A-ee5bc018e8cf', 'snippet': 'Jun 6, 2023 ... ... 程序错误等。 而当人们问它“ChatGPT能否取代人类”时，它反而会表示 ... 大型语言模型并通过强化学习进行训练。ChatGPT于2022年11月30日发布，它\xa0...'}
4: {'title': '人工智能简史（Draft）. 追溯机器人思维的兴起| by Conan Xin | Medium', 'link': 'https://conanxin.medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2-draft-35531f6449b2', 'snippet': 'May 27, 2023 ... ... 程序能够以与人类无异的方式理解和产生语言。 几十年来，文本是一种通用 ... 大型语言模型中自发地出现了。在此之前，心智理论被认为是一种明显的人类\xa0...'}
5: {'title': '大型語言模型的預訓練任務. ChatGPT… | by Albert Chen | Jan, 2024 ...', 'link': 'https://medium.com/@albertchen3389/%E5%A4%A7%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A0%90%E8%A8%93%E7%B7%B4%E4%BB%BB%E5%8B%99-b831dcf8f6f7', 'snippet': 'Jan 4, 2024 ... 例如，它可能會對句子的結構進行改動，或者在句子中加入錯誤信息。這樣做的目的是讓模型學習在更複雜的情況下恢復原始文本。舉例來說，原句子“小狗在公園\xa0...'}
6: {'title': '智谱GLM-4 大语言模型好用吗？. 我替你尝试了它的基本对话、绘图 ...', 'link': 'https://wshuyi.medium.com/%E6%99%BA%E8%B0%B1-glm-4-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%A5%BD%E7%94%A8%E5%90%97-2f9299e1b6ae', 'snippet': 'Jan 17, 2024 ... 我在想，作为一个中文的大型语言模型，它增强了接受中文提示词的能力后 ... 可惜，在生成代码并完成处理后，GLM-4 又一次报告了错误。 好在一旦出现\xa0...'}
7: {'title': '大型語言模型（LLM）對自然語言處理（NLP）的影響- AI 講講話 ...', 'link': 'https://medium.com/aigeneral/%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E5%B0%8D%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86-nlp-%E7%9A%84%E5%BD%B1%E9%9F%BF-277641294517', 'snippet': 'Aug 23, 2023 ... 語言分類：根據文本內容進行情感分析或主題分類等。 語言錯誤指正：LLM 可以自動檢測拼寫錯誤或語法錯誤等。 透過LLM 的發展，研究者們不斷地嘗試使\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-02 15:13:20.642 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.023 | Max budget: $10.000 | Current cost: $0.007, prompt_tokens: 2254, completion_tokens: 24
2024-03-02 15:13:21.460 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
大型语言模型 数值计算准确性

### The online search results
0: {'title': '揭示零样本预测的机制：利用机器学习模型来理解大型语言模型 ...', 'link': 'https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0', 'snippet': 'May 31, 2023 ... ... 数据帧的脚本，将其生成的合成信息纳入其中。完美！ 当我提出另一个问题时，回答是准确的，但过于详细，缺乏直接性。 为了解决这个问题，我不得不对我\xa0...'}
1: {'title': '大语言模型数据隐私的解决之道：全同态加密- Ingonyama 中文 ...', 'link': 'https://medium.com/@ingonyamachinese/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9A%90%E7%A7%81%E7%9A%84%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93-%E5%85%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86-b4eedcf33194', 'snippet': 'Sep 24, 2023 ... 在密码学领域，全同态加密是一个突破性的概念。它的魅力在于神奇的特性：它允许对加密数据进行计算，而无需先解密，实现对敏感信息的隐私推理。'}
2: {'title': 'Space and Time，简称SxT - ranran - Medium', 'link': 'https://medium.com/@ranran123/space-and-time-%E7%AE%80%E7%A7%B0sxt-875639f4628f', 'snippet': 'Jan 9, 2024 ... ... 计算科学领域的前沿技术，旨在通过可验证的计算层，在分散的数据仓库上扩展零知识证明的应用。这一概念在智能合同、大型语言模型（LLM）以及企业级\xa0...'}
3: {'title': '将数千兆字节的数据引入智能合约：与Space and Time的Scott ...', 'link': 'https://medium.com/@hopeofmavia/%E5%B0%86%E6%95%B0%E5%8D%83%E5%85%86%E5%AD%97%E8%8A%82%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BC%95%E5%85%A5%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%B8%8Espace-and-time%E7%9A%84scott-dykstra%E8%BF%9B%E8%A1%8C%E5%AF%B9%E8%AF%9D-ccdedf5cd815', 'snippet': 'Feb 19, 2024 ... 通过将这样的系统与大型语言模型集成，您可以实现对模型输出的可验证性和防篡改性。您可以确保模型的训练数据没有被篡改，并且模型在生成输出时没有进行\xa0...'}
4: {'title': '空间和时间（Space and Time，简称SxT）：可验证计算层的新纬度 ...', 'link': 'https://medium.com/@gainai898/%E7%A9%BA%E9%97%B4%E5%92%8C%E6%97%B6%E9%97%B4-space-and-time-%E7%AE%80%E7%A7%B0sxt-%E5%8F%AF%E9%AA%8C%E8%AF%81%E8%AE%A1%E7%AE%97%E5%B1%82%E7%9A%84%E6%96%B0%E7%BA%AC%E5%BA%A6-f7872210949b', 'snippet': 'Jan 7, 2024 ... ... 性和安全性的关注。这一新兴技术有望在智能合同、大型语言模型和企业数据处理等领域发挥关键作用，为数字时代的数据处理提供了更加安全和可靠的基础。'}
5: {'title': '设置开源大型语言模型: - 作者花了几个晚上设置一台家用笔记本电脑 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%BA%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-81ec2bf5842a', 'snippet': '7 days ago ... “运行”与“训练”大型语言模型的重要性: - 与训练模型相比，在笔记本电脑上运行 ... - 累积距离以及每个路段的计算步速均已添加到数据集中。 计算段信息\xa0...'}
6: {'title': 'Footprint Analytics x Future3 Campus联合发布AI与Web3研究报告 ...', 'link': 'https://medium.com/@Future3Campus/footprint-analytics-x-future3-campus%E8%81%94%E5%90%88%E5%8F%91%E5%B8%83ai%E4%B8%8Eweb3%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A-c3759e8c46cf', 'snippet': 'Dec 4, 2023 ... 大型语言模型的培训需要依赖大规模数据，通过学习数据中的模式来建立模型 ... 流畅度指的是模型的输出是否自然、通顺，准确性则表示模型的答案是否准确。'}
7: {'title': '人工智能简史（Draft）. 追溯机器人思维的兴起| by Conan Xin | Medium', 'link': 'https://conanxin.medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2-draft-35531f6449b2', 'snippet': 'May 27, 2023 ... 大型语言模型成功的秘诀在于它们独特的架构。这种架构仅在六年前出现 ... 首先，模型的准确性通过成本函数进行评估。返回不正确的答案会给模型带来成本\xa0...'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-02 15:13:22.759 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.030 | Max budget: $10.000 | Current cost: $0.007, prompt_tokens: 2152, completion_tokens: 15
2024-03-02 15:13:24.686 | DEBUG    | Action.SearchInWeb:_search_and_rank_urls:170 - ### Topic
Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.
### Query
大型语言模型 可执行代码生成

### The online search results
0: {'title': '作者花了几个晚上设置一台家用笔记本电脑来运行开源大型语言模型 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%BA%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-81ec2bf5842a', 'snippet': '7 days ago ... - 在本地使用开源模型，例如Code Llama LLM，可以对Python 代码进行实验和交叉检查。 ... - 该博客讨论了编码领域中Python 代码生成、气味识别和法学硕士\xa0...'}
1: {'title': '基于大语言模型的自主智能体实现调研. A Survey on Large Language ...', 'link': 'https://medium.com/@xiaofeng_metis/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-a-survey-on-large-language-model-based-autonomous-agents-f2bdf348e4eb', 'snippet': 'Sep 1, 2023 ... 随着进一步发展，基于LLM的代理可能会创新地设计宇宙飞船，模拟流体流动，进行结构分析，甚至通过生成可与工程系统集成的可执行代码来控制自主车辆。 工业\xa0...'}
2: {'title': 'ChatGPT — LLM 模型（大型语言模型）. 中國 — 了解ChatGPT 的 ...', 'link': 'https://medium.com/chatgpt-learning-asia/chatgpt-llm-%E6%A8%A1%E5%9E%8B-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-2947b198fc8e', 'snippet': 'May 12, 2023 ... 他们可以通过聊天机器人以文本格式回答问题，应用范围非常广泛，例如：. 了解蛋白质、分子、DNA 和RNA。 编写计算机代码。 为图像生成器构建文本和图像对\xa0...'}
3: {'title': 'ChatGPT 和谈话的艺术：生成人工智能的潜力分析。. 中國 — 了解 ...', 'link': 'https://medium.com/chatgpt-learning-asia/chatgpt-%E5%92%8C%E8%B0%88%E8%AF%9D%E7%9A%84%E8%89%BA%E6%9C%AF-%E7%94%9F%E6%88%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%BD%9C%E5%8A%9B%E5%88%86%E6%9E%90-612fed17a727', 'snippet': 'May 12, 2023 ... 他们接受了大量数据的训练，可以适应创建其他专业模型并生成多个应用程序。 ... 第4 节— ChatGPT — LLM 模型（大型语言模型）. ChatGPT и искусство общения\xa0...'}
4: {'title': 'PDF对话助手: - 一种促进用户和PDF 文档之间交互的工具，允许用户 ...', 'link': 'https://medium.com/@wmfhgn17lwxlwfefa1szia/pdf%E5%AF%B9%E8%AF%9D%E5%8A%A9%E6%89%8B-667893ba81f7', 'snippet': '6 days ago ... ... 程序的框架，特别是那些利用语言模型的应用程序。 - 处理文档摄取、文本处理以及与语言模型交互等任务。 LLM（大型语言模型）: ... 可读的格式。 - 它执行\xa0...'}
5: {'title': '淺談GPT 生成式語言模型(1) — 過去. 本文內容難度： | by SimonLiu ...', 'link': 'https://medium.com/infuseai/gpt-model-past-introduction-1e2558462e41', 'snippet': 'Feb 7, 2023 ... ChatGPT 透過生成式預訓練轉換器GPT 模型，並且引用了強大的預訓練模型，讓模型可以執行各種複雜的NLP 任務，如問答、文章生成、文本摘要等，這個模型\xa0...'}
6: {'title': 'opML is All You Need: 在以太坊运行13B 机器学习模型| by ORA 中文 ...', 'link': 'https://medium.com/@ora-zh/opml-is-all-you-need-%E5%9C%A8%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%BF%90%E8%A1%8C-13b-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B-f7b20eec8260', 'snippet': 'Oct 25, 2023 ... ... 模型推断和训练/微调. 与zkML 相比, opML 提供了低成本和高效率的ML 证明. opML 的硬件要求较低: opML 可以在普通PC 上运行大型语言模型, 例如7B\xa0...'}
7: {'title': '生成式AI 参与的未来，行业该做好哪些准备？. 来源丨CoinTelegraph ...', 'link': 'https://medium.com/@Web3CN_Pro/%E7%94%9F%E6%88%90%E5%BC%8F-ai-%E5%8F%82%E4%B8%8E%E7%9A%84%E6%9C%AA%E6%9D%A5-%E8%A1%8C%E4%B8%9A%E8%AF%A5%E5%81%9A%E5%A5%BD%E5%93%AA%E4%BA%9B%E5%87%86%E5%A4%87-1ca75751f242', 'snippet': 'May 12, 2023 ... ... 大型数据集上运行，并生成新颖、独特的内容。 最流行的生成式AI ... 它是OpenAI 开发的一种有效的生成式AI 语言模型，可以快速响应用户命令、生成内容。'}

### Requirements
Please remove irrelevant search results that are not related to the query or topic. Then, sort the remaining search results based on the link credibility. If two results have equal credibility, prioritize them based on the relevance. Provide the
ranked results' indices in JSON format, like [0, 1, 3, 4, ...], without including other words.

2024-03-02 15:13:26.194 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.036 | Max budget: $10.000 | Current cost: $0.006, prompt_tokens: 1947, completion_tokens: 15
2024-03-02 15:13:26.194 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=1
2024-03-02 15:13:26.194 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do WebBrowseAndSummarize(WebBrowseAndSummarize)
2024-03-02 15:13:37.537 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

揭示零样本预测的机制：利用机器学习模型来理解大型语言模型（LLM）的决策过程

Ray Mi

·

Follow

May 31, 2023
引言

当代的机器学习领域，像ChatGPT这样的大型语言模型（LLM）正日益受到关注。它们在知识库、智能搜索机制、聊天机器人和内容创作等各种应用中展现出巨大的潜力。

在机器学习空间中，一个常见的挑战是获取用于验证假设和假定的高质量、代表性的数据。由于高成本、有限的可用性、数据清洁度问题、潜在的偏见以及安全和隐私方面的顾虑等多种障碍，收集这样的数据可能是艰巨的任务。

在与众多客户的讨论中，我注意到人们对于利用ChatGPT和其他LLM的担忧。这些担忧大多源于安全和隐私考虑，导致许多组织选择不使用这些模型。

我与许多客户谈过，了解他们公司对ChatGPT和LLM的看法，大多数公司因为安全和隐私的担忧而禁止使用ChatGPT。

由于将数据与LLM相连接是困难的，为什么我们不利用内容创作的能力来生成合成数据，并将这些数据作为机器学习项目的输入呢？

在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。简而言之，该模型利用其训练时所学的知识进行预测，并在很少或没有上下文的情况下做出假设。

在本文中您将看到：

如何设计正确的提示来从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测）。
创建合成数据并实施提示策略，以获得大量观察结果的回应。
利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策的基本原理。

本文是一系列多个实验中的第一篇，使用相似的业务案例进行演示。未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与业务逻辑和现有流程更紧密地对齐。请随我们一起踏上这个激动人心的大型语言模型潜力开发之旅，敬请关注。

应用案例

在加入DataRobot之前，我在汇丰银行担任全球风险分析经理/副总裁。我的主要职责是利用机器学习优化交易监测系统，并加强我们的反洗钱（AML）框架。为了说明我的工作，我将以AML为例。

什么是洗钱？

洗钱是指通过一系列复杂的银行转账或商业交易来掩盖非法获取资金的来源的非法过程。整个洗钱过程的方案以一种模糊且间接的方式将“洗净”的资金返还给洗钱者。

为什么洗钱是一个难题？

联合国的研究表明，全球洗钱金额估计占全球GDP的2–5%。 随着交易监测能力的成本上升以及监管压力增加，要求个人对合规程序失败承担更多责任，许多组织现在正在寻求突破性技术来解决这些挑战。

理解交易监测框架及其挑战：

简单来说，交易监测过程始于数据，其中包括交易细节和客户资料。银行然后在其交易监测系统（TMS）中应用业务规则。系统监测交易行为并生成一批可能可疑的警报。 然后，由专家团队手动调查这些警报，以确定它们是否真正可疑或仅仅是误报。这个过程可能具有挑战性且耗时，这就是创新技术可以在提高效率和效果方面发挥关键作用的地方。

机器学习如何帮助？

机器学习可以在这个过程中提供巨大的帮助。它可以利用历史交易数据、客户信息和过去的调查结果（无论是真警报还是误报）来预测每个新警报的风险水平。然后可以利用这些信息在手动调查之前对警报进行优先级排序。这不仅简化了流程，还确保及时处理最可能造成损害的问题。

大型语言模型（LLM）如何协助？

当数据收集具有挑战性或反洗钱（AML）团队正在创建新的监测规则时，LLM可以成为宝贵的工具。它们可以用于：a）生成合成数据，和b）预测警报是否可疑。这有助于更有效的监测规则，并协助高效处理警报，促进反洗钱框架的整体优化。

我们能够相信LLMs的辅助作用吗？

如果我们利用机器学习来模拟这些模型所做的决策，我们可以对LLMs产生-的洞察力进行验证和增强，从而对它们对我们的交易监测系统的贡献的可靠性产生信任。通过审查洞察力并理解LLMs预测背后的推理，我们可以验证和增强它们对我们的交易监测系统的贡献的可靠性。
实验过程

为了从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测），我设计了合适的提示语。

首先，我设计了一个简单的提示语，要求提供一个客户的30天交易摘要。ChatGPT给出了一些建议，但没有提供具体的数字数据。

然后，我修改了问题，使其更加精确和详细。我收到的回答非常出色和结构清晰。这种叙述在警报调查过程中非常常见，通常调查专家会利用这些信息来得出结论。

令人惊讶的是，ChatGPT甚至能够创建一个用于生成pandas数据帧的脚本，将其生成的合成信息纳入其中。完美！

当我提出另一个问题时，回答是准确的，但过于详细，缺乏直接性。

为了解决这个问题，我不得不对我的问题进行进一步的细化，使其更加具体地满足我的需求。

到目前为止，我们已经成功地使用了合理的提示策略从LLMs生成了合成数据和预测，甚至没有任何历史上下文。这显示了这些模型在从提示中生成有用、可操作的信息方面的潜力。

创建合成数据并实施提示策略以获取大量观测结果。

在这部分中，我简化了问题，只考虑了8个维度：（ACH-自动清算系统，Wire-电汇）×（交易金额，交易次数）×（实际活动，预期活动）。

我将这个新规则称为“与预期行为的Wire和ACH偏差”。

通过一些文本操作，我能够生成如下的提示语：

“在回答中只回答是或否，不要提供其他信息。这是问题的内容：我正在调查一起潜在的洗钱案件，客户的30天交易行为如下：Wire金额：$7148.0，Wire交易次数：5.0次；ACH金额：$15318.0，ACH交易次数：16.0次；该客户的预期行为是：Wire金额：$7486.0，Wire交易次数：8.0次；ACH金额：$4767.0，ACH交易次数：4.0次；基于实际和预期行为，这个案件是否可疑？”

以下是一个示例：

基于上述实验，我建立了一个包含300名客户的数据集。从每一行中，我生成了一个提示语，并从ChatGPT获得了一个“是”或“否”的回答。 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的一个重要因素。

这是数据集的前几行：

利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策背后的原理。

在对300条记录进行分析后，ChatGPT将其中180条分类为“是”（可疑）和120条分类为“否”（误报）。

让我们快速检查一下Wire交易金额的分布。

交易金额和每种交易类型的交易次数之间存在明显的相关性，这是符合预期和逻辑的。

DataRobot开发了许多模型，并根据首选指标（在本例中是AUC）对它们进行了排名。最优模型的ROC曲线显示了其有效区分ChatGPT“是”和“否”回答的能力。

通过利用基于SHAP的特征影响分析，我们发现尽管提示主要侧重于比较实际值和预期值（“比率”变量），但实际交易金额和交易次数（例如Txn Cnt ACH）也对预测有显著贡献。

让我们深入研究一下前几个关键特征的影响：

当ACH交易次数超过9次时，较高的值显著增加”是”预测的概率。
对于实际和预期Wire交易金额之间的比率，超过1的偏离值表示更高的风险，当该比率超过2时，风险显著增加。
与前一个情况相反，当ChatGPT评估实际和预期ACH交易次数之间的偏离时，低于预期值（<0.8）也引起怀疑。
当实际Wire交易金额超过8000美元时，风险水平突然上升。

为了提供更多见解，以下是基于SHAP的预测解释，揭示了影响ChatGPT预测的因素。

通过利用机器学习并探索LLM的内部工作原理，我们开启了无限的机遇。我们可以优化模型，提高其准确性，并利用它们的力量在各个行业和领域推动智能决策的发展。

结论

我还有其他想法要探索，但我将它们保留到未来的博客文章中。总结起来，从这个分析中得出的关键要点是：

大型语言模型（LLM）可以通过有效的提示策略进行零样本预测。
机器学习和预测洞察力对于理解LLM的预测和推理过程至关重要。
利用LLM生成合成数据可以极大地加快新想法的开发和评估，消除数据可用性限制和安全/隐私问题。

这些洞察力突出了LLM在各种应用中的潜力，并强调了利用机器学习技术进行预测分析的重要性。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Llm
Datarobot
Machine Learning
Trust
Written by Ray Mi
35 Followers

RVP of DataScience Practice, DataRobot

Follow
More from Ray Mi

Ray Mi

From Innovation to Implementation: Best Practices for Monitoring Generative AI in Business
Introduction
4 min read
·
Aug 11, 2023

11

Ray Mi

Unveiling the Mechanics of Zero-Shot Predictions: Harnessing Machine Learning Models to Understand…
Introduction
8 min read
·
May 30, 2023

7

Ray Mi

Future of Generative AI: A Frontline Practitioner’s Take on Adoption Trends
Introduction
8 min read
·
Jun 5, 2023

28

Ray Mi

Demystify Large Language Model and Generative AI (Part 2) : From GPT to ChatGPT, a Data Science…
Introduction
9 min read
·
Jun 14, 2023

35

See all from Ray Mi
Recommended from Medium

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.2K

37

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Lists
Predictive Modeling w/ Python
20 stories
·
956 saves
Practical Guides to Machine Learning
10 stories
·
1129 saves
Natural Language Processing
1244 stories
·
725 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
320 saves

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:37.603 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 可执行代码生成".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

ERROR
410
This account is under investigation or was found in violation of the Medium Rules.
There are thousands of stories to read on Medium. Visit our homepage
to find one that’s right for you.
Take me to Medium

2024-03-02 15:13:38.502 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.036 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 241, completion_tokens: 3
2024-03-02 15:13:38.507 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 可执行代码生成".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

基于大语言模型的自主智能体实现调研
A Survey on Large Language Model based Autonomous Agents论文阅读笔记

Harry同学

·

Follow

25 min read
·
Sep 2, 2023

--

框架的整体结构如下图所示，包括一个档案模块、一个记忆模块、一个规划模块和一个行动模块。分析模块的目标是确定代理角色。记忆和规划模块将代理置入动态环境中,使其能够回顾过去行为并计划未来行动. 行动模块负责将代理决策转化为特定输出. 在这些模组内部, 分析单元影响着记忆与规划单元，并且共同影响着行动单元.

构造基于LLM自主智能体

我们期望基于LLM的自主代理能够有效地完成不同的任务，这是基于LLM具有类似人类的能力。为了实现这个目标，有两个重要方面，即（1）应设计哪种架构以更好地使用LLM和（2）如何学习架构的参数。在架构设计的背景下，我们对现有研究进行了系统性综合，最终形成一个全面统一的框架。至于第二个方面，我们总结了三种常用策略包括：（1）从示例中学习，在精选数据集上微调模型；（2）从环境反馈中学习，利用实时交互和观察；以及（3）从人类反馈中学习, 利用人类专业知识和干预进行改进。

代理架构设计

近期在语言模型（LLMs）方面的进步已经展示了它们完成各种任务的潜力。然而，仅依赖于LLMs，由于其架构限制，很难有效地实现一个自主代理。为了弥补这个差距，以前的工作开发了一些模块来启发和增强LLMs用于建立自主代理的能力。在本节中，我们提出一个统一框架来总结之前工作中提出的架构。具体来说，我们框架的整体结构如图2所示，包括一个分析模块、一个记忆模块、一个规划模块和一个行动模块。分析模块的目标是确定代理角色。记忆和规划模块将代理置入动态环境中,使其能够回顾过去行为并计划未来行动. 行动模块负责将代理决策转化为特定输出. 在这些组件内部, 分析组件影响记忆与规划组件，并且集合起来, 这三个组件影响着行动组件.

档案模块

自主代理通常通过扮演特定角色来执行任务，例如编码员、教师和领域专家。配置模块的目标是指示代理的角色配置，这些通常会写入提示以影响LLM的行为。在现有的工作中，生成代理配置有三种常用策略。

手工设定
根据种子档案使用 LLM 生成
代理人是根据现实世界调查数据集中参与者的人口背景进行初始化的。数据集对齐方法能够准确捕获真实群体的属性，有效地弥合虚拟世界和现实世界之间的差距。

除了制定个人资料生成策略外，另一个重要的问题是如何确定用于描述代理人的信息。这些信息包括人口统计信息（例如年龄、性别和收入等），这些都能揭示出一群体的特征；心理学信息，它表明了代理人的个性；以及社会关系信息，它描述了代理之间的关系。

记忆模块

AI代理中的短期记忆相当于Transformer架构约束下支持学习能力的环境窗口。长期记忆类似于代理可以根据需要迅速查询和检索的外部向量存储。

记忆结构

统一内存：在这种结构中，内存被组织成一个单一的框架，没有区分短期和长期记忆的差异。该框架为读取、写入和反映内存提供了统一的接口。
混合内存：清晰地区分了短期和长期功能。短期组件临时缓冲最近的感知，而长期记忆则随着时间的推移巩固重要信息。

记忆格式
信息可以以各种格式存储在内存中，每种格式都有其独特的优点。例如，自然语言能够保留全面的语义信息，而嵌入式则可以提高读取内存的效率。以下我们将介绍四种常用的记忆格式。

自然语言：使用自然语言进行任务推理/编程可以实现灵活、富含语义的存储/访问。
嵌入式：使用嵌入式来保存信息可以增强内存检索和阅读效率。
数据库：外部数据库提供了结构化的存储方式, 可以通过有效且全面操作操纵这些记忆.

记忆操作
有三个关键的内存操作，包括读取、写入和自我反思。

记忆读取：关键在于从记忆中提取信息。通常，我们有三个常用的信息提取标准，即近期性、相关性和重要性。更近期、更相关、更重要的记忆更可能被提取出来。
记忆写入：代理人可以通过在他们的记忆中存储重要信息来获取知识和经验。在写作过程中，有两个潜在问题需要仔细解决。一方面，关键是如何存储与现有记忆相似的信息（记忆复制）。另一方面，当内存达到其存储限制时考虑如何删除信息也很重要（记忆溢出）。
记忆反思：这个操作旨在赋予代理人能力，使他们能够浓缩和推导出更高级的信息，或者自主验证和纠正自己的行为。它帮助代理人理解自己和他人的属性、偏好、目标和联系，从而指导他们的行为。以前的研究已经研究了各种形式的记忆反思，即(1) 自我总结。2) 自我验证。另一种形式的反思涉及评估代理行动效果如何. (3) 自我修正。这种类型反射下，代理可通过环境回馈纠正其行为方式(4) 同情心增强 记忆倒影也可加强智能体同情心功能
规划模块

当人类面临复杂任务时，他们首先将其分解为简单的子任务，然后逐一解决每个子任务。规划模块赋予基于LLM的代理具有思考和计划解决复杂任务的能力，这使得代理更加全面、强大和可靠。

无反馈规划

子目标分解：一些研究者打算让大型语言模型（LLMs）逐步思考以解决复杂任务。思维链条（CoT）已成为允许大型模型解决复杂任务的标准技术。
多路径思维：基于CoT的研究表明，人类的思考和推理过程是一种树状结构，有多条路径可以得出最终结果。
外部规划器：尽管LLMs具有显著的零样本规划能力，但在许多情况下，它们并不如传统的规划器可靠，特别是面对领域特定的长期规划问题时。

有反馈规划
当人类处理任务时，成功或失败的经验会引导他们反思自我并提高他们的规划能力。这些经验通常是基于外部反馈获得和积累的。为了模拟这种人类的能力，许多研究者设计了可以从环境、人类和模型中接收反馈的规划模块，显著提高了代理商的规划能力。

环境反馈：在许多研究中，代理人根据环境反馈制定计划。例如，ReAct 将代理人的行动空间扩展到一系列行动和语言空间。明确的推理和行动是顺序进行的，当一个行动的反馈没有正确答案时，将再次进行推理直至得出正确答案。
人类反馈：代理可以在真实人类反馈的帮助下制定计划。这种信号可以帮助代理更好地适应实际环境，也可能缓解幻觉问题。
模型反馈：语言模型可以作为批评家，对生成的计划进行批评和改进。引入了自我完善机制，通过迭代反馈和改进来提高LLM的输出效果。具体来说，LLM被用作生成器、反馈提供者和精炼者。首先，生成器用于产生初步输出，然后反馈提供者为这个输出提供具体且可行的反馈，最后精炼者利用这些反馈来改进输出结果。通过在生成器和评论家之间建立一个迭代的反馈循环，从而增强了LLM的推理能力。

总的来说，规划模块对于代理人解决复杂任务至关重要。虽然外部反馈总是可以帮助做出明智的计划，但并非总是存在。有反馈和无反馈的规划都对构建基于LLM的代理人非常重要。

行动模块

动作模块的目标是将代理人的决策转化为具体结果。它直接与环境互动，决定了代理人完成任务的效率。

行动目标
行动目标指的是行动的目标，通常由真实的人类或代理自身来确定。三个主要的行动目标包括任务完成、对话交互以及环境探索和交互。

任务完成：行动模块的基本目标是以逻辑方式完成特定任务。不同场景下的任务类型各异，这导致了行动模块必须进行设计。
对话交互：基于LLM的自主代理人进行与人类的自然语言对话的能力是至关重要的，因为人类用户通常需要获取代理状态或完成与代理的协作任务。
环境探索与互动：代理人能够通过与环境的互动来获取新知识，并通过总结近期经验来提升自身。这样，代理人可以生成越来越适应环境和符合常识的新行为。

行动策略
行动策略指的是代理人产生行动的方法。在现有的工作中，这些策略可能包括记忆回顾、多轮互动、反馈调整以及结合外部工具。

记忆回溯：记忆回溯技术帮助代理人根据存储在内存模块中的经验做出明智的决策。生成性代理人维护一个对话和经验的记忆流。在采取行动时，相关的记忆片段被作为条件输入提供给LLMs，以确保行动的一致性。
多轮交互：这种方法试图利用跨多轮的对话上下文，使代理人能够确定适当的响应作为行动。
反馈调整：人类反馈或与外部环境的互动在帮助代理适应并增强其行动策略方面已经显示出了有效性。
整合外部工具：基于LLM的自主代理可以通过整合外部工具和扩展知识源进行增强。一方面，这些代理可以被赋予在训练或推断阶段访问和使用各种API、数据库、网络应用程序以及其他外部资源的能力。

行动空间
基于LLM的代理人的行动空间指的是代理人可以执行的可能行动集合。这主要源自两个方面：扩展行动能力的外部工具，以及代理人自身如语言生成和基于记忆的决策制定等知识和技能。

工具：各种外部工具或知识源为代理提供了更丰富的行动能力，包括API、知识库、视觉模型、语言模型等。(1) API。利用外部API来补充和扩展行动空间是近年来流行的范式。(2) 知识库连接至外部知识库可帮助代理获得特定领域信息以产生更真实操作。(3) 语言模型也可作为丰富操作空间来使用。
代理人的自我知识：代理人自我获取的知识也提供了多样化的行为，例如利用LLM的生成能力进行规划和语言产生，基于记忆做出决策等。代理人自我获取的知识如记忆、经验和语言能力使得无需工具就可以实现多种行动。

行动影响
行动影响指的是一个行动的后果，这包括环境的变化、代理人内部状态的改变、新行动的触发以及对人类感知的影响。

改变环境：行动可以直接改变环境状态，例如移动代理位置、收集物品、建造建筑等。
改变内部状态：代理人采取的行动也可以改变代理人自身，包括更新记忆、形成新的计划、获取新知识等等。
触发新的行动：对于大多数基于LLM的自主代理，行动通常以顺序方式进行，也就是说，前一个行动可以触发下一个新的行动。
影响人类的感知：行为中的语言、图像和其他方式直接影响用户的感知和体验。

学习策略
学习是人类获取知识和技能的重要机制，有助于提升他们的能力 — — 这一点在LLM（语言模型）代理领域中具有深远意义。通过学习过程，这些代理获得了更高级别遵循指令、熟练处理复杂任务以及无缝适应前所未有和多样化环境的能力。这种转变过程使这些代理超越了初始编程，使他们能够以更大的精细度执行任务。

从实例中学习
以实例学习是支撑人类和AI学习的基础过程。在LLM（语言模型）为基础的代理领域，这一原则体现在微调中，通过接触真实世界数据，这些代理能够提升他们的技能。

从人类标注中学习：在追求与人类价值观和谐相处的过程中，整合由人生成的反馈数据成为微调LLMs（大型语言模型）的基石。这种做法在塑造旨在补充甚至替代人类参与特定任务的智能代理方面尤其关键。
从LLMs的标注中学习：在预训练过程中，LLMs通过大量的训练数据获取了丰富的世界知识。经过微调和与人类对齐后，它们展现出类似于人类判断力的能力，如ChatGPT和GPT-4等模型所示。因此，我们可以利用LLMs进行注释任务，这比人工注释可以显著降低成本，并提供广泛数据采集的可能性。

从环境反馈中学习
在许多情况下，智能代理需要主动探索周围环境并与之互动。因此，他们需要具备适应环境和通过环境反馈提升自身能力的能力。在强化学习领域，代理通过不断探索环境并根据环境反馈进行调整来学习[68, 82, 98, 152]。这一原则也适用于基于LLM的智能代理。

从互动人类反馈中学习
互动的人类反馈为代理提供了在人类指导下以动态方式适应、演变和精炼其行为的机会。与一次性反馈相比，交互式反馈更符合现实世界的情况。由于代理是在一个动态过程中学习的，他们不仅处理静态数据，还参与到对自己理解、适应和与人类对齐的持续改进中来。

基于LLM的自助智能体应用

LLM（语言模型）基础的自主代理在各个领域的应用，标志着我们解决问题、做决策和创新方式的范式转变。这些代理具备了语言理解、推理和适应等能力，通过提供前所未有的洞察、帮助和解决方案，正在革新行业和学科。

社会科学

计算社会科学涉及开发和应用计算方法来分析复杂的人类行为数据，通常是大规模的，包括来自模拟场景的数据。最近，LLMs展示出了令人印象深刻的类人能力，这对于社会计算科学研究充满希望。

心理学：LLM（语言模型）基础的代理可以用于进行心理实验。利用LLM基础的代理来模拟包括最后通牒游戏、花园路径句子、米尔格拉姆电击实验和群体智能容量等心理实验。在前三个实验中，LLM基础的代理可以复现当前的心理发现，而最后一个实验揭示了一些语言模型（包括ChatGPT和GPT-4）中存在”超准确性扭曲”，这可能会影响下游应用。在[3]中，作者使用LLM基础的代理来模拟博弈论领域两种原型重复游戏：囚犯困境和性别之争。他们发现LLM基础的代理显示出优先考虑自身利益而非协调合作的心里倾向。
政治科学与经济学：最近的研究已在政治科学和经济学领域使用基于LLM的代理人。这些代理人被用来分析党派印象，探索政治行动者如何修改议程等应用。此外，基于LLM的代理人可以用于意识形态检测和预测投票模式。更进一步，最近的研究努力已专注于通过利用基于LLM的代理人来了解政治演讲中的话语结构和说服元素。在霍顿等人进行的研究中，为基于LLM的代理人提供了特定特征，如才能、偏好和个性。这使得研究者能够在模拟场景中探索经济行为，并对经济学领域获得新颖见解。
社会模拟：对人类社会进行实验通常代价高昂，违反伦理道德，甚至无法实现。相比之下，基于代理的模拟使研究者能够在特定规则下构建假设场景来模拟一系列社会现象，例如有害信息的传播。研究者既观察又干预系统的宏观和微观层面，这使他们能够研究反事实事件。
法学：基于LLM的代理可以作为法律决策过程中的辅助工具，帮助法官做出更有根据的判断。《盲审》采用了多种语言模型来模拟多个法官的决策过程。它收集各种不同的意见，并通过投票机制整合结果。ChatLaw是一款知名的中国法律精调LLM。为解决模型幻觉问题，ChatLaw结合了数据库搜索和关键词搜索技术以提高准确性。同时，还采用了自我注意力机制来增强LLM在缓解参考数据不准确影响方面的能力。
社会科学研究助理：除了在社会计算的特定领域进行专门研究外，基于LLM的代理可以扮演研究助理的角色。他们有潜力帮助研究人员完成如生成文章摘要、提取关键词和生成脚本等任务。此外，基于LLM的代理还可以作为写作辅助工具，并且甚至具备识别社会科学家新颖研究问题的能力。
自然科学

由于大型语言模型的快速发展，LLM基础代理在自然科学领域的应用正在增加。这些代理为自然科学研究带来了新的机会。以下，我们将介绍许多代表性领域，在这些领域中，LLM基础代理可以发挥重要作用。

文档和数据管理：在自然科学研究领域，大量的文献和数据往往需要精细的收集、组织和提取，这涉及到大量的时间和人力资源。基于LLM的代理具有强大的自然语言处理能力，使它们能够有效地使用各种工具浏览互联网、文件、数据库以及其他信息源。这一能力使他们可以获取海量数据，并无缝整合并管理之，从而为科学研究提供了宝贵帮助。通过利用API访问互联网，代理可以高效查询并检索实时相关信息，协助完成诸如问题回答和实验计划等任务。
自然科学实验助手：基于LLM的代理可以独立运行，自主进行实验，同时也是支持科学家在他们的研究项目中的宝贵工具。例如，介绍了一个创新的代理系统，该系统利用LLM来自动化科学实验的设计、规划和执行。当提供了实验目标作为输入时，该系统会访问互联网并检索相关文档以获取必要信息。随后，它使用Python代码进行必要计算，并最终执行实验的顺序步骤。
自然科学教育：得益于自然语言处理能力，LLMs通过自然语言交互与人类进行无缝沟通，使它们成为提供实时问答和知识传播的令人兴奋的教育工具。代理系统作为有价值的教育工具，帮助学生和研究者学习实验设计、方法论和分析。他们帮助培养批判性思维和解决问题的技巧，同时鼓励对科学原理有更深入的理解。
工程学

基于LLM的自主代理已经在协助和增强工程研究和应用中展现出巨大的潜力。

土木工程：在土木工程中，可以使用基于LLM的代理来设计和优化复杂结构，如建筑物、桥梁、大坝、道路等。[99]提出了一个交互式框架，在这个框架中，人类建筑师和AI代理可以协作在3D模拟环境中构造结构。交互式代理能够理解自然语言指令，放置方块，检测混乱情况，寻求澄清，并吸收人类反馈，显示出人机合作在工程设计中的潜力。
计算机科学与软件工程：在计算机科学和软件工程领域，基于LLM的代理提供了自动化编码、测试、调试和文档生成的可能性[115, 113, 58, 29, 33, 44, 41]。ChatDev [113] 提出了一个端到端的框架，在这个框架中，多个代理角色通过自然语言对话进行交流和协作，以完成软件开发生命周期。该框架展示了高效且成本有效地生成可执行软件系统。ToolBench 可用于代码自动补全和代码推荐等任务。
航空航天工程：在航空航天工程中，早期的研究探索使用基于LLM的代理来建模物理学，解决复杂的微分方程，并优化设计。[107] 在解决与气动力学、飞机设计、轨迹优化等相关问题上显示出了有希望的结果。随着进一步发展，基于LLM的代理可能会创新地设计宇宙飞船，模拟流体流动，进行结构分析，甚至通过生成可与工程系统集成的可执行代码来控制自主车辆。
工业自动化：在工业自动化领域，基于LLM的代理可以用来实现生产过程的智能规划和控制。提出了一个新颖的框架，该框架将大型语言模型（LLMs）与数字孪生系统集成，以适应灵活的生产需求。该框架利用提示工程技术创建可以根据数字孪生提供的信息适应特定任务的LLM代理。这些代理可以协调一系列原子功能和技能，在自动化金字塔内完成不同级别的生产任务。这项研究展示了将LLMs整合到工业自动化系统中的潜力，为更敏捷、灵活和可适应性强的生产过程提供了创新解决方案。
机器人技术与具象化人工智能：近期的研究已经为机器人和具象化人工智能开发了更高效的强化学习代理。重点在于提升自主代理在具象环境中进行规划、推理和合作的能力。一些方法如[25]将互补优势结合到统一系统中，用于具象推理和任务规划。高级命令可以改善规划，而低级控制器则将命令转换为行动。
通用自主AI代理：基于LLM开发的一些开源项目已经对人工通用智能（AGI）进行了初步探索，他们致力于自主通用AI代理框架的研究和开发。这使得开发者可以快速且可靠地构建、管理并运行有用的自主代理。
基于LLM的自主代理评估

本节介绍了评估基于LLM的自主代理有效性的方法。与LLM本身类似，AI代理的评估并非易事。在这里，我们提出了两种常用的评估AI代理的策略：主观和客观评价。

主观评估

基于LLM的代理在许多领域都有广泛的应用。然而，在很多情况下，缺乏通用的指标来评估代理的性能。一些潜在属性，如代理的智能和用户友好性，也不能通过定量指标进行衡量。因此，主观评估对当前研究至关重要。

主观评估是指通过各种方式如交互、打分等由人类测试基于LLM的代理的能力。在这种情况下，参与测试者通常通过众包平台招募；而一些研究人员认为由于个体差异导致众包人员不稳定，并使用专家注释进行测试。

人工标注：在一些研究中，人类评估者会根据一些特定的视角直接对基于LLM（大型语言模型）的代理生成结果进行排名或打分；另一种评估类型是以用户为中心的，它要求人类评估者回应基于LLM的代理系统是否对他们有帮助，以及它是否用户友好等。具体来说，一个可能的评价可以是社交模拟系统能否有效地促进在线社区规则设计的提升。
图灵测试：在这种方法中，人类评估者总是被要求区分代理行为和人类行为。在生成性代理中，第一批人类评估者通过面试来评估代理的五个关键能力领域。经过两天的游戏时间后，另一批人类评估者将被要求在相同条件下区分代理和人类的反应。在自由形式党派文本实验中，人类评估者被要求猜测响应是来自于人还是基于LLM的代理。
客观评估

客观评价是指使用可以计算、比较和随时间追踪的定量指标来评估基于LLM（语言模型）的自主代理人的能力。与主观或人类评价相反，目标指标旨在提供关于代理表现的具体、可测量洞察力。

指标：为了客观评估代理的有效性，设计适当的指标是非常重要的，这可能会影响到评估的准确性和全面性。理想的评估指标应该能够精确地反映出代理的质量，并且与人们在现实场景中使用它们时的感受相一致。在现有工作中，我们可以看到以下具有代表性的评估指标。(1) 任务成功度量：这些度量衡量一个代理完成任务和达成目标的能力如何。常见度量包括成功率、奖励/得分、覆盖率以及准确率。数值越高表示任务完成能力越强。(2) 人类相似度指标：这些指标量化了代理行为与人类行为的相似程度。典型的例子包括轨迹/位置精确性，对话相似性，以及模仿人类反应。更高的相似性表明更像人类的推理。(3) 效率指标：与前述用于评价代理有效性的指标不同，这些指标从各种角度评估代理效率。典型的指标包括规划长度，开发成本，推断速度和澄清对话数量。
策略：基于评估所采用的方法，我们可以识别出几种常见的策略：（1）环境模拟：在这种方法中，代理人在沉浸式3D环境如游戏和互动小说中进行评估，使用任务成功和人类相似性等指标，包含轨迹、语言使用和完成目标等因素。这展示了代理人在现实世界场景中的实际能力。（2）孤立推理：在此方法中，研究者通过采用有限任务如精度、段落完成率和消融度量来专注于基本认知能力。这种方式简化了对个体技能的分析。（3）社会评价：直接利用人类研究和模仿度量探查社会智慧。这评估了高阶社会认知。（4）多任务：使用来自不同领域的各种任务套件进行零/少射击评价。这衡量了泛化性。（5）软件测试: 探索将LLMs应用于各种软件测试任务上面例如生成测试案例复制错误调试代码以及与开发者外部工具交互他们使用像是测试覆盖范围错误检测率代码质量以及推理能力之类的指标去衡量基于LLM 的代理效果。
基准测试：除了指标之外，客观评估还依赖于基准测试、受控实验和统计显著性检测。许多论文使用任务和环境的数据集构建基准来系统地测试代理。Clembench是一种用于评估聊天优化语言模型作为对话代理的游戏化方法，它探索了通过将他们暴露在设计出来挑战特定能力的限制性、类游戏设置中有意义地评估LLM（大型语言模型）的可能性。Tachikuma是一个利用TRPG游戏日志来评价LLMs理解并推断复杂交互以及与多个角色和新颖物体相互作用能力的基准。AgentBench提供了一个全面框架，用于在各种环境中评估LLMs作为自主代理，并采取F1作为主要度量标准进行标准化基准测试LLM代理。这是首次系统地对预训练LLMs在不同领域真实世界挑战上表现如何进行评估。SocKET是一个全面的基础设施，旨在跨越58项任务（涵盖五类社会信息如幽默和讽刺、情感和感觉、信誉等）来评价大型语言模型(LLMs) 的社会知识能力。AgentSims是一种灵活的设施，可构建大规模语言模型(LLMs) 的测试沙箱，并促进数据生成和社会科学研究中多样化的评价任务和应用程序.ToolBench是一个开源项目，旨在通过提供一个开放平台进行训练、服务以及工具学习方面 LLMs 的效果测算从而帮助构建强大且具备通用工具使用能力的大规模语言模型 (LLMs) 。Dialop设计了三项任务：优化、规划以及调停 ，以此衡量 基于 LLM 的代理决策能力.WebShop基础设施则针对产品搜索并从118万件真实商品集合中检索产品这两项功能 对 LLM 代理 进行效果测算 ，其奖励机制则根据属性重叠率与回忆表现给出.Mobile-Env则是一款易扩展交互平台 , 它为衡量 LLM-based agents 在与信息用户界面(InfoUI ) 进行多步骤交互方面所展示出来得技巧 提供了良好得支持 . WebArena已经创建了包含常见领域得全方位网站环境.该环境充当着衡量agent端到端方式下完成任务时功能正确性得平台.GentBench则被设计成可以衡量 agent 包括推理 , 安全 , 效率等各种技巧得benchmark . 此外 , 它也支持对agents运用工具处理复杂问题时所显示出来得技术水平进行考核.
挑战

虽然基于LLM的自主AI代理人的先前工作已经展示了许多有希望的方向，但这个领域仍处于初始阶段，并且在其发展道路上存在许多挑战。以下，我们将介绍几个重要的挑战。

角色扮演能力

与传统的LLM不同，AI代理通常需要扮演特定的角色（例如，程序编码员、研究员和化学家）来完成不同的任务。因此，代理人的角色扮演能力非常重要。虽然对于许多常见的角色（如电影评论家），LLM可以很好地模拟他们，但仍有许多角色和方面是LLM难以捕捉到的。首先，LLM通常基于网络语料库进行训练，因此对于在网上鲜少被讨论或新兴出现的角色，LLM可能无法很好地模拟它们。另外, 之前研究已经表明现有的LLMs可能无法很好地模拟人类认知心理特性，在对话场景中缺乏自我意识。解决这些问题可能需要微调 LLM 或者精心设计代理提示/架构。例如, 可以首先收集一些罕见职业或心理特质真实数据，并利用它来微调 LLMs. 然而, 如何确保微调后模型依然在普遍职业上表现良好也会带来进一步挑战. 除了微调外, 还可以设计专门针对 LLMS 角色扮演能力增强其功能性 的代理提示/架构. 然而找到最优秀提示/架构并不容易, 因为他们设计空间太大.

广义的人类价值观对齐

传统LLM中的人类价值观对齐问题已经被广泛讨论。在自主AI代理领域，特别是当这些代理用于模拟时，我们认为应该更深入地探讨这个概念。为了更好地服务于人类，传统的LLM通常会进行微调以与正确的人类价值观保持一致，例如，代理不应计划制造炸弹来报复社会。然而，在利用这些代理进行真实世界模拟时，一个理想的模拟器应能诚实地描绘出各种各样包含错误价值观在内的人性特质。事实上, 模拟人性中消极方面可能更重要, 因为模拟目标之一就是发现并解决问题, 而没有消极方面就意味着没有需要解决的问题。例如，在模拟真实世界社会时，我们可能需要允许代理计划制造炸弹，并观察它如何行动以执行该计划以及其行为产生的影响。基于这些观察结果, 人们可以采取更有效果阻止现实社会中相似行为发生。受以上案例启示, 也许基于代理系统仿真最重要问题之一就是如何进行广义化的人类价值观对齐 — — 即针对不同目标和应用场景下, 使得AI能够能夠對應多元化、多变化、甚至有時候带有負面色彩或者錯誤價值取向等多種情境下進行對齐操作. 然而当前存在力量强大但仅与单一类型（正向） 的 LLMs 如ChatGPT 和 GPT-4 进行了“对齐”。因此，“重新定位”这些模型通过设计合适数字提示策略成了一个有趣且具挑战性方向。

提示的稳健性

为了确保代理人的合理行为，设计者通常会在LLMs中加入额外的模块，如记忆和规划模块。然而，这些模块的引入需要开发更多的提示以便于一致性操作和有效沟通。先前的研究已经强调了LLMs中提示缺乏稳健性，即使是微小变动也可能产生大幅度不同结果。当构建自主代理人时，这个问题就显得更加突出，因为他们并非只包含一个单一提示，而是考虑所有模块的一个提示框架，在其中一个模块对其他模块有潜在影响力。此外，不同LLMs之间的提示框架可以有很大差异。开发一个统一且稳健、能够应用到各种LLMs上面去的提示框架是个重要但尚未解决问题。针对上述问题有两种可能解决方案：（1）通过试错法手工制作必要元素；或者（2）使用GPT自动生成。

幻觉现象

幻觉现象对于大型语言模型（LLMs）来说是一个根本性的挑战，其中模型错误地自信地输出虚假信息。这个问题在自主代理中也很普遍。例如，在中，人们发现当面对简单指令进行代码生成任务时，代理可能会表现出幻觉行为。幻觉可以导致严重的后果，如错误或误导的代码、安全风险和道德问题。要解决这个问题，一种可能的方法是将人类纠正反馈融入到人-代理交互环节中。

知识边界

自主AI代理的一个重要应用是模拟不同的现实世界人类行为。人类模拟研究有着悠久的历史，最近对此兴趣的激增可以归因于LLMs（大型语言模型）所取得的显著进步，这些进步在模拟人类行为方面展示了显著能力。然而，我们必须认识到LLMs的强大可能并非总是有利的。具体来说，理想情况下，仿真应准确复制人类知识。在这方面，由于LLMs接受了超出普通个体范围之外广泛网络知识库上训练, 它们可能表现出过度强大。 LLMs 的巨大能力可以极大地影响仿真效果。例如，在尝试模拟用户选择各种电影时, 确保 LLMS 假设没有关于这些电影先前知识至关重要. 但是, LLMs 可能已经获取了关于这些电影信息. 如果没有实施适当策略, 即使现实世界中用户无法预先获取到这些电影内容, LLMs也可能根据其广泛知识做出决定. 根据以上例子, 我们可以得出结论: 在构建可信赖代理仿真环境时, 如何限制使用用户未知 LLMS 知识成为一个重要问题.

效率

由于其自回归架构，LLMs通常具有较慢的推理速度。然而，代理可能需要多次查询LLMs以执行每个动作，例如从内存模块中提取信息、在采取行动之前进行规划等等。因此，代理行动的效率大大受到LLM推理速度的影响。使用相同API密钥部署多个代理可以进一步显著增加时间成本。

参考文献
https://arxiv.org/abs/2308.11432
https://github.com/Paitesanshi/LLM-Agent-Survey
Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month

--

Written by Harry同学
60 Followers

nothing

Follow

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:38.512 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 程序错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

如何利用AI学习区块链知识
ChatGPT x Kapa.ai ⇒ 开发者的福音

Moonbeam小萌妹

·

Follow

Published in

Moonbeam 中文

·
May 24, 2023

由OpenAI推出的人工智能聊天机器人ChatGPT在各大平台掀起了一阵狂热之风。发布仅四个月的时间，获得超一亿用户，成长速度远高于现今网络应用巨头脸书和Amazon。随着最新版本GPT-4的正式上线，其AI性能和完善程度再度提升，深受用户和开发者的青睐。

GPT-4是一种基于文本的人工智能，接受过互联网上大量数据的训练，可以在学习智能合约的编写和代码错误的识别方面提供帮助。ChatGPT的出现为开发者提供了便利性，使其操作变得更加轻松简单。

ChatGPT语言模型包含context-aware模块，能够对应上下文内容。因此即使它没有产生正确的答案，您也可以通过引导它来找到满足您需求的最佳解决方案。

如何使用ChatGPT

在本教程中，Moonbeam将使用ChatGPT来编写和调试智能合约。请注意，本教程仅供参考。Moonbeam不保证项目信息的准确性、真实性和完整性。请大家提前做好研究。

开始操作之前需要先注意以下三点：

ChatGPT的训练数据只包括2021年9月及以前的信息（即回答内容不能包含该时间点以后的事件信息）
回复限制在500字以内
GPT-4的内容虽然合理，但不能保证100%的准确性

📺 观看完整的操作教程

本视频介绍了ERC-20 Token创建、Hardhat部署说明、测试场景，以及如何利用GPT-4处理已知的错误合约。请注意：本教程所使用的ChatGPT为GPT-4最新版本。该版本相较其他版本具有更先进的智能模型，但需要支付$20的月费。当然，您也可以使用GPT-3.5的免费版本进行测试。

首先，前往https://chat.openai.com/，登陆/注册账号。

进入页面后，根据个人需求输入关键词/句子，随后ChatGPT将根据关键词进行回复。以下为4个操作案例：

ERC-20 Token创建

Hardhat部署说明

处理错误合约

测试场景

ChatGPT回复中的代码可直接进行完整复制。但请注意，目前ChatGPT仅作演示目的，请勿将其用于实际环境。

如何使用Kapa.ai

ChatGPT基本上可以解决大多数在编写和调试智能合约所遇到的问题，由于ChatGPT所使用的训练资料为2021年9月以前的数据，而Moonbeam自2022年1月正式上线后，网络也在不断迭代更新。因此，Moonbeam团队利用ChatGPT的模型使用Moonbeam开发者文档、Moonbeam开发论坛和Substrate开发者文档网站进行训练，并将其命名为Kapa.ai。

Kapa.ai结合了技术知识来源的语义检索系统，并由包括GPT-4在内的大型语言模型提供支持。Kapa.ai同时支持英文和中文等主流语言，还可以回答关于在Moonbeam或是波卡上开发的相关特定问题。

前往Moonbeam的Discord，在DEV-HUBS频道的ask-kapa-ai中即可使用Kapa.ai协助开发！详细操作步骤请查看此文章。

Kapa.ai经过Moonbeam在Discord上的培训后，目前也支持直接访问Moonbeam官方文档网站！前往Moonbeam文档网站，点击页面右下角“Ask AI”按钮，输入问题/关键词即可。

ChatGPT与Kapa.ai的结合，对于喜欢构建的开发者来说是个福音，也是顺手的工具。开发者无需花费大量时间重新检索和研究相关资料，可以利用AI来协助加速开发进程，在提升效率的同时还能弥补缺漏，一举多得！

关于Moonbeam

Moonbeam是一个智能合约平台，用于构建跨链互连应用程序，能够访问任何链上的用户、资产和服务。通过将来自以太坊、Cosmos、波卡等功能整合到一个平台中，Moonbeam解决了当今用户体验碎片化的问题，解锁了真正的互操作性，并为下一代应用程序奠定基础。Moonbeam平台使用集成的跨链信息传递，允许开发者创建访问多个远程区块链服务的智能合约。通过此方式结合Moonbeam的开发者友好型EVM平台、各类工具支持和Substrate架构，为构建互连应用程序提供理想化的开发环境。

官网｜英文Twitter｜中文Twitter｜英文电报群｜中文电报群｜中文电报Channel｜Discord

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Moonbeam
科普文章
操作教程
Written by Moonbeam小萌妹
61 Followers
·
Editor for 

Moonbeam 中文

Follow
More from Moonbeam小萌妹 and Moonbeam 中文

Moonbeam小萌妹

in

Moonbeam 中文

为何波卡被称为Layer 0？
理解区块链的技术本质，将揭示加密货币运行轨迹的神秘面纱。了解这背后的原理，将为你带来全新的视角，让你对加密货币的奇妙世界充满无尽的好奇。本文将通过波卡带你了解区块链最本质的技术概念，以及区块链技术对加密世界的重要性。
11 min read
·
Jun 9, 2023

Moonbeam小月光

in

Moonbeam 中文

除了Polkadot.js，波卡还有哪些原生的钱包
波卡生态钱包项目简要介绍
7 min read
·
Jan 19, 2023

Moonbeam小月光

in

Moonbeam 中文

你的DOT即将解锁，请注意以下事项
近期，社区小伙伴的问题层出不穷，围绕着如何获取质押的DOT，领取剩余的插槽质押奖励，或是DOT的新去处等等。 这篇文章将回答社区感兴趣的问题。
6 min read
·
Oct 18, 2023

Moonbeam小萌妹

in

Moonbeam 中文

Web2与Web3开发的不同之处
Web2是引入交互功能的第二代互联网，也是我们今天所熟悉的。随着Web的不断发展，第三代互联网，也被称为Web3，正处于积极开发中。但是Web2和Web3开发之间有什么区别呢？让我们来阅读本文深入了解。
16 min read
·
May 2, 2023
See all from Moonbeam小萌妹
See all from Moonbeam 中文
Recommended from Medium

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

Lists
Staff Picks
593 stories
·
788 saves
Stories to Help You Level-Up at Work
19 stories
·
501 saves
Self-Improvement 101
20 stories
·
1420 saves
Productivity 101
20 stories
·
1307 saves

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Gowtham Oleti

Apps I Use And Why You Should Too.
Let’s skip past the usual suspects like YouTube, WhatsApp and Instagram. I want to share with you some less familiar apps that have become…
10 min read
·
Nov 15, 2023

18.5K

324

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:44.436 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.050 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 4285, completion_tokens: 218
2024-03-02 15:13:44.438 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

大语言模型数据隐私的解决之道：全同态加密

Ingonyama 中文

·

Follow

Sep 24, 2023

--

原文链接：https://medium.com/@ingonyama/solving-llm-privacy-with-fhe-3486de6ee228

人工智能的崛起令人叹为观止。从基本算法到最先进的形式 — 大语言模型（LLM），如 ChatGPT 和 Copilot — 人工智能处于技术演进的前沿。

随着这些模型与用户互动并处理大量数据和提示，数据隐私的问题就变得非常重要。亚马逊和苹果等公司已经限制员工访问ChatGPT等公共API，以防止因人工智能交互而导致的数据泄露。此外，可以合理地预期，很快将出台法规来要求一定程度的用户隐私保护。

我们如何确保与这些模型的交互、提问和共享的数据保持隐私呢？

全同态加密 (FHE) 深度解读

在密码学领域，全同态加密是一个突破性的概念。它的魅力在于神奇的特性：它允许对加密数据进行计算，而无需先解密，实现对敏感信息的隐私推理。

借助这种特性可以确保两个重要的事情：数据在处理过程中保持安全，以及对模型的知识产权（IP）的完全保护。

隐私推理与知识产权保护

如今，”隐私 “和 “用户体验 “似乎是鱼和熊掌不可兼得。人们往往为了更好的体验，将自己的信息托管到第三方公司。我们相信，这些第三方公司可以平衡好隐私与优质的服务，而不必在隐私性更高但缺少功能的本地解决方案或牺牲隐私以获得丰富功能的服务之间做出选择。

全同态加密能够在完全保护模型知识产权的情况下实现隐私推理。通过对加密数据进行计算，它可以确保提示词完全保密，同时还能保护大语言模型的知识产权。

传统加密技术与全同态加密技术

在传统加密领域，如果对加密数据进行有意义的运算，首先需要对其进行解密。但是解密就意味着易受到攻击，哪怕是一瞬间。
相比之下，全同态加密可以直接对密文进行运算，确保敏感信息在整个运算过程中保持隐私。

全同态加密的重要性

全同态加密的重要性不仅限于理论。想象一下云计算服务，可以在不解密数据的情况下进行数据处理，或者医疗数据库可以在不获取敏感患者详细信息的情况下进行分析。全同态加密的潜在应用非常广泛且多样化，包括安全投票系统和对加密数据库进行隐私搜索等。

全同态加密的数学理论

全同态加密利用容错学习（LWE）问题，这是一种格子密码学技术，具有抗量子性。在容错学习中，利用随机噪声使数据变得不可读，除非拥有秘钥。对加密数据进行算术运算是可能的，但这通常会增加噪声水平。如果连续进行过多的运算，任何人都无法读取数据，包括持有密钥的人。

这就是部分同态加密（SHE）。要将部分同态加密转换为全同态加密，需要一种能降低噪音水平的操作。这种操作被称为 “自举”（Bootstrapping），多种全同态加密方案都采用了自举操作。在本文中，我们将重点讨论环面上的全同态加密方案(Torus FHE)，它利用数学环面的代数结构来实现 全同态加密。

环面全同态加密的优势

尽管每种全同态加密方案都有自己的优缺点，但在实际场景中，TFHE目前拥有更高效的实现。TFHE的另一个重要优势在于其可编程自举（Programmable Bootstrapping，PBS），它将通常的自举操作扩展到包括对单变量函数的计算，例如在机器学习领域中至关重要的激活函数。

TFHE 的一个劣势是要求在计算中每执行一次算术运算都要执行一次 PBS 操作，而其他方案则允许在自举操作之间批量执行一些操作。

关于全同态加密推理时间的假设与逼近

为了估计使用全同态加密进行大语言模型推理所需的时间，我们做出了一些假设：

每个令牌所需的算术操作次数大约是模型中参数数量的1–2倍。这是一个下限，因为每个令牌都使用了整个模型，我们将假设这个下限足够接近实际需求。
大语言模型中的每个算术操作都可以映射到TFHE中的一个算术操作。这基本上是两种方案中变量类型大小的说明。我们假设对于大语言模型来说，INT4变量足够，并且对于TFHE来说是可行的。
大语言模型中的每个算术操作都需要映射到全同态加密中的一个算术操作。这意味着我们不能在未加密的情况下运行模型的一部分。Zama最近的一篇博文考虑了不使用这个假设的FHE推理，其中大部分模型由用户在本地执行，没有任何加密，只有一个小部分（例如单个注意力头）在模型的公司服务器上使用全同态加密运行。我们认为，这种方法实际上并没有保护模型的知识产权，因为在这种情况下，用户可以只运行缺失的头部，并且只有轻微的精度损失，如此处所示，或者对缺失部分进行相对廉价的训练，以获得与原始模型相当的结果。
TFHE中的每个算术操作都需要进行一次PBS（可编程自举）。PBS是TFHE计算的主要瓶颈。
目前最先进的TFHE实现是FPT。这是一种FPGA实现，以每35微秒计算一次PBS。
在大语言模型中使用全同态加密的挑战

随着最新技术的进展，目前最好的全同态加密实现可以在仅需35微秒的时间内执行一次算术操作。然而，当考虑到像GPT2这样复杂的模型时，单个令牌需要进行惊人的15亿次操作。这意味着每个令牌的处理时间约为52,000秒。

为了更好地理解，对于语言模型来说，一个令牌可以表示一个字符或一个完整的单词等内容。想象一下与一个语言模型进行交互，其中响应时间需要一两个星期！这样的延迟显然对于实时通信或模型的任何实际应用都是不可行的。

这显示了在当前的全同态加密技术下，对于大规模的语言模型来说，实现实时推理仍然是一个巨大的挑战。尽管全同态加密在数据保护方面具有重要意义，但在需要高度计算密集型的任务中，其性能限制可能使其难以应用于实际场景。对于实时交互和快速响应的需求，可能需要探索其他的安全计算和隐私保护解决方案。

潜在的解决方案

为了使全同态加密应用到大语言模型中，以下是一个可能的路线图：

使用多机器实现并行处理：
从每个令牌的52,000秒开始。
通过部署10,000个并行机器，我们将时间缩短到每个令牌的5秒。请注意，大语言模型确实可以高度并行化，目前的推理通常在数千个或更多的GPU核心上并行执行。

2. 过渡到先进的硬件：

从改进后的每个令牌的5秒开始。
切换到GPU或ASIC，我们可以实现每个令牌0.1秒的处理时间。虽然GPU可以在速度上提供更直接的收益，但ASIC在速度和功耗方面都可以提供更高的收益，例如ZPU就是这样的例子。

正如图所示，使用现有的数据加速技术，通过全同态加密可以实现大语言模型的私有推理。一个大型但可行的初始投资可以支持建立足够大的数据中心来实现这一目标。然而，这种可能性仍然是微乎极微的，并且对于更大的大语言模型，如Copilot（120亿参数）或GPT3（1750亿参数），仍存在差距需要弥补。

对于Copilot来说，较小的令牌吞吐量就足够了，因为它生成的是代码输出，通常比人类语言更简洁。如果我们将吞吐量要求降低8倍，那么Copilot也能达到可行性的目标。

最后的差距可以通过组合更大规模的并行化、更好的实现以及在全同态加密中进行引导的更高效算法来弥补。在Ingonyama，我们相信算法是弥合这一差距的重要组成部分，我们的团队目前正专注于算法的研究和开发。

结束语

全同态加密的安全性和大语言模型的计算能力的结合可以重新定义人工智能交互，确保效率和隐私两者兼顾。虽然存在一些挑战，但通过持续的研究和创新，我们可以实现与AI模型（如ChatGPT）的交互既具有即时性又具有隐私性的未来。这将为用户提供更高效和安全的体验，并推动人工智能技术在各个领域的广泛应用。

关注我们的进展

Twitter: https://twitter.com/Ingo_zk

Github: https://github.com/ingonyama-zk

YouTube: https://www.youtube.com/@ingo_zk

LinkedIn: https://www.linkedin.com/company/ingonyama

加入我们：https://www.ingonyama.com/careers

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
密碼學
人工智能
大语言模型
ChatGPT
Github Copilot

--

Written by Ingonyama 中文
18 Followers
Follow

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:52.184 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.060 | Max budget: $10.000 | Current cost: $0.010, prompt_tokens: 2832, completion_tokens: 411
2024-03-02 15:13:52.186 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 程序错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

大型語言模型（LLM）對自然語言處理（NLP）的影響

AI Justka

·

Follow

Published in

AI 講講話

·
Aug 23, 2023
Photo by Freepik on Pinterest
從自然語言處理（NLP）到大型語言模型（LLM）

我們在淺談 自然語言處理（NLP, Natural Language Processing）介紹過「自然語言處理（NLP）」是什麼，它是一種橫跨計算機科學、人工智能和語言學的學科。包括多方面的方法和技術，基本有認知、理解、處理，或甚至是生成自然語言（即人類日常所使用的語言）等。

NLP 是讓電腦能夠處理和分析人類語言，將其轉換為可計算和可操作的形式，再根據目的做處理。例如：對文本和語音的分析、機器翻譯、語音識別、資訊檢索、文本摘要、情感分析和對話系統等多方面的應用。

在 NLP 中，電腦需要對語言進行斷詞（可參考：AI 斷詞大解密）、詞性標註（可參考：給聊天機器人的訓練重點提示）、句法分析和語意理解等，以便更好地處理和理解文本。

機器是不會思考的，於是科學家們就告訴機器如何識字，也就是將人類使用的語言轉化為有意義的符號和關係，機器從大量的資料和現象中找出自己的規則並且學習，這就是「機器學習」的開端。隨著「深度學習」和「神經網絡」等技術不斷地發展，讓人工智慧有了大躍進，這些擁有龐大資料和參數的語言模型，即被稱為「大型語言模型」（LLM，Large Language Model）。

大型語言模型（LLM）對自然語言處理（NLP）的影響

LLM 是基於 NLP 所發展的技術，它帶來非常重要的影響，可以應用在各種 NLP 任務中，例如：

語言生成：生成更自然流暢的語言，可應用在語音識別、機器翻譯等。
語言理解：理解文本的意義，例如在模糊語句對AI的影響中提及語言中「一詞多義」的現象，當我們利用 LLM 分析更多資料，文本理解的準確性也會越高。
語言分類：根據文本內容進行情感分析或主題分類等。
語言錯誤指正：LLM 可以自動檢測拼寫錯誤或語法錯誤等。

透過 LLＭ 的發展，研究者們不斷地嘗試使以上任務的準確度提高，也盡可能地減低訓練的時間或成本，帶給我們更多便利性。

相反地，LLM 仍然存在一些限制：

數據不足：訓練數據資料若不足，則可能影響語言模型的準確性。
過度擬合：「過度擬合（overfitting）」是指模型利用原先提供的訓練資料可進行準確的預測結果，但在加入新資料後，過度擬合的模型可能會提供不準確的預測，導致整體準確度下降。
語言結構：LLM 可能被限制在已知的語言結構或語法規則中，因此碰到新的語言形式或變化時，可能無法將它處理好。
偏見謬誤：LLM 可能會有性別、種族、地域等方面的偏見。

現今研究者們也不斷地對於 LLM 存在的瑕疵做優化，讓我們可以有更好的工具進行各種任務。同時我們也應該考量以上正面或負面的各種因素，選擇合適的模型和方法來解決各種任務。

如何因應人工智慧？

2022 年 ChatGPT 的問世引起全球轟動，雖然像 ChatGPT 一樣的生成式 AI（Generative AI）看似已經滲入我們的生活或工作，帶來正面或負面的影響，但我們必須思考的是：「AI 技術不是要取代我們，而是該如何應用 AI 增進我們的技術？」

例如：AI 雖然會幫我們寫文章，但從分析大量資料之後所堆砌而成的文字，不可能原封不動地應用到各個領域。我們可以參考 AI 給我們的答案，幫助我們增加工作效率，進一步提升我們人類的生產技術及品質。

同時 ，AI 所生成的文字或圖片的智慧財產權應歸屬於誰？或是更嚴重的侵權、歧視或侵害隱私所造成的問題，例如：深偽技術（Deepfake）（可參考：眼見不為憑 — — AI 做出的虛擬人像），AI 所涉及的社會、法律及倫理等各方面的問題，勢必是我們未來必須持續關注並思考的問題。

AI 講講話｜人工智慧 AI 系列文目錄
淺談 人工智慧（AI, Artificial Intelligence）
AI 的歷史演進
取得訓練資料 — — 打造模型的第一步
特徵抽取 — — 你是哪裡人？
AI 技術在企業上的數位轉型
AI 的應用：機器翻譯
AI 是如何變聰明的？ — — 淺談「機器學習」與「深度學習」
AI 如何變聰明？（二） — — 什麼是「機器學習」
AI 如何變聰明？（三） — — 模擬人類大腦的「類神經網路」
AI 如何變聰明？（四） — — 什麼是「深度學習」
開啟 AI 2.0 新時代
大型語言模型（LLM）的發展
大型語言模型（LLM）對自然語言處理（NLP）的影響 ← 目前位置
ChatGPT 為什麼那麼紅？一次了解歷代 GPT 模型
Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Written by AI Justka
9 Followers
·
Editor for 

AI 講講話

this is a testing for the chatbot

Follow
More from AI Justka and AI 講講話

AI Justka

in

AI 講講話

大型語言模型（LLM）的發展
在上一篇 開啟 AI 2.0 新時代 我們提到「LLM」（Large Language Models，大型語言模型），它是奠定在深度學習的基礎上，可以進行語言理解、文本生成、圖像處理等多種任務，說到 LLM 的發展歷程，可以追溯到早期的統計語言模型和神經網絡語言模型。
6 min read
·
Aug 23, 2023

AI Justka

in

AI 講講話

ChatGPT 為什麼那麼紅？
一次了解歷代 GPT 模型
8 min read
·
Aug 23, 2023

AI Justka

in

AI 講講話

直覺易懂的分類 — — 決策樹（Decision Tree）
決策樹（Decision Tree）是一種監督式演算法（監督式學習可參考AI 如何變聰明？（二） — — 什麼是「機器學習」​​​​​​​），被廣泛用於機器學習、模型預測當中，由於決策樹直觀且易於掌握，就像一棵樹一樣，是一個強而有力的工具！
4 min read
·
Aug 29, 2022

1

AI Justka

in

AI 講講話

AI 斷詞大解密
聊天機器人如何知道我們在說什麼？
4 min read
·
Dec 3, 2021

2

See all from AI Justka
See all from AI 講講話
Recommended from Medium

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Lists
Staff Picks
593 stories
·
788 saves
Stories to Help You Level-Up at Work
19 stories
·
501 saves
Self-Improvement 101
20 stories
·
1420 saves
Productivity 101
20 stories
·
1307 saves

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Gowtham Oleti

Apps I Use And Why You Should Too.
Let’s skip past the usual suspects like YouTube, WhatsApp and Instagram. I want to share with you some less familiar apps that have become…
10 min read
·
Nov 15, 2023

18.5K

324

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:54.122 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.072 | Max budget: $10.000 | Current cost: $0.012, prompt_tokens: 3405, completion_tokens: 361
2024-03-02 15:13:54.125 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

Space and Time，简称SxT

ranran

·

Follow

Jan 9, 2024

空间和时间（Space and Time，简称SxT）代表了一项引领计算科学领域的前沿技术，旨在通过可验证的计算层，在分散的数据仓库上扩展零知识证明的应用。这一概念在智能合同、大型语言模型（LLM）以及企业级数据处理领域引发了广泛的兴趣和探讨。

计算层的创新： SxT 的独特之处在于其作为计算层的创新性设计。该层不仅为复杂计算任务提供了高效的执行环境，还能够灵活适应分散式环境，克服了传统中心化计算模型的局限性。

零知识证明的隐私保护： SxT 的核心特征之一是零知识证明的应用。这项密码学技术为系统提供了能力，以在验证计算的正确性的同时保护敏感数据。这种隐私保护的方法为智能合同和数据处理提供了高度安全性。

分散的数据仓库的优势： SxT 构建在分散的数据仓库之上，从而允许数据存储在多个地点。这种分布式结构不仅提高了系统的鲁棒性，还提供了更高的可用性和对抗单点故障的能力。

智能合同和LLM的融合： 在智能合同领域，SxT 提供了可验证的数据处理，确保合同的执行是可信赖的。对于大型语言模型，SxT 可能用于在分布式环境中进行高效的自然语言处理和文本分析，同时保护用户的隐私。

企业级数据处理的安全性： 在企业环境中，SxT 提供了一种安全、可验证的数据处理解决方案。企业可以利用这一技术，确保在处理敏感数据时不会暴露关键信息，从而满足严格的合规性和隐私法规。

总体而言，SxT 不仅是计算科学领域的技术创新，同时也为智能合同、LLM和企业级数据处理开辟了新的可能性。其对隐私保护和分散式计算的关注，使其成为当前科技发展中备受瞩目的前沿技术之一。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Written by ranran
0 Followers
Follow
More from ranran

ranran

Technical guide about SxT
Technical guide about SxT Understand the distributed nature: Ensure you have a solid understanding of the distributed nature of data…
2 min read
·
Jan 23, 2024

ranran

建立在 SxT 上：Golteum
Built on SxT 是一个客户创作的博客系列，展示了 Web3 中基于 Space and Time 构建的许多用例。这篇博文由 Golteum 的团队撰写，旨在强调空间和时间如何成为他们堆栈的关键部分。您可以在此处阅读原始博客文章。
3 min read
·
Jan 18, 2024

ranran

Space and Time
Space and Time (SxT) represents a cutting-edge technology that leads the field of computing science and aims to expand the application of…
2 min read
·
Jan 17, 2024

ranran

关于 SxT 的技术指南
了解分散性质： 确保对数据存储的分散性质有深入的了解。SxT在处理分布在多个节点上的数据时效果最佳。熟悉体系结构，以充分发挥分散处理的能力。
2 min read
·
Jan 9, 2024
See all from ranran
Recommended from Medium

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Lists
Staff Picks
593 stories
·
788 saves
Stories to Help You Level-Up at Work
19 stories
·
501 saves
Self-Improvement 101
20 stories
·
1420 saves
Productivity 101
20 stories
·
1307 saves

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Riikka Iivanainen

The secret life of people with high self-control (it’s easier than you think)
Research suggests that people with high self-control are good at avoiding temptation — not resisting it
8 min read
·
Jan 9, 2024

25K

457

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:57.081 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.084 | Max budget: $10.000 | Current cost: $0.012, prompt_tokens: 3581, completion_tokens: 196
2024-03-02 15:13:57.084 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 程序错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

揭示零样本预测的机制：利用机器学习模型来理解大型语言模型（LLM）的决策过程

Ray Mi

·

Follow

May 31, 2023
引言

当代的机器学习领域，像ChatGPT这样的大型语言模型（LLM）正日益受到关注。它们在知识库、智能搜索机制、聊天机器人和内容创作等各种应用中展现出巨大的潜力。

在机器学习空间中，一个常见的挑战是获取用于验证假设和假定的高质量、代表性的数据。由于高成本、有限的可用性、数据清洁度问题、潜在的偏见以及安全和隐私方面的顾虑等多种障碍，收集这样的数据可能是艰巨的任务。

在与众多客户的讨论中，我注意到人们对于利用ChatGPT和其他LLM的担忧。这些担忧大多源于安全和隐私考虑，导致许多组织选择不使用这些模型。

我与许多客户谈过，了解他们公司对ChatGPT和LLM的看法，大多数公司因为安全和隐私的担忧而禁止使用ChatGPT。

由于将数据与LLM相连接是困难的，为什么我们不利用内容创作的能力来生成合成数据，并将这些数据作为机器学习项目的输入呢？

在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。简而言之，该模型利用其训练时所学的知识进行预测，并在很少或没有上下文的情况下做出假设。

在本文中您将看到：

如何设计正确的提示来从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测）。
创建合成数据并实施提示策略，以获得大量观察结果的回应。
利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策的基本原理。

本文是一系列多个实验中的第一篇，使用相似的业务案例进行演示。未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与业务逻辑和现有流程更紧密地对齐。请随我们一起踏上这个激动人心的大型语言模型潜力开发之旅，敬请关注。

应用案例

在加入DataRobot之前，我在汇丰银行担任全球风险分析经理/副总裁。我的主要职责是利用机器学习优化交易监测系统，并加强我们的反洗钱（AML）框架。为了说明我的工作，我将以AML为例。

什么是洗钱？

洗钱是指通过一系列复杂的银行转账或商业交易来掩盖非法获取资金的来源的非法过程。整个洗钱过程的方案以一种模糊且间接的方式将“洗净”的资金返还给洗钱者。

为什么洗钱是一个难题？

联合国的研究表明，全球洗钱金额估计占全球GDP的2–5%。 随着交易监测能力的成本上升以及监管压力增加，要求个人对合规程序失败承担更多责任，许多组织现在正在寻求突破性技术来解决这些挑战。

理解交易监测框架及其挑战：

简单来说，交易监测过程始于数据，其中包括交易细节和客户资料。银行然后在其交易监测系统（TMS）中应用业务规则。系统监测交易行为并生成一批可能可疑的警报。 然后，由专家团队手动调查这些警报，以确定它们是否真正可疑或仅仅是误报。这个过程可能具有挑战性且耗时，这就是创新技术可以在提高效率和效果方面发挥关键作用的地方。

机器学习如何帮助？

机器学习可以在这个过程中提供巨大的帮助。它可以利用历史交易数据、客户信息和过去的调查结果（无论是真警报还是误报）来预测每个新警报的风险水平。然后可以利用这些信息在手动调查之前对警报进行优先级排序。这不仅简化了流程，还确保及时处理最可能造成损害的问题。

大型语言模型（LLM）如何协助？

当数据收集具有挑战性或反洗钱（AML）团队正在创建新的监测规则时，LLM可以成为宝贵的工具。它们可以用于：a）生成合成数据，和b）预测警报是否可疑。这有助于更有效的监测规则，并协助高效处理警报，促进反洗钱框架的整体优化。

我们能够相信LLMs的辅助作用吗？

如果我们利用机器学习来模拟这些模型所做的决策，我们可以对LLMs产生-的洞察力进行验证和增强，从而对它们对我们的交易监测系统的贡献的可靠性产生信任。通过审查洞察力并理解LLMs预测背后的推理，我们可以验证和增强它们对我们的交易监测系统的贡献的可靠性。
实验过程

为了从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测），我设计了合适的提示语。

首先，我设计了一个简单的提示语，要求提供一个客户的30天交易摘要。ChatGPT给出了一些建议，但没有提供具体的数字数据。

然后，我修改了问题，使其更加精确和详细。我收到的回答非常出色和结构清晰。这种叙述在警报调查过程中非常常见，通常调查专家会利用这些信息来得出结论。

令人惊讶的是，ChatGPT甚至能够创建一个用于生成pandas数据帧的脚本，将其生成的合成信息纳入其中。完美！

当我提出另一个问题时，回答是准确的，但过于详细，缺乏直接性。

为了解决这个问题，我不得不对我的问题进行进一步的细化，使其更加具体地满足我的需求。

到目前为止，我们已经成功地使用了合理的提示策略从LLMs生成了合成数据和预测，甚至没有任何历史上下文。这显示了这些模型在从提示中生成有用、可操作的信息方面的潜力。

创建合成数据并实施提示策略以获取大量观测结果。

在这部分中，我简化了问题，只考虑了8个维度：（ACH-自动清算系统，Wire-电汇）×（交易金额，交易次数）×（实际活动，预期活动）。

我将这个新规则称为“与预期行为的Wire和ACH偏差”。

通过一些文本操作，我能够生成如下的提示语：

“在回答中只回答是或否，不要提供其他信息。这是问题的内容：我正在调查一起潜在的洗钱案件，客户的30天交易行为如下：Wire金额：$7148.0，Wire交易次数：5.0次；ACH金额：$15318.0，ACH交易次数：16.0次；该客户的预期行为是：Wire金额：$7486.0，Wire交易次数：8.0次；ACH金额：$4767.0，ACH交易次数：4.0次；基于实际和预期行为，这个案件是否可疑？”

以下是一个示例：

基于上述实验，我建立了一个包含300名客户的数据集。从每一行中，我生成了一个提示语，并从ChatGPT获得了一个“是”或“否”的回答。 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的一个重要因素。

这是数据集的前几行：

利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策背后的原理。

在对300条记录进行分析后，ChatGPT将其中180条分类为“是”（可疑）和120条分类为“否”（误报）。

让我们快速检查一下Wire交易金额的分布。

交易金额和每种交易类型的交易次数之间存在明显的相关性，这是符合预期和逻辑的。

DataRobot开发了许多模型，并根据首选指标（在本例中是AUC）对它们进行了排名。最优模型的ROC曲线显示了其有效区分ChatGPT“是”和“否”回答的能力。

通过利用基于SHAP的特征影响分析，我们发现尽管提示主要侧重于比较实际值和预期值（“比率”变量），但实际交易金额和交易次数（例如Txn Cnt ACH）也对预测有显著贡献。

让我们深入研究一下前几个关键特征的影响：

当ACH交易次数超过9次时，较高的值显著增加”是”预测的概率。
对于实际和预期Wire交易金额之间的比率，超过1的偏离值表示更高的风险，当该比率超过2时，风险显著增加。
与前一个情况相反，当ChatGPT评估实际和预期ACH交易次数之间的偏离时，低于预期值（<0.8）也引起怀疑。
当实际Wire交易金额超过8000美元时，风险水平突然上升。

为了提供更多见解，以下是基于SHAP的预测解释，揭示了影响ChatGPT预测的因素。

通过利用机器学习并探索LLM的内部工作原理，我们开启了无限的机遇。我们可以优化模型，提高其准确性，并利用它们的力量在各个行业和领域推动智能决策的发展。

结论

我还有其他想法要探索，但我将它们保留到未来的博客文章中。总结起来，从这个分析中得出的关键要点是：

大型语言模型（LLM）可以通过有效的提示策略进行零样本预测。
机器学习和预测洞察力对于理解LLM的预测和推理过程至关重要。
利用LLM生成合成数据可以极大地加快新想法的开发和评估，消除数据可用性限制和安全/隐私问题。

这些洞察力突出了LLM在各种应用中的潜力，并强调了利用机器学习技术进行预测分析的重要性。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Llm
Datarobot
Machine Learning
Trust
Written by Ray Mi
35 Followers

RVP of DataScience Practice, DataRobot

Follow
More from Ray Mi

Ray Mi

From Innovation to Implementation: Best Practices for Monitoring Generative AI in Business
Introduction
4 min read
·
Aug 11, 2023

11

Ray Mi

Unveiling the Mechanics of Zero-Shot Predictions: Harnessing Machine Learning Models to Understand…
Introduction
8 min read
·
May 30, 2023

7

Ray Mi

Future of Generative AI: A Frontline Practitioner’s Take on Adoption Trends
Introduction
8 min read
·
Jun 5, 2023

28

Ray Mi

Demystify Large Language Model and Generative AI (Part 2) : From GPT to ChatGPT, a Data Science…
Introduction
9 min read
·
Jun 14, 2023

35

See all from Ray Mi
Recommended from Medium

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.2K

37

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Lists
Predictive Modeling w/ Python
20 stories
·
956 saves
Practical Guides to Machine Learning
10 stories
·
1129 saves
Natural Language Processing
1244 stories
·
725 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
320 saves

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:58.467 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Fail to load page content for Timeout 30000ms exceeded.

2024-03-02 15:13:58.919 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.125 | Max budget: $10.000 | Current cost: $0.041, prompt_tokens: 12769, completion_tokens: 696
2024-03-02 15:13:58.921 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 可执行代码生成".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

Member-only story

中國 — 关于 CHATGPT 技术的一般文章
ChatGPT — LLM 模型（大型语言模型）
中國 — 了解 ChatGPT 的技术和应用。

José Antonio Ribeiro Neto (Zezinho)

·

Follow

Published in

ChatGPT LEARNING — ASIA

·
7 min read
·
May 12, 2023
DALL·E 2023–03–15 11.13.04 — 人工智能应用中大型语言模型的印象主义绘画。
ChatGPT — LLM 模型（大型语言模型）

LLM（大型语言模型）是这些模型中最著名的。

用于使用自然语言处理 (NLP) 算法和称为 Transformers 的 AI 训练技术解决语言问题。

ChatGPT 使用这种从长文本字符串中获取含义的技术来了解不同的单词或语义组件可能如何相关，然后确定它们彼此相邻出现的可能性。

一款猜测较早学习的单词和短语的游戏，稍后再猜。

这些转换器在一个称为预训练的过程中在大量自然语言文本上无人值守地运行，然后由与模型交互的人类进行调整。

预训练是教授系统的地方，或者更确切地说，是它自己学习文本中单词之间关系的地方。

这些大规模模型导致了系统的发展，这些系统可以理解我们所说或所写的内容，或者更确切地说，可以从他们从人类那里学到的东西中产生知识。

使用这些模板的一个非常简单的例子是在键入消息时自动填写表格和手机。 该系统为您提供了备选词，供您在句子的上下文中进行选择。

我们正在谈论猜测下一个词或接下来的两个词。 LLM模型把这个概念发挥到了极致，有的可以看前后700个单词，有的远不止于此。

也就是说，他们试图猜测文本中接下来的 700 个单词。

这些系统越聪明，它们就能猜到越多的单词，或者更确切地说，可以统计地预测出正确的单词作为答案。

1 — 在各种人类活动中训练的模型

值得注意的是，只要经过适当的训练，这些模型就可以适用于所有类型的人类活动。

例如：

用著名艺术家的作品训练的系统可以按照这些艺术家的风格生成新的艺术作品。
受过数学或化学教科书训练的系统可以在这些领域产生具有新想法的结果。
接受辩护案例培训的系统可以学习和协作，以便在法官和法院中开发和解决案件。

我们可以看到，这些系统将在未来几年入侵世界，我们将在我们的教育、个人和职业生活中与其中许多系统互动。

出于这个原因，我们正在目睹一场主导和改进这项技术的竞赛，这项技术可能与互联网一样重要，并且可以带来社会变革，如农业、工业和技术革命。

ChatGPT 询问什么是 AI 中的 LLM 的屏幕截图。

2 — LLM 算法

LLM是一种深度学习算法，可以根据海量数据训练得到的知识，识别、归纳、翻译、预测和生成文本等内容。

这些文本模型不仅仅用于教授或翻译人类语言。

他们可以通过聊天机器人以文本格式回答问题，应用范围非常广泛，例如：

了解蛋白质、分子、DNA 和RNA。
编写计算机代码。
为图像生成器构建文本和图像对。
改进搜索引擎。
作曲、写诗、写故事、写书。

这些模型在推理、常识和问题解决等人工智能领域展示了强大的能力。

最受欢迎的 LLM 模型是：

ChatGPT 中使用的 OpenAI 的 GPT（生成式预训练转换器）。
CODEX by OpenAI 用于计算机代码生成。
Microsoft 的 Sydney 基于 ChatGPT for Bing 构建。
Bard 使用的谷歌LaMDA（对话应用程序语言模型）是谷歌的会话人工智能服务。
Nvidia 的威震天。
Create an account to read the full story.

The author made this story available to Medium members only.
If you’re new to Medium, create a new account to read this story on us.

Sign up with Google
Sign up with Facebook
Sign up with email
Already have an account? Sign in

Written by José Antonio Ribeiro Neto (Zezinho)
10K Followers
·
Editor for 

ChatGPT LEARNING — ASIA

AI Researcher & Author | USA WebCT IT Exec | Portuguese-Brazilian | Tech Educ Director | Digitalis Portugal Partner | Ex-Soccer Athlete | Advocating Peace.

Follow
More from José Antonio Ribeiro Neto (Zezinho) and ChatGPT LEARNING — ASIA

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT LEARNING

ChatGPT and the Human Talent
ENGLISH — LEARN ABOUT ChatTGPT TECHNOLOGY AND APPLICATIONS
·
5 min read
·
Jan 24, 2024

1.7K

15

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT LEARNING — ASIA

Модель LLM (большие языковые модели)
РУССКИЙ — ПОНИМАНИЕ В ТЕХНОЛОГИИ И ПРИМЕНЕНИИ ChatGPT.
·
6 min read
·
May 13, 2023

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT LEARNING — ASIA

Влияние ChatGPT на образование.
РУССКИЙ — ПОНИМАНИЕ В ТЕХНОЛОГИИ И ПРИМЕНЕНИИ ChatGPT.
·
8 min read
·
Feb 25, 2023

125

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT Insights: AI in Short Articles.

From ChatGPT to Ethical Implications: A Journey through the Risks of Generative AI
EXPLORING ARTIFICIAL INTELLIGENCE IN SHORT DOSES OF KNOWLEDGE
·
11 min read
·
Feb 21, 2024

100

See all from José Antonio Ribeiro Neto (Zezinho)
See all from ChatGPT LEARNING — ASIA
Recommended from Medium

Jules S. Damji

Best Prompt Techniques for Best LLM Responses
Better prompts is all you need for better responses
7 min read
·
Feb 12, 2024

122

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Lists
What is ChatGPT?
9 stories
·
309 saves
ChatGPT prompts
44 stories
·
1190 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
320 saves
ChatGPT
21 stories
·
492 saves

Jordan Gibbs

Three Underrated ChatGPT Use Cases
Three of my favorite use cases for ChatGPT that I don’t see enough people using.
·
5 min read
·
5 days ago

330

1

AI Accelerator

4 Ways to Connect ChatGPT to the Internet: A Comprehensive Guide
In today’s digital age, the ability to connect AI models like ChatGPT to the internet is a game-changer. With the rise of OpenAI’s ChatGPT…
·
3 min read
·
Oct 25, 2023

157

Mark Riedl

A Very Gentle Introduction to Large Language Models without the Hype
1. Introduction
38 min read
·
Apr 14, 2023

7.1K

118

Prompt Artist

in

𝐀𝐈 𝐦𝐨𝐧𝐤𝐬.𝐢𝐨

How to Optimize ChatGPT Prompts: Tokens and Cost Saving with Sensitivity to Phrasing Prompts…
Crucial aspects of ChatGPT’s prompt engineering include sensitivity to input phrasing, resulting in potential savings on both tokens &…
9 min read
·
Jan 15, 2024

51

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:13:59.794 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.125 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 199, completion_tokens: 3
2024-03-02 15:13:59.798 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
首页
培训课程
分类浏览
活动讲座
问答
企业培训
摸鱼
快讯
搜索
APP
发布
注册 | 登录
GPT-4V连小学生都不如？最新基准测试错误率竟高达90%：红绿灯认错、勾股定理也不会
新智元
关注
2023-10-31
0 评论
1351 浏览
1 收藏
15 分钟
🔗 B端产品经理两大难题：如何从市场，用户，业务等多个角度分析和设计产品？如何有效地管理和推进项目落地？

具备视觉能力的GPT-4版本——GPT-4V，一定程度上被大众寄予了期待，但最近有研究人员基于他们对于视觉能力的测试，发现GPT-4V在回答视觉问题组的错误率竟高达近90%。而导致这类错误发生的原因，可能在于视觉错觉和语言幻觉。

GPT-4被吹的神乎其神，作为具备视觉能力的GPT-4版本——GPT-4V，也被大众寄于了厚望。

但如果告诉你，初中生都知道的勾股定理，只适用于直角三角形。

然而GPT-4V却自信将其用于钝角三角形中计算斜边长度。

还有更离谱的，GPT-4V直接犯了致命的安全错误，竟然认为红灯可以行驶。

这到底是怎么回事呢？

马里兰大学的研究团队在探索过程中发现了这些问题，并在此基础上提出了两种主要的错误类型：语言幻觉和视觉错觉，以此来阐释这些错误的原因。

论文链接：https://arxiv.org/abs/2310.14566

项目主页：https://github.com/tianyi-lab/HallusionBench

研究人员依据上述分析，创建了一个名为HallusionBench的图像-语境推理基准测试，旨在深入探讨图像与语境推理的复杂性。

基于他们的对于视觉能力的测试，GPT4V在回答视觉问题组的错误率高达近90%。

研究者们还对新发布的GPT-4V(ision)和LLaVA-1.5进行了详细的研究，深入分析了它们在视觉理解方面的能力。

HallusionBench是第一个专为VLM设计的基准测试，主要关注视觉错觉和知识幻觉。这个测试包括约200组视觉问答，其中近一半是由人工专家创作的。

目前数据已经开源, 并且还在更新中。

如何定义B端产品及B端产品经理方法论
相较于C端产品，B端产品最大的特点是：面向特定领域用户，且数量少得多，但更注重对用户专业领域操作流程的深度挖掘——也就是专业性更强，与业务的结合更紧密。
查看详情 >

涉及的图片类型多样，包括原始的错觉图片、图表、地图、海报、视频及手动制作或修改的图片，涵盖数学、计数、文化、动漫、体育和地理等多个领域。

论文中，作者初步阐述了HallusionBench中的两种视觉问题分类：视觉依赖型（Visual Dependent）和视觉补充型（Visual Supplement），并讨论了实验对照组的设计方法。

随后，他们分析了可能导致答案错误的两大主要原因：视觉错觉（Visual Illusion）和语言幻觉（Language Hallucination）。

在文末，作者通过不同的子类别详细展示了各主要类别中的失败案例，并进行了深入的分析。

关键点：

「语言幻觉」：在GPT-4V和LLaVA-1.5中会误导90%的样本推理。视觉与语言之间的微妙平衡至关重要！
「视觉错觉」：LVLMs中的视觉模块容易受到复杂视觉上下文的影响，语言模型的错误被夸大。
简单的图像修改就能欺骗GPT-4V和LLaVA-1.5，暴露了对更强大的图像分析能力的需求。
GPT-4V在推理多个图像之间的时间关系方面存在困难。
LLaVA-1.5有时会在常识查询上犯错，需要改进其语言模型先验。
一、视觉问题类型

视觉依赖型问题（Visual Dependent）：

这类问题的答案完全依赖于视觉内容，缺乏图像信息时无法确切回答。

这些问题通常关联到图像本身或其显示的内容。例如，在没有图像的情况下，无法准确回答诸如「图中右侧的橙色圆圈是否与左侧的同样大小？」之类的问题。

视觉补充型问题（Visual Supplement）：

这些问题即使在没有视觉内容的情况下也能得到回答。在这种类型的问题中，视觉元素仅提供附加信息。

比如，即便没有图片辅助，GPT-4V仍能回答「新墨西哥州是否比德克萨斯州大？」等问题。

测试的核心在于判断GPT-4V和LLaVA-1.5能否利用图像内容来作答，而不是仅凭它们的参数化记忆。

二、错误分类

作者对错误回答进行了分析，并将其原因分为两大类：

视觉错误（Language Hallucination）：

这类错误产生于对输入图像的错误视觉识别和解释。模型未能从图像中提取准确信息或对其进行正确推断。

语言幻觉（Visual Illusion）：

模型基于其参数化知识库，对问题输入和图像背景作出不恰当的先入为主的假设。模型应当针对问题的具体环境作出反应，而不是忽略问题本身或对图像作出错误解读。

三、范例

从图1所展示的经典视觉错觉案例中可见，GPT-4V在识别各种错觉图像及其名称上显示出比LLaVA-1.5更丰富的知识储备。

图1

然而，在回答经过编辑处理的图像相关问题时，GPT-4V未能提供精确答案。

这种现象可能源于GPT-4V更多地依赖于其参数化存储的知识，而不是实际对图像进行分析。

与此相反，无论是处理原始图像还是编辑后的图像，LLaVA-1.5的表现都相对较差，这反映出LLaVA-1.5在视觉识别方面的能力较为有限。

观察图2提供的样本，可以发现GPT-4V和LLaVA-1.5均未能正确识别平行线、正三角形、多边形及其他数学定理。

这一现象揭示了，对GPT-4V而言，在处理几何和数学问题方面仍面临较大挑战。

图2

在图3的展示中，作者指出了几则海报，展示的是一些知名的地方美食，但这些美食的地理特征遭到了改动。

面对这样的场景，GPT-4V和LLaVA-1.5都未能充分考虑上下文信息，忽略了图像内容，继续根据文本中提及的知名产地来回答相关问题。

图3

在图4的案例中，作者进一步探讨了对多张图片序列的处理能力。

图片的顺序排列和倒序排列在语义上常表现出对立的意义，例如「出现与消失」和「后退与前进」。

图4

研究比较表明，尽管这些图片序列描绘了不同的动态，GPT-4V依然未能区分这些图片的顺序和逆序排列。

这一发现指出，在视频序列推理方面，GPT-4V仍需大幅度的优化和提高。

图5展示了一个案例，其中在缺乏图像背景信息的情境下，GPT-4V提供了一个断定性的回答。

图5

相对地，LLaVA-1.5，由于对文本的理解不足，提出了一个技术上无误但与问题无关的答回答。

当以修改后的π值作为视觉输入，两个模型均未能从图像中正确识别和解释这个值。

图6中的情形显示，当缺少视觉输入时，GPT-4V和LLaVA-1.5都能准确且断定地作出回答。

图6

然而，在表格作为视觉输入的情况下，GPT-4V尝试依据视觉信息解答，却误取了错误数据。

例如，GPT-4V错误地答道「中国赢得了36枚金牌」，尽管图表实际显示的是美国获得了这些金牌。

相比之下，LLaVA-1.5更依赖于其参数化记忆，在分别处理问题和表格时表现不同。

在图7的场景中，即使没有视觉辅助，GPT-4V和LLaVA-1.5都作出了断定性的答复，其中GPT-4V的答案更为准确和精确。

图7

当引入图表作为视觉输入，GPT-4V能精准地根据图表中的数据给出答案，而LLaVA-1.5则依赖于其参数化知识进行回答。

但是，一旦图表被翻转，GPT-4V对答案的预测发生了根本性变化。这个错误可以被解释为由视觉错觉引起的。

根据图8，在缺乏图像支持的情形下，GPT-4V和LLaVA-1.5均提供了确定的回答，但正确答案仅由GPT-4V给出。

图8

由此可以推断，GPT-4V在知识层面上优于LLaVA-1.5。

然而，当地图的视觉呈现发生改变时，两种模型由于其强大的参数记忆能力，均未能正确推断出四个州的相对位置。

四、总结

近年来，随着大规模语言模型和多模态研究的快速发展，人工智能领域经历了重大的变革。

自然语言处理（NLP）和计算机视觉（CV）的结合，不仅促成了大型视觉语言模型（LVLM）的诞生，而且显著提高了图像推理任务的性能。

但是，LVLM仍面临着一些挑战，如语言幻觉和视觉错觉等问题。

本研究通过推出HallusionBench，旨在为VLM提供一个基准测试，特别是在那些容易因语言幻觉或视觉错觉而失败的复杂情况下。

我们对GPT-4V和LLaVA-1.5的不同示例和失败案例进行了深入探讨，包括：

1. 在HallusionBench中，GPT-4V和LLaVA-1.5在处理含有先验知识的问题时，往往会受到语言幻觉的影响。这些模型更倾向于依赖先验知识，导致在我们的分析的例子中，超过90%的答案是错误的。因此，模型需要在参数化记忆和输入文本图片之间找到一个平衡点。

2. 即便是在GPT-4V和LLaVA-1.5缺乏参数化记忆或先验知识的情况下，它们仍然容易受到视觉错觉的影响。这些模型常常在处理几何图形、数学图像、视频（多图像场景）、复杂图表等问题时给出错误答案。目前，视觉语言模型在视觉处理方面的能力还很有限。

3. GPT-4V和LLaVA-1.5在HallusionBench中容易被一些基本的图像操作所误导，如图像翻转、颠倒顺序、遮挡、物体编辑以及颜色的修改等。目前的视觉语言模型尚未能有效处理这些图像操作。

4. 虽然GPT-4V支持处理多图，但在分析涉及时间线索的多图像问题时，它未能展现出有效的时间推理能力，在HallusionBench中表现欠佳。

5. 在HallusionBench的测试中，LLaVA-1.5由于知识库相对较少，有时会犯下一些基本的错误。

作者表示，他们的数据集已经开源，并正在继续扩展数据库。最新的数据会在Github （https://github.com/tianyi-lab/HallusionBench）上不断更新。

这项研究为未来更加强大、平衡和精准的LVLM奠定了基础，并期待通过这些详细的案例研究，为未来研究提供一些可能方向。

参考资料：

https://arxiv.org/abs/2310.14566

编辑：LRS，好困

来源公众号：新智元（ID：AI_era），“智能+”中国主平台，致力于推动中国从“互联网+”迈向“智能+”。

本文由人人都是产品经理合作媒体 @新智元 授权发布，未经许可，禁止转载。

题图来自 Unsplash，基于CC0协议。

该文观点仅代表作者本人，人人都是产品经理平台仅提供信息存储空间服务。

赞赏
收藏
1
点赞
0
更多精彩内容，请关注人人都是产品经理微信公众号或下载App
GPT-4V
LLaVA-1.5
大模型
视觉错觉
语言幻觉
分享
新智元
关注
"智能+"中国主平台，致力于推动中国从"互联网+"迈向"智能+"
39篇作品  138999总阅读量
为你推荐
Axure高保真教程：滑动内容选择器
11-172014 浏览
回顾GPT大模型2023这一年，5大顶级公司预测2024年AI产品
12-012049 浏览
3万亿市场、5亿用户，亟待开发的直播电商产业价值链！
03-294351 浏览
董宇辉升职了，也离“东方甄选”越来越远了
12-20595 浏览
MarTech​-CDP实战手册-CDP交付验收（十三）
10-132728 浏览
如何掌握高阶运营增长，突破职场瓶颈？
推荐
评论
评论请登录
目前还没评论，等你发挥！
为你推荐
这届618，中小商家不再「失声」？
06-192793 浏览
除了ChatGPT，谁是 AI 领域下一个大赢家？
09-227080 浏览
6个月，1个人让增长业务“重回正轨”
09-119448 浏览
推荐专题
更多专题
专题
13427人已学习12篇文章
SaaS平台产品架构设计
本专题的文章分享了SaaS平台产品架构设计。
专题
35959人已学习3042篇文章
私域学院
专题
14657人已学习12篇文章
支付风控体系的设计指南
本专题的文章分享了支付风控系统的设计指南
专题
16433人已学习15篇文章
用户激励体系的签到功能设计指南
签到功能是培养用户习惯的好办法。本专题的文章提供了签到功能的设计指南。
专题
31350人已学习15篇文章
用户增长，这样做才有效！
一起来看看别人家是怎么做用户增长的。
专题
12851人已学习13篇文章
如何做好用户访谈？
无论是对于需求的挖掘，还是对于产品的设计迭代，用户访谈这个环节都是必不可少的。本专题的文章分享了如何做好用户访谈。
社群
QQ群 | 微信群
TOC产品交流群
加入
TOB产品交流群
加入
TOG产品交流群
加入
抖音运营交流群
加入
视频号运营交流
加入
小红书运营交流
加入
快讯
查看更多
瑞幸正在退出“价格战”，库迪再推出9.9元促销
2小时前
比亚迪股份：2月新能源汽车销量122311辆，同比下降36.8%
2小时前
鸿蒙智行AITO全系2月交付新车21142辆
2小时前
热门文章
用户研究之全面解析Persona
03-01
浅聊产品经理到底是个什么经理？
03-01
电商分账系统的使用——空中分账
03-01
六大指标，让细分市场选择不再困难（二）
03-01
金融风控中常说的决策引擎，到底是什么？
03-01
Sora热度背后，真正值得学习的是什么？
03-01
工作中，是老板让做什么就做什么，还是做对的事情？
工作中，明明我们以已有的经验和事实证明，老板的想法是不可取的，而且并不能达到老板的预期但是老板也坚持...
26k 点击26 回答
进入回答
每段工作经验都比较短，会影响找工作吗？
18.6k 点击37 回答
知识分享类视频，问答社区“知乎”or短视频平台“抖音”，谁更具优势？
28.1k 点击47 回答
抖音大力布局本地生活，有没有可能变成短视频版“美团”？
33.7k 点击53 回答
文章导航
一、视觉问题类型
二、错误分类
三、范例
四、总结
关于
人人都是产品经理（woshipm.com）是以产品经理、运营为核心的学习、交流、分享平台，集媒体、培训、社群为一体，全方位服务产品人和运营人，成立12年举办在线讲座1000+期，线下分享会500+场，产品经理大会、运营大会50+场，覆盖北上广深杭成都等20个城市，在行业有较高的影响力和知名度。平台聚集了众多BAT美团京东滴滴360小米网易等知名互联网公司产品总监和运营总监，他们在这里与你一起成长。
合作伙伴
链接
隐私政策
投稿须知
意见反馈
帮助中心

公众号

视频号

友情链接
PM265
产品经理导航
起点课堂
猪八戒网
人才热线
伙伴云表格
网易易盾
个推
友盟+
粮仓
创业邦
每日报告
鸟哥笔记
慕课网
旗下品牌: 起点课堂 | 运营派 | 粮仓企微管家
©2010-2024 - 人人都是产品经理 - 粤ICP备14037330号-粤公网安备 44030502001309号
广播电视节目制作经营许可证（粤）字第03109号 版权所有 © 深圳聚力创想信息科技有限公司

2024-03-02 15:14:03.710 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.139 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 4282, completion_tokens: 300
2024-03-02 15:14:03.712 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 程序错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

从「文化技术」理解大型语言模型

LM Po

·

Follow

Jul 14, 2023

人工智能 (AI) 的最新进展，特别是在大型语言模型 (Large Language Model — LLM) 领域（例如 OpenAI 的 ChatGPT 和 Google 的 LaMDA），引发了有关这些系统的性质和功能的争论。 一些人认为LLM是真正的智能代理(Agents)，而另一些人则认为他们只是通过对大量数据集进行复杂的统计分析来产生表面的人性。 然而，这种二分法依赖于拟人化的观点，可能会阻碍更具建设性的观点。

最近，艾莉森·戈普尼克（Alison Gopnik）教授（加州大学伯克利分校）认为，我们不必将LLM与人类个体的思维进行比较，而是可以有效地将它们视为促进人类获取知识的「文化技术」。 正如「语言」能够将 「知识」代代相传一样，LLM也能综合人类集体智慧的成果。 它们的功能不是展示智能，而是充当人类「应用智能的媒介」。 正如「语言」让我们的祖先能够传承「知识和技能」一样，LLM让我们更有效地积累过去的知识。

从这个角度看，关于LLM到底是艾伦·图灵(Alan Turing)这样的天才还是仅仅是「双语艺术家」(double-talk artist)的争论见得无关重要。 我们应更好地评估LLM如何发挥其作为「文化遗产载体」的作用。 它们是否忠实地代表人类来之不易的「知识」？ 我们能否更轻松地运用它来增强对知识的理解？ LLM成功的衡量标准不是它是否能模仿人类思维，而是它如何有效地为大众理解和运用知识。

文化技术 (Cultural Technologies)

历史上出现过几种革命性扩展人类获取知识的「文化技术」。 「文字」能够实现跨时代、跨地域保存和传播「知识」。 「印刷术」增强了这种能力，「图书馆」作为知识库，广泛提供学术成果。近年来「搜索引擎」和「维基百科」等数字工具进一步推广了人类集体智慧的获取。

ChatGPT等语言模型也应视之为新一代的「文化技术」。它们的功能不是展示智能，而是综合大量人类语言创作的文本数据集。它们扮演总结人类语言文字累积的角色。 LLM作为拟人化的独立代理人，它们的能力似乎有限。但如果将其理解为「文化技术」，其意义就变得更加清晰。它们并不体现知识，而是跨时间跨空间提供他人所体现的知识。

「文化技术」能大大增强人类的「认知能力」，历史已证明这一事实，通过支撑「知识」的代代传承，「文化技术」实现知识的积累式创新，每代人都站在前人的肩膀上。汲取了数十亿数字文本的LLM系统，应能为新一代人类学习带来更大增强趋势。 LLM的成功应该基于它是否高效地概括和呈现人类来之不易的智慧成果来判断。如同图书馆，它的目的不是取代人类智力，而是让智力成果更易获取。在这个角色中，如果谨慎应用，LLM将为提升对知识宝库的理解带来巨大希望。

文化演变

文化的演变依赖于「模仿」与「创新」之间的平衡。像LLM这样的技术擅长在训练数据中模仿语言模式。然而，产生新颖见解需要超越过去的发现，探索未知领域。尽管像ChatGPT这样的模型可以按概率产生文本，但人类的创造力往往来源于检测意外的关联。

最近的「因果学习实验」(causal learning)说明了这一局限。仅3岁的孩子就可以通过有趣的实验快速推断出新型「木块探测器」的工作原理。尽管接触了数十亿文本，LLM仍难以应对这种直观的物理推理。如果没有得到关于「木块探测器」原理的明确训练，LLM无法在这种陌生环境中掌握因果关系。

这些发现凸显人类创造力在超越理解界限方面的持续重要性。尽管模仿现有知识至关重要，但探索新领域的创新仍超出当前AI的范围。 LLM的计算能力无法消除好奇心驱动的探究需求。汇总集体智慧的技术仍依赖有机智能来拓展洞见的领域。

人工智能时代的社会智慧

要实现「人类」与「人工智能」之间的有效协作，就需要认识到双方的互补优势。作为卓越的模仿者，LLM可以作为人类文明遗产的宝贵索引。但仅仅模仿过去并不能推动进步。人类学者依然保留「超越根深蒂固范式」和「创造新思想」的不可替代的功能。每一位创新者都站在前人巨人的肩膀上，知识通过连续性和创造性的微妙互动向前发展。

人类积累文化演变的能力固有风险。通过获取和传播知识，我们很容易受错误信息和操纵影响。书写和印刷等技术推动智识进步,也带来新形式欺骗。像LLM这样的AI系统加剧了这种紧张。它们擅长总结我们来之不易的知识，促进发现。但LLM的产出本质上反映人类的缺陷和智慧。提供启迪的能力同样提供误导工具。

历史已记载了解决这困境的经验。随着每项「新文化技术」出现，必然带来新「规范」和「制度」的发展，常以「激励利益」并「减轻伤害」从而带来进步。这样事实被核查，道德被规范化，法规被颁布。

强大的LLM同样需要深思熟虑的社会智慧来治理。不应被对机器超智能的恐惧言论取代了对人类福祉的切实担忧。现今社会更紧迫的是培育个人和集体「美德」和「技术知识」，从而以善用这些技术。通过合理化担忧，我们可以解决LLM问题，同时发挥其潜力。因此，核心挑战在于向新旧文化技术灌输「崇高价值观」和「相关技术知识」，通过这些价值观和知识谱写人类正在展开的新故事。

结论：

·「 语言」、「书写」、「印刷」、「图书馆」、「搜索引擎」等「文化技术」使人类能够在前几代人的发现的基础上继续发展，这对于人类的智慧和进步至关重要。

· 像 ChatGPT 这样的LLM非常擅长模仿语言模式，但不擅长创新或产生新颖的意想不到的想法，而这对于智力也很重要。

· 新的「文化技术」既带来好处（传播知识），也带来风险（传播错误信息）。 历史上，各种规范、机构和法规的出现都是为了实现利益最大化、危害最小化。

· 我们应该将大语言模型视为一种新的文化技术，并专注于制定适当的规范和规定，而不是争论它们是否「智能」。 目标应该是让这些模型造福人类。

参考：

https://simons.berkeley.edu/talks/large-language-models-culture-technology

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Technology
Culture
Artificial Intelligence
Politics
Written by LM Po
3 Followers
Follow
More from LM Po

LM Po

From Writing to AI: Viewing LLMs as Cultural Technology
Recent advances in artificial intelligence (AI), particularly in the domain of Large Language Models (LLMs) like OpenAI’s ChatGPT and…
5 min read
·
Jul 14, 2023

7

See all from LM Po
Recommended from Medium

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

Lists
AI Regulation
6 stories
·
343 saves
ChatGPT prompts
44 stories
·
1190 saves
Generative AI Recommended Reading
52 stories
·
769 saves
ChatGPT
21 stories
·
492 saves

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Alexandru Lazar

in

ILLUMINATION

Ten Habits that will get you ahead of 99% of People
Improve your life and get ahead of your peers in 10 simple steps
9 min read
·
Nov 18, 2023

20K

349

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:14:04.952 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.148 | Max budget: $10.000 | Current cost: $0.009, prompt_tokens: 2568, completion_tokens: 308
2024-03-02 15:14:04.954 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 可执行代码生成".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

Member-only story

中國 — 关于 CHATGPT 技术的一般文章
ChatGPT 和谈话的艺术：生成人工智能的潜力分析。
中國 — 了解 ChatGPT 的技术和应用。

José Antonio Ribeiro Neto (Zezinho)

·

Follow

Published in

ChatGPT LEARNING — ASIA

·
14 min read
·
May 12, 2023
DALL·E 2023–03–15 11.06.58 -关于生成人工智能的印象派绘画。
第 1 节 — 介绍

ChatGPT 是人工智能分支的一部分，称为生成人工智能 (GenAI)。

它们是用于生成文本、音频、图像、视频、模拟和计算机代码的算法。

生成式人工智能采用称为机器学习、深度学习和神经网络的人工智能技术，根据对文字、声音、图像和视频的统计预测来生成内容。

之所以称为生成式，是因为它通过简单的自然语言命令创建了一些以前不存在的东西，例如“画一张猫和狮子坐在一起的图片”或“写一篇关于环境的文章”，或编写代码在 Python 中。

截图询问 ChatGPT 什么是生成人工智能。

1 — 生成式 AI 和内容制作

生成式 AI 根据从其受过训练的大量数据中学习到的统计数据和概率来制定响应。

生成人工智能能够生产：

文章、诗歌、新闻、脚本、审查计算机代码、演示文稿、翻译等文本。
新风景、人脸、绘画、化身、虚拟环境等图像。
音频，例如音乐、音效、画外音、将视频或音频转换为文本等。
来自先前定义的文本或图像的合成视频。

这里令人兴奋的是，生成式人工智能产品会根据用户提出的问题在计算机提示符下提供答案，这是一个接收问题的空白行，类似于聊天机器人。

ChatGPT 4.0 版称为多模式。 这意味着它可以从提示行中提供的文本或图像生成内容。

2 — 通过提示行的命令

DALL-E 屏幕带有命令提示符，请求生成“合成图像”。

我可以让 ChatGPT 写一篇关于环境的文章，或者让 DALL-E 从简单的问题中生成一幅关于我们社会偏见的印象派绘画，比如：

ChatGPT，你能写一篇关于环境的文章吗？
DALL-E，你能画一幅关于环境的印象派画作吗？

你写作时就好像在和朋友、孩子或邻居聊天一样。

第 2 节 — ChatGPT 和综合内容
DALL·E 2023–03–15 11.08.36 — 关于生成人工智能的印象派绘画。

生成式 AI 生成的主要产品称为合成数据或内容，由数字世界中的机器（应用程序）创建。

它们是使用从输入数据中学习的统计技术和模式从预先存在的数据生成的文本、图像、音频和视频内容。

一个生成式 AI 应用程序可能已经过训练，可以阅读数千篇关于政治的文章，以便能够提出或回答有关该主题的新问题。

另一个应用程序可以从成对的数据与文本和图像的关联中生成印象派绘画，这些印象派绘画已经接受了印象派画家的数百幅画作的训练。

所有应用程序的概念都是相同的。

首先是基于大量数据的训练，包含数千、数百万或数十亿个示例，其结果是从简单的问题中得到智能答案。

一些生成合成内容的应用程序及其功能是：

ChatGPT 生成文本、计算机代码。
MidJourney 创造美丽的插图。
DALL-E 用于绘制美丽的图画。
Create an account to read the full story.

The author made this story available to Medium members only.
If you’re new to Medium, create a new account to read this story on us.

Sign up with Google
Sign up with Facebook
Sign up with email
Already have an account? Sign in

Written by José Antonio Ribeiro Neto (Zezinho)
10K Followers
·
Editor for 

ChatGPT LEARNING — ASIA

AI Researcher & Author | USA WebCT IT Exec | Portuguese-Brazilian | Tech Educ Director | Digitalis Portugal Partner | Ex-Soccer Athlete | Advocating Peace.

Follow
More from José Antonio Ribeiro Neto (Zezinho) and ChatGPT LEARNING — ASIA

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT LEARNING

ChatGPT and the Human Talent
ENGLISH — LEARN ABOUT ChatTGPT TECHNOLOGY AND APPLICATIONS
·
5 min read
·
Jan 24, 2024

1.7K

15

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT LEARNING — ASIA

Модель LLM (большие языковые модели)
РУССКИЙ — ПОНИМАНИЕ В ТЕХНОЛОГИИ И ПРИМЕНЕНИИ ChatGPT.
·
6 min read
·
May 13, 2023

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT LEARNING — ASIA

Влияние ChatGPT на образование.
РУССКИЙ — ПОНИМАНИЕ В ТЕХНОЛОГИИ И ПРИМЕНЕНИИ ChatGPT.
·
8 min read
·
Feb 25, 2023

125

José Antonio Ribeiro Neto (Zezinho)

in

ChatGPT Insights: AI in Short Articles.

From ChatGPT to Ethical Implications: A Journey through the Risks of Generative AI
EXPLORING ARTIFICIAL INTELLIGENCE IN SHORT DOSES OF KNOWLEDGE
·
11 min read
·
Feb 21, 2024

100

See all from José Antonio Ribeiro Neto (Zezinho)
See all from ChatGPT LEARNING — ASIA
Recommended from Medium

Bernard Bado

in

Generative AI

Here’s How to Become ChatGPT Power User in 2024
4 simple tricks you can start using right away
·
4 min read
·
Feb 23, 2024

337

2

Jordan Gibbs

Three Underrated ChatGPT Use Cases
Three of my favorite use cases for ChatGPT that I don’t see enough people using.
·
5 min read
·
5 days ago

330

1

Lists
What is ChatGPT?
9 stories
·
309 saves
ChatGPT prompts
44 stories
·
1190 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
320 saves
ChatGPT
21 stories
·
492 saves

Anish Singh Walia

in

𝐀𝐈 𝐦𝐨𝐧𝐤𝐬.𝐢𝐨

8 ChatGPT Prompts That Will Blow Your Mind and Transform Your Life
AI and technology are not just tools; they are companions in our journey of evolution. Together, they create a landscape where our lives…
7 min read
·
5 days ago

369

8

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

AI Accelerator

4 Ways to Connect ChatGPT to the Internet: A Comprehensive Guide
In today’s digital age, the ability to connect AI models like ChatGPT to the internet is a game-changer. With the rise of OpenAI’s ChatGPT…
·
3 min read
·
Oct 25, 2023

157

Thomas Smith

in

The Generator

Why OpenAI’s Sora Is About Way More Than AI Videos
A world in silicon
·
6 min read
·
4 days ago

1.2K

18

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:14:04.960 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.156 | Max budget: $10.000 | Current cost: $0.008, prompt_tokens: 1811, completion_tokens: 596
2024-03-02 15:14:04.963 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算准确性".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

将数千兆字节的数据引入智能合约：与Space and Time的Scott Dykstra进行对话

Hilary xia

·

Follow

Feb 20, 2024

原文：https://www.nasdaq.com/articles/bringing-terabytes-of-data-to-smart-contracts-chatting-with-scott-dykstra-from-space-and

区块链的前提是它处理的数据无法被篡改。然而，迄今为止，主要区块链的吞吐量与企业需要处理的数据相比微不足道。

更重要的是，区块链甚至无法高效地访问自己的数据。以太坊归档节点需要3到12万亿字节的数据（取决于实现方式），但智能合约无法在不付出巨额的燃气费用的情况下访问这些数据。

一些项目构建了索引器来解决与区块链数据归档相关的低效问题，解决了一些即时需求，例如DEX分析页面。但是，新一代的Space and Time正致力于将这一概念推向一个全新的层面。

Space and Time建立了一个全面的“数据仓库”系统，依赖于基于密码学的SQL证明系统，旨在将数据验证能力扩展到数百万兆字节。随着人工智能的发展，即使在Web3之外，这变得越来越重要。

我们与Space and Time的首席技术官Scott Dykstra坐下来，了解他们如何充分利用区块链的潜力。

嗨，Scott，很高兴见到你。让我们从基本介绍这个主题开始。为什么世界需要可验证和防篡改的数据？这只是Web3的一个用例，还是您认为它会扩展到其他领域？

SD：我认为，在我们进入一个混乱的、由人工智能驱动的世界之际，验证数据是否未被篡改以及对数据的计算是否正确变得越来越重要。这归结于对我们所依赖的系统具有可证明的中立性、透明性和未篡改性的信心。在Web3中，这个用例非常明确，全球的节点运营商正在合并计算资源，以构建一个可证明的网络，但在Web3之外的其他行业也同样重要。

您希望了解金融系统（如银行）没有被操纵。您希望交易系统（如股票或加密货币）是透明和可追溯的。您希望企业共享敏感数据（如患者医疗数据或会计记录）时能够在保护隐私的同时保证数据未被篡改。

如果您有能力可验证数据和数据处理都未被篡改，并且可以使用熟悉的数据库工具以合理的成本来实现这一点，那你为什么不这样做呢？

您提到人工智能在我们的生活中越来越普遍。许多人担心我们无法看到其内部运作，因此围绕其展开的讨论往往集中在“对齐”它并控制其输出上。您认为这是一个可以实现的目标吗？如果是，您认为该如何实现？

SD：当我们对大型语言模型的规模进行分类时，我们谈论的是数十亿个参数。我相信，目前最流行的开源大型语言模型Llama 2拥有700亿个参数。您可以将这些参数视为数据库中的70亿个数据点。如果您的大型语言模型的训练直接来自一个可验证的数据库，该数据库保存着这些数据点，那么您可以以一种无需信任的、透明的方式对齐和控制模型的输出。

实现这一目标的一种方法是将大型语言模型与可验证的数据存储和处理系统相结合，例如Space and Time。通过使用基于密码学的SQL证明系统，Space and Time可以提供对数百万兆字节数据的验证能力。这意味着您可以验证数据的完整性和正确性，以及对数据的计算过程进行验证，而无需依赖于单一的中央机构或信任第三方。

通过将这样的系统与大型语言模型集成，您可以实现对模型输出的可验证性和防篡改性。您可以确保模型的训练数据没有被篡改，并且模型在生成输出时没有进行不当操作。这种方法可以提供更高的透明度和可靠性，使我们能够更好地理解和控制人工智能系统的行为。

当然，实现这个目标还需要解决许多技术和隐私方面的挑战。但随着技术的不断发展和日益成熟，我相信我们可以朝着这个目标迈进，并创造一个更加可信和可控的人工智能世界。

SD：幸运的是，是的。当我们提供必要的上下文时，GPT-4返回的SQL质量让我们感到震惊。我们构建了一个系统，用户提供简单的提示，我们将该提示与用户所在的数据库上下文一起发送给GPT-4：表、列、外键、SQL语法示例等等。令人震惊的是，它的准确性 — — 我们看到客户报告的查询准确率在30行以下的SQL查询中达到80%至90%。对于这种复杂度的查询，它非常准确。

我们构建这个系统是为了解决一个我们认为非常重要、广泛存在且尚未解决的问题：没有人喜欢编写SQL查询数据库。我认为这是GPT-4的完美应用案例，它还不够先进，无法在没有大量人工干预的情况下编写代码。但是它在编写SQL方面非常擅长。而人们则不擅长。

Space and Time在同行中独一无二的地方在于，它通过加密证明验证数据，称为SQL证明。你能够以一种简单易懂的方式解释它的工作原理吗？零知识证明如何保证查询及其数据的正确性？

SD：关键在于，我们在数据进入Space and Time时就对其进行了数字指纹识别，无论数据来自何处 — — 无论是我们从主要区块链收集的数据，还是从视频游戏服务器或传统金融市场中流入的数据，或者是应用程序插入的数据。

我们获取一个数字指纹 — — 类似于数据的一个精确哈希，可以这么说 — — 然后将其放在智能合约中的链上。所有原始数据都加载到我们的数据仓库中，但数字指纹足够小，可以以经济实惠的方式存储在链上。然后，当您查询数据时，数据仓库会生成查询结果以及一个称为零知识证明的加密电路，证明查询的底层数据没有被篡改，实际数据处理也没有被篡改。

最后，我们以一种非常简单且计算轻量的方式将查询结果、证明和数字指纹发送给智能合约。智能合约可以进行一些快速的数学计算，将查询结果与证明进行比较。验证它的不一定是智能合约，也可以是运行客户端库的iPhone、银行系统或可信任的第三方审计机构。

我们构建了这个验证框架，使任何人都可以使用它，它不仅适用于Web3。真正的关键在于这些数字指纹。

因此，通过Space and Time，智能合约可以直接查询可验证的数据仓库，对吗？这种功能有哪些用途？

SD：我们相信，Web3的下一个浪潮将是数据驱动的金融服务，智能合约将能够存储和处理大量数据，并回答有关其自身链或其他链上活动的非常复杂的问题。

如今，智能合约甚至无法回答基本问题，比如“显示所有拥有两个此NFT的钱包”。对于Web3的下一波浪潮，它们将需要能够回答更复杂的问题，比如“特斯拉股票的隐含波动率是多少？”或者“美国当前的无风险利率是多少？”这些是需要对历史数据进行计算的重要金融基元。

未来的金融服务将要求智能合约能够提供任意问题的能力，并对这些问题的答案进行大规模数据处理。Space and Time可以处理这种处理需求。

您如何看待Space and Time和Proof of SQL对行业的未来带来的好处？如果您愿意，您能描述一下这个产品将如何改变我们的生活，您的乌托邦愿景是什么？

SD：数据仓库驱动着全球的商业运作，但集中式云服务的成本非常高昂。去中心化的数据仓库意味着社区可以贡献计算资源 — — 任何人都可以搭建一个数据库服务器，将其提供给网络并获得其所做工作的报酬，从而大幅降低数据库计算的成本。

我们可以提供一种成本更低廉、性能类似于流行云数据仓库的服务。但这需要Proof of SQL。如果我们允许世界上的任何人贡献服务器，我们必须证明这些服务器没有被篡改。因此，这是乌托邦的一个组成部分：提供更经济实惠的数据库服务，以推动全球商业的发展。

另一个组成部分是为Web3行业提供一种处理比链上甚至是新的、更可扩展的链（如L2）能够容纳的更大数据量的方法。Space and Time是一个解决方案，它位于每个主要链的旁边，为链的计算和存储提供补充。

最重要的第三个组成部分是，Space and Time提供了一种将区块链的无需信任性和可证明性引入数据库的方法。全球的商业运作依赖于数据库，而区块链引入了无需信任和可证明性的概念；我们正在将这种技术引入数据库。

那么，所有这些意味着什么呢？这意味着各个行业都可以实现无需信任 — — 例如，银行家不能操纵账目，假装拥有他们实际上没有的准备金或资产。

Space and Time赋予了这个世界这种能力，并且可以以一种非常经济高效的方式实现。这也意味着区块链技术最终可以扩展到接入全球商业逻辑的范围。如果智能合约能够无需信任地查询关于数TB传统商业数据的问题，我们最终可以迎接Web3的愿景，即将全球的商业逻辑上链。

这就是我们在Space and Time上构建的未来。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Written by Hilary xia
0 Followers
Follow
More from Hilary xia

Hilary xia

Mavia推出的土地 NFT 软质押与普通质押方式有何不同
2022年3月26日，Mavia正式开始土地 NFT 软质押。用户可以在无需支付高昂 gas的情况下，轻松地获得质押奖励，并且不会用户面临长期锁仓而无法持有和控制钱包中的NFT。
5 min read
·
Mar 27, 2022

50

Hilary xia

Space and Time推出基于区块链和人工智能数据验证的Proof-of-SQL
原文：https://cryptoslate.com/space-and-time-launches-proof-of-sql-for-blockchain-and-ai-data-verification/
3 min read
·
Feb 5, 2024

Hilary xia

介绍Space and Time社区积分
原文: https://www.spaceandtime.io/blog/introducing-space-and-time-community-points
4 min read
·
Jan 9, 2024

Hilary xia

Space and Time 利用 Microsoft Azure Open AI 帮助客户解码区块链数据
原文：https://customers.microsoft.com/en-us/story/1729595843821189195-space-and-time-microsoft-azure-open-ai-united-states
5 min read
·
3 days ago
See all from Hilary xia
Recommended from Medium

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Lists
Staff Picks
593 stories
·
788 saves
Stories to Help You Level-Up at Work
19 stories
·
501 saves
Self-Improvement 101
20 stories
·
1420 saves
Productivity 101
20 stories
·
1307 saves

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Anish Singh Walia

in

𝐀𝐈 𝐦𝐨𝐧𝐤𝐬.𝐢𝐨

7 Secret Websites That Pay You to Work from Anywhere in 2024 — Part 1
Looking for websites that pay you to work from anywhere? Check out these 7 secret websites that offer remote work opportunities in 2024.
6 min read
·
Jan 10, 2024

8.2K

113

Paul Phoenix

6 Legit Apps To Make Truly Passive Income By Having Your Computer Turned On.
Discover how to earn passive income by simply leaving your computer running. Here are six methods that can help you monetize your idle…
9 min read
·
Jan 21, 2024

4.4K

82

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:14:07.312 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.175 | Max budget: $10.000 | Current cost: $0.019, prompt_tokens: 6090, completion_tokens: 284
2024-03-02 15:14:07.315 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

揭示零样本预测的机制：利用机器学习模型来理解大型语言模型（LLM）的决策过程

Ray Mi

·

Follow

May 31, 2023
引言

当代的机器学习领域，像ChatGPT这样的大型语言模型（LLM）正日益受到关注。它们在知识库、智能搜索机制、聊天机器人和内容创作等各种应用中展现出巨大的潜力。

在机器学习空间中，一个常见的挑战是获取用于验证假设和假定的高质量、代表性的数据。由于高成本、有限的可用性、数据清洁度问题、潜在的偏见以及安全和隐私方面的顾虑等多种障碍，收集这样的数据可能是艰巨的任务。

在与众多客户的讨论中，我注意到人们对于利用ChatGPT和其他LLM的担忧。这些担忧大多源于安全和隐私考虑，导致许多组织选择不使用这些模型。

我与许多客户谈过，了解他们公司对ChatGPT和LLM的看法，大多数公司因为安全和隐私的担忧而禁止使用ChatGPT。

由于将数据与LLM相连接是困难的，为什么我们不利用内容创作的能力来生成合成数据，并将这些数据作为机器学习项目的输入呢？

在深入探讨这一提议之前，了解在机器学习项目中使用LLM的影响至关重要，特别是在监督学习场景下。LLM通常基于”零样本学习”或”少样本学习”的原则进行预测。简而言之，该模型利用其训练时所学的知识进行预测，并在很少或没有上下文的情况下做出假设。

在本文中您将看到：

如何设计正确的提示来从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测）。
创建合成数据并实施提示策略，以获得大量观察结果的回应。
利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策的基本原理。

本文是一系列多个实验中的第一篇，使用相似的业务案例进行演示。未来的方向将包括如何向ChatGPT提供指导和示例来纠正错误分类，并将其与业务逻辑和现有流程更紧密地对齐。请随我们一起踏上这个激动人心的大型语言模型潜力开发之旅，敬请关注。

应用案例

在加入DataRobot之前，我在汇丰银行担任全球风险分析经理/副总裁。我的主要职责是利用机器学习优化交易监测系统，并加强我们的反洗钱（AML）框架。为了说明我的工作，我将以AML为例。

什么是洗钱？

洗钱是指通过一系列复杂的银行转账或商业交易来掩盖非法获取资金的来源的非法过程。整个洗钱过程的方案以一种模糊且间接的方式将“洗净”的资金返还给洗钱者。

为什么洗钱是一个难题？

联合国的研究表明，全球洗钱金额估计占全球GDP的2–5%。 随着交易监测能力的成本上升以及监管压力增加，要求个人对合规程序失败承担更多责任，许多组织现在正在寻求突破性技术来解决这些挑战。

理解交易监测框架及其挑战：

简单来说，交易监测过程始于数据，其中包括交易细节和客户资料。银行然后在其交易监测系统（TMS）中应用业务规则。系统监测交易行为并生成一批可能可疑的警报。 然后，由专家团队手动调查这些警报，以确定它们是否真正可疑或仅仅是误报。这个过程可能具有挑战性且耗时，这就是创新技术可以在提高效率和效果方面发挥关键作用的地方。

机器学习如何帮助？

机器学习可以在这个过程中提供巨大的帮助。它可以利用历史交易数据、客户信息和过去的调查结果（无论是真警报还是误报）来预测每个新警报的风险水平。然后可以利用这些信息在手动调查之前对警报进行优先级排序。这不仅简化了流程，还确保及时处理最可能造成损害的问题。

大型语言模型（LLM）如何协助？

当数据收集具有挑战性或反洗钱（AML）团队正在创建新的监测规则时，LLM可以成为宝贵的工具。它们可以用于：a）生成合成数据，和b）预测警报是否可疑。这有助于更有效的监测规则，并协助高效处理警报，促进反洗钱框架的整体优化。

我们能够相信LLMs的辅助作用吗？

如果我们利用机器学习来模拟这些模型所做的决策，我们可以对LLMs产生-的洞察力进行验证和增强，从而对它们对我们的交易监测系统的贡献的可靠性产生信任。通过审查洞察力并理解LLMs预测背后的推理，我们可以验证和增强它们对我们的交易监测系统的贡献的可靠性。
实验过程

为了从ChatGPT（GPT 3.5 Turbo）查询二元决策（预测），我设计了合适的提示语。

首先，我设计了一个简单的提示语，要求提供一个客户的30天交易摘要。ChatGPT给出了一些建议，但没有提供具体的数字数据。

然后，我修改了问题，使其更加精确和详细。我收到的回答非常出色和结构清晰。这种叙述在警报调查过程中非常常见，通常调查专家会利用这些信息来得出结论。

令人惊讶的是，ChatGPT甚至能够创建一个用于生成pandas数据帧的脚本，将其生成的合成信息纳入其中。完美！

当我提出另一个问题时，回答是准确的，但过于详细，缺乏直接性。

为了解决这个问题，我不得不对我的问题进行进一步的细化，使其更加具体地满足我的需求。

到目前为止，我们已经成功地使用了合理的提示策略从LLMs生成了合成数据和预测，甚至没有任何历史上下文。这显示了这些模型在从提示中生成有用、可操作的信息方面的潜力。

创建合成数据并实施提示策略以获取大量观测结果。

在这部分中，我简化了问题，只考虑了8个维度：（ACH-自动清算系统，Wire-电汇）×（交易金额，交易次数）×（实际活动，预期活动）。

我将这个新规则称为“与预期行为的Wire和ACH偏差”。

通过一些文本操作，我能够生成如下的提示语：

“在回答中只回答是或否，不要提供其他信息。这是问题的内容：我正在调查一起潜在的洗钱案件，客户的30天交易行为如下：Wire金额：$7148.0，Wire交易次数：5.0次；ACH金额：$15318.0，ACH交易次数：16.0次；该客户的预期行为是：Wire金额：$7486.0，Wire交易次数：8.0次；ACH金额：$4767.0，ACH交易次数：4.0次；基于实际和预期行为，这个案件是否可疑？”

以下是一个示例：

基于上述实验，我建立了一个包含300名客户的数据集。从每一行中，我生成了一个提示语，并从ChatGPT获得了一个“是”或“否”的回答。 此外，我计算了实际活动和预期活动之间的比率，因为这是我在问题中强调的一个重要因素。

这是数据集的前几行：

利用机器学习解释洞察力（在本指南中，我们将使用DataRobot）来理解ChatGPT“零样本”决策背后的原理。

在对300条记录进行分析后，ChatGPT将其中180条分类为“是”（可疑）和120条分类为“否”（误报）。

让我们快速检查一下Wire交易金额的分布。

交易金额和每种交易类型的交易次数之间存在明显的相关性，这是符合预期和逻辑的。

DataRobot开发了许多模型，并根据首选指标（在本例中是AUC）对它们进行了排名。最优模型的ROC曲线显示了其有效区分ChatGPT“是”和“否”回答的能力。

通过利用基于SHAP的特征影响分析，我们发现尽管提示主要侧重于比较实际值和预期值（“比率”变量），但实际交易金额和交易次数（例如Txn Cnt ACH）也对预测有显著贡献。

让我们深入研究一下前几个关键特征的影响：

当ACH交易次数超过9次时，较高的值显著增加”是”预测的概率。
对于实际和预期Wire交易金额之间的比率，超过1的偏离值表示更高的风险，当该比率超过2时，风险显著增加。
与前一个情况相反，当ChatGPT评估实际和预期ACH交易次数之间的偏离时，低于预期值（<0.8）也引起怀疑。
当实际Wire交易金额超过8000美元时，风险水平突然上升。

为了提供更多见解，以下是基于SHAP的预测解释，揭示了影响ChatGPT预测的因素。

通过利用机器学习并探索LLM的内部工作原理，我们开启了无限的机遇。我们可以优化模型，提高其准确性，并利用它们的力量在各个行业和领域推动智能决策的发展。

结论

我还有其他想法要探索，但我将它们保留到未来的博客文章中。总结起来，从这个分析中得出的关键要点是：

大型语言模型（LLM）可以通过有效的提示策略进行零样本预测。
机器学习和预测洞察力对于理解LLM的预测和推理过程至关重要。
利用LLM生成合成数据可以极大地加快新想法的开发和评估，消除数据可用性限制和安全/隐私问题。

这些洞察力突出了LLM在各种应用中的潜力，并强调了利用机器学习技术进行预测分析的重要性。

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Llm
Datarobot
Machine Learning
Trust
Written by Ray Mi
35 Followers

RVP of DataScience Practice, DataRobot

Follow
More from Ray Mi

Ray Mi

From Innovation to Implementation: Best Practices for Monitoring Generative AI in Business
Introduction
4 min read
·
Aug 11, 2023

11

Ray Mi

Unveiling the Mechanics of Zero-Shot Predictions: Harnessing Machine Learning Models to Understand…
Introduction
8 min read
·
May 30, 2023

7

Ray Mi

Future of Generative AI: A Frontline Practitioner’s Take on Adoption Trends
Introduction
8 min read
·
Jun 5, 2023

28

Ray Mi

Demystify Large Language Model and Generative AI (Part 2) : From GPT to ChatGPT, a Data Science…
Introduction
9 min read
·
Jun 14, 2023

35

See all from Ray Mi
Recommended from Medium

Benedict Neo

in

bitgrit Data Science Publication

Roadmap to Learn AI in 2024
A free curriculum for hackers and programmers to learn AI
11 min read
·
Feb 21, 2024

3.2K

37

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Lists
Predictive Modeling w/ Python
20 stories
·
956 saves
Practical Guides to Machine Learning
10 stories
·
1129 saves
Natural Language Processing
1244 stories
·
725 saves
The New Chatbots: ChatGPT, Bard, and Beyond
12 stories
·
320 saves

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:14:09.319 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.184 | Max budget: $10.000 | Current cost: $0.008, prompt_tokens: 2421, completion_tokens: 214
2024-03-02 15:14:11.614 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.197 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 4282, completion_tokens: 192
2024-03-02 15:14:11.616 | DEBUG    | Action.SearchInWeb:run:234 - ### Requirements
1. Utilize the text in the "Reference Information" section to respond to the question "大型语言模型 数值计算错误".
2. If the question cannot be directly answered using the text, but the text is related to the research topic, please provide a comprehensive summary of the text.
3. If the text is entirely unrelated to the research topic, please reply with a simple text "Not relevant."
4. Include all relevant factual information, numbers, statistics, etc., if available.

### Reference Information
Write

Sign up

Sign in

从「文化技术」理解大型语言模型

LM Po

·

Follow

Jul 14, 2023

人工智能 (AI) 的最新进展，特别是在大型语言模型 (Large Language Model — LLM) 领域（例如 OpenAI 的 ChatGPT 和 Google 的 LaMDA），引发了有关这些系统的性质和功能的争论。 一些人认为LLM是真正的智能代理(Agents)，而另一些人则认为他们只是通过对大量数据集进行复杂的统计分析来产生表面的人性。 然而，这种二分法依赖于拟人化的观点，可能会阻碍更具建设性的观点。

最近，艾莉森·戈普尼克（Alison Gopnik）教授（加州大学伯克利分校）认为，我们不必将LLM与人类个体的思维进行比较，而是可以有效地将它们视为促进人类获取知识的「文化技术」。 正如「语言」能够将 「知识」代代相传一样，LLM也能综合人类集体智慧的成果。 它们的功能不是展示智能，而是充当人类「应用智能的媒介」。 正如「语言」让我们的祖先能够传承「知识和技能」一样，LLM让我们更有效地积累过去的知识。

从这个角度看，关于LLM到底是艾伦·图灵(Alan Turing)这样的天才还是仅仅是「双语艺术家」(double-talk artist)的争论见得无关重要。 我们应更好地评估LLM如何发挥其作为「文化遗产载体」的作用。 它们是否忠实地代表人类来之不易的「知识」？ 我们能否更轻松地运用它来增强对知识的理解？ LLM成功的衡量标准不是它是否能模仿人类思维，而是它如何有效地为大众理解和运用知识。

文化技术 (Cultural Technologies)

历史上出现过几种革命性扩展人类获取知识的「文化技术」。 「文字」能够实现跨时代、跨地域保存和传播「知识」。 「印刷术」增强了这种能力，「图书馆」作为知识库，广泛提供学术成果。近年来「搜索引擎」和「维基百科」等数字工具进一步推广了人类集体智慧的获取。

ChatGPT等语言模型也应视之为新一代的「文化技术」。它们的功能不是展示智能，而是综合大量人类语言创作的文本数据集。它们扮演总结人类语言文字累积的角色。 LLM作为拟人化的独立代理人，它们的能力似乎有限。但如果将其理解为「文化技术」，其意义就变得更加清晰。它们并不体现知识，而是跨时间跨空间提供他人所体现的知识。

「文化技术」能大大增强人类的「认知能力」，历史已证明这一事实，通过支撑「知识」的代代传承，「文化技术」实现知识的积累式创新，每代人都站在前人的肩膀上。汲取了数十亿数字文本的LLM系统，应能为新一代人类学习带来更大增强趋势。 LLM的成功应该基于它是否高效地概括和呈现人类来之不易的智慧成果来判断。如同图书馆，它的目的不是取代人类智力，而是让智力成果更易获取。在这个角色中，如果谨慎应用，LLM将为提升对知识宝库的理解带来巨大希望。

文化演变

文化的演变依赖于「模仿」与「创新」之间的平衡。像LLM这样的技术擅长在训练数据中模仿语言模式。然而，产生新颖见解需要超越过去的发现，探索未知领域。尽管像ChatGPT这样的模型可以按概率产生文本，但人类的创造力往往来源于检测意外的关联。

最近的「因果学习实验」(causal learning)说明了这一局限。仅3岁的孩子就可以通过有趣的实验快速推断出新型「木块探测器」的工作原理。尽管接触了数十亿文本，LLM仍难以应对这种直观的物理推理。如果没有得到关于「木块探测器」原理的明确训练，LLM无法在这种陌生环境中掌握因果关系。

这些发现凸显人类创造力在超越理解界限方面的持续重要性。尽管模仿现有知识至关重要，但探索新领域的创新仍超出当前AI的范围。 LLM的计算能力无法消除好奇心驱动的探究需求。汇总集体智慧的技术仍依赖有机智能来拓展洞见的领域。

人工智能时代的社会智慧

要实现「人类」与「人工智能」之间的有效协作，就需要认识到双方的互补优势。作为卓越的模仿者，LLM可以作为人类文明遗产的宝贵索引。但仅仅模仿过去并不能推动进步。人类学者依然保留「超越根深蒂固范式」和「创造新思想」的不可替代的功能。每一位创新者都站在前人巨人的肩膀上，知识通过连续性和创造性的微妙互动向前发展。

人类积累文化演变的能力固有风险。通过获取和传播知识，我们很容易受错误信息和操纵影响。书写和印刷等技术推动智识进步,也带来新形式欺骗。像LLM这样的AI系统加剧了这种紧张。它们擅长总结我们来之不易的知识，促进发现。但LLM的产出本质上反映人类的缺陷和智慧。提供启迪的能力同样提供误导工具。

历史已记载了解决这困境的经验。随着每项「新文化技术」出现，必然带来新「规范」和「制度」的发展，常以「激励利益」并「减轻伤害」从而带来进步。这样事实被核查，道德被规范化，法规被颁布。

强大的LLM同样需要深思熟虑的社会智慧来治理。不应被对机器超智能的恐惧言论取代了对人类福祉的切实担忧。现今社会更紧迫的是培育个人和集体「美德」和「技术知识」，从而以善用这些技术。通过合理化担忧，我们可以解决LLM问题，同时发挥其潜力。因此，核心挑战在于向新旧文化技术灌输「崇高价值观」和「相关技术知识」，通过这些价值观和知识谱写人类正在展开的新故事。

结论：

·「 语言」、「书写」、「印刷」、「图书馆」、「搜索引擎」等「文化技术」使人类能够在前几代人的发现的基础上继续发展，这对于人类的智慧和进步至关重要。

· 像 ChatGPT 这样的LLM非常擅长模仿语言模式，但不擅长创新或产生新颖的意想不到的想法，而这对于智力也很重要。

· 新的「文化技术」既带来好处（传播知识），也带来风险（传播错误信息）。 历史上，各种规范、机构和法规的出现都是为了实现利益最大化、危害最小化。

· 我们应该将大语言模型视为一种新的文化技术，并专注于制定适当的规范和规定，而不是争论它们是否「智能」。 目标应该是让这些模型造福人类。

参考：

https://simons.berkeley.edu/talks/large-language-models-culture-technology

Sign up to discover human stories that deepen your understanding of the world.
Free

Distraction-free reading. No ads.

Organize your knowledge with lists and highlights.

Tell your story. Find your audience.

Sign up for free
Membership

Access the best member-only stories.

Support independent authors.

Listen to audio narrations.

Read offline.

Join the Partner Program and earn for your writing.

Try for $5/month
Technology
Culture
Artificial Intelligence
Politics
Written by LM Po
3 Followers
Follow
More from LM Po

LM Po

From Writing to AI: Viewing LLMs as Cultural Technology
Recent advances in artificial intelligence (AI), particularly in the domain of Large Language Models (LLMs) like OpenAI’s ChatGPT and…
5 min read
·
Jul 14, 2023

7

See all from LM Po
Recommended from Medium

Karolina Kozmana

Common side effects of not drinking
By rejecting alcohol, you reject something very human, an extra limb that we have collectively grown to deal with reality and with each…
10 min read
·
Jan 22, 2024

19.2K

527

Unbecoming

10 Seconds That Ended My 20 Year Marriage
It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom…
·
4 min read
·
Feb 17, 2022

76K

1075

Lists
AI Regulation
6 stories
·
343 saves
ChatGPT prompts
44 stories
·
1190 saves
Generative AI Recommended Reading
52 stories
·
769 saves
ChatGPT
21 stories
·
492 saves

Ignacio de Gregorio

Google Has Finally Dethroned ChatGPT
They Finally Did It
·
10 min read
·
Feb 23, 2024

5.1K

94

Artturi Jalli

I Built an App in 6 Hours that Makes $1,500/Mo
Copy my strategy!
·
3 min read
·
Jan 23, 2024

11.7K

147

Iain Stanley

in

Digital Global Traveler

I Went Speed-Dating in Tokyo: It Explains Japan’s Sexless Population Explosion!
Exclusive conversations with a bevy of beautiful, single girls? What could go wrong…
·
8 min read
·
Jan 17, 2024

12.1K

146

Alexandru Lazar

in

ILLUMINATION

Ten Habits that will get you ahead of 99% of People
Improve your life and get ahead of your peers in 10 simple steps
9 min read
·
Nov 18, 2023

20K

349

See more recommendations

Help

Status

About

Careers

Blog

Privacy

Terms

Text to speech

Teams

2024-03-02 15:14:13.002 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.211 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 4329, completion_tokens: 303
2024-03-02 15:14:19.319 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.224 | Max budget: $10.000 | Current cost: $0.013, prompt_tokens: 3429, completion_tokens: 602
2024-03-02 15:14:21.425 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.236 | Max budget: $10.000 | Current cost: $0.012, prompt_tokens: 3429, completion_tokens: 486
2024-03-02 15:14:21.426 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=2
2024-03-02 15:14:21.426 | INFO     | Role.Researcher:_act:55 - David(Researcher): to do ConductResearch(ConductResearch)
2024-03-02 15:14:21.426 | DEBUG    | Action.SearchInWeb:run:284 - ### Reference Information
url: https://www.woshipm.com/ai/5931690.html
summary: 大型语言模型（LLMs）在进行数值计算时经常出现错误。研究人员发现，与传统的思维链推理不同，思维程序方法涉及生成可执行代码来解决问题。然而，最近的研究发现，LLMs在执行数值计算时经常出现错误，可能是由于视觉错觉和语言幻觉的原因。研究人员创建了一个名为HallusionBench的图像-语境推理基准测试，用于深入探讨图像与语境推理的复杂性。根据测试结果，GPT-4V在回答视觉问题组的错误率高达近90%。研究者还对GPT-4V和LLaVA-1.5进行了详细的研究，发现它们在视觉理解方面存在困难。总的来说，大型语言模型在数值计算方面存在一些挑战，需要进一步改进和优化。
---
url: https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0
summary: 大型语言模型（LLM）在进行数值计算时经常会出现错误。与传统的思维链推理相比，思维程序方法涉及生成可执行代码来解决问题。这篇文章介绍了如何利用机器学习模型来理解LLM的决策过程，并通过生成合成数据和实施提示策略来获得大量观察结果的回应。文章还提到了利用机器学习解释洞察力来理解LLM的预测和推理过程的重要性。通过这种方法，可以加快新想法的开发和评估，消除数据可用性限制和安全/隐私问题。
---
url: https://medium.com/@edmond.po/%E4%BB%8E%E6%96%B0%E6%96%87%E5%8C%96%E6%8A%80%E6%9C%AF%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B2%BB%E7%90%86-bb7239eb4c8b
summary: 大型语言模型（LLM）在执行数值计算时经常出现错误。与传统的思维链推理相比，思维程序方法涉及生成可执行代码来解决问题。根据参考信息，我们可以得出以下结论：

- 大型语言模型（LLM）被视为一种新的文化技术，类似于文字、印刷术和搜索引擎等技术。它们的功能是综合人类语言创作的文本数据集，而不是展示智能。
- LLM擅长模仿语言模式，但不擅长创新或产生新颖的想法。人类的创造力往往超越过去的发现，需要探索未知领域。
- LLM的计算能力无法消除好奇心驱动的探究需求。人类创造力在超越理解界限方面的持续重要性得到强调。
- 为了实现人类与人工智能之间的有效协作，需要认识到双方的互补优势。LLM可以作为人类文明遗产的宝贵索引，但人类学者仍然具有超越根深蒂固范式和创造新思想的重要功能。
- 我们应该将大型语言模型视为一种新的文化技术，并制定适当的规范和规定，以确保它们造福人类。

总的来说，大型语言模型在数值计算方面存在错误，但它们作为文化技术的角色是综合人类知识的成果，并为人类获取和应用知识提供了有效的媒介。
---
url: https://medium.com/moonbeam-%E4%B8%AD%E6%96%87/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8ai%E5%AD%A6%E4%B9%A0%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9F%A5%E8%AF%86-7f1e4d7e152f
summary: 大型语言模型（LLMs）在执行数值计算时经常出现错误。根据提供的参考信息，我们可以得出以下结论：

ChatGPT是一种基于文本的人工智能聊天机器人，由OpenAI推出。它接受了大量的互联网数据训练，可以帮助人们学习智能合约的编写和代码错误的识别。ChatGPT的出现为开发者提供了便利性，使其操作变得更加轻松简单。它具有context-aware模块，可以根据上下文内容生成回复。即使它没有产生正确的答案，用户也可以通过引导它来找到满足需求的最佳解决方案。

Kapa.ai是由Moonbeam团队开发的基于ChatGPT的语义检索系统。它结合了大型语言模型（包括GPT-4）和技术知识来源，可以回答关于Moonbeam或波卡上开发的特定问题。开发者可以在Moonbeam的Discord和官方文档网站上使用Kapa.ai来协助开发，节省时间并加速开发进程。

总结来说，ChatGPT和Kapa.ai是基于大型语言模型的人工智能工具，可以帮助开发者学习和解决智能合约编写和代码错误的问题。它们提供了便利性和效率，但不能保证100%的准确性。
---
url: https://medium.com/aigeneral/%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E5%B0%8D%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86-nlp-%E7%9A%84%E5%BD%B1%E9%9F%BF-277641294517
summary: 大型语言模型（LLM）在执行数值计算时经常出现错误。与传统的思维链推理不同，思维程序方法涉及生成可执行代码来解决问题。根据参考信息中的文本，大型语言模型（LLM）对自然语言处理（NLP）的影响是多方面的，包括语言生成、语言理解、语言分类和语言错误纠正等。然而，LLM仍然存在一些限制，如数据不足、过度拟合、语言结构和偏见谬误等。研究者们正在努力优化LLM的缺陷，以提供更好的工具来解决各种任务。
---
url: https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0
summary: 大型语言模型（LLM）在执行数值计算时经常出现错误。与传统的思维链推理相比，程序思维方法涉及生成可执行代码来解决问题。根据提供的参考信息，我们可以了解到，LLM在进行预测时通常基于"零样本学习"或"少样本学习"的原则。简而言之，LLM利用其训练时所学的知识进行预测，并在很少或没有上下文的情况下做出假设。这种方法可能导致LLM在进行数值计算时出现错误。因此，为了解决这个问题，可以利用机器学习解释洞察力来理解LLM的决策过程，并通过设计正确的提示来从LLM查询二元决策。此外，还可以创建合成数据并实施提示策略，以获得大量观察结果的回应。通过这些方法，可以增强LLM的准确性和可靠性，从而提高其在数值计算方面的性能。
---
url: https://medium.com/@edmond.po/%E4%BB%8E%E6%96%B0%E6%96%87%E5%8C%96%E6%8A%80%E6%9C%AF%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B2%BB%E7%90%86-bb7239eb4c8b
summary: 大型语言模型（LLM）在执行数值计算时经常出现错误。与传统的思维链推理相比，思维程序方法涉及生成可执行代码来解决问题。根据引用信息，我们可以得出以下结论：

- 一些人认为LLM是真正的智能代理，而另一些人则认为它们只是通过对大量数据集进行复杂的统计分析来产生表面的人性。
- 艾莉森·戈普尼克（Alison Gopnik）教授认为，我们不必将LLM与人类个体的思维进行比较，而是可以将它们视为促进人类获取知识的「文化技术」。
- LLM作为拟人化的独立代理人，它们的能力似乎有限。但如果将其理解为「文化技术」，其意义就变得更加清晰。它们并不体现知识，而是跨时间跨空间提供他人所体现的知识。
- LLM非常擅长模仿语言模式，但不擅长创新或产生新颖的意想不到的想法，而这对于智力也很重要。
- LLM的成功应该基于它是否高效地概括和呈现人类来之不易的智慧成果来判断。
- 新的「文化技术」既带来好处（传播知识），也带来风险（传播错误信息）。我们应该将大语言模型视为一种新的文化技术，并专注于制定适当的规范和规定，而不是争论它们是否「智能」。目标应该是让这些模型造福人类。

根据这些信息，我们可以得出结论，LLM在数值计算方面存在错误，但它们作为文化技术的角色是为了促进人类获取知识和理解。因此，我们应该关注如何有效地利用LLM来提高对知识的理解，并制定适当的规范和规定来管理它们的使用。
---
url: https://medium.com/@fdmilei/%E6%8F%AD%E7%A4%BA%E9%9B%B6%E6%A0%B7%E6%9C%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E6%9C%BA%E5%88%B6-%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%9D%A5%E7%90%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-llm-%E7%9A%84%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-6bb2b50defd0
summary: 大型语言模型（LLMs）在执行数值计算时经常出现错误。与传统的思维链相比，思维程序方法涉及生成可执行代码来解决问题。在这篇文章中，作者探讨了使用LLMs进行零样本预测的机制。作者设计了合适的提示语来查询ChatGPT（GPT 3.5 Turbo）的二元决策，并创建了合成数据来获得大量观测结果的回应。通过利用机器学习解释洞察力，作者揭示了ChatGPT“零样本”决策背后的原理。作者还强调了LLMs在各种应用中的潜力，并强调了利用机器学习技术进行预测分析的重要性。
---
url: https://medium.com/@ingonyamachinese/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9A%90%E7%A7%81%E7%9A%84%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93-%E5%85%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86-b4eedcf33194
summary: 大型语言模型（LLMs）在进行数值计算时经常出现错误。与传统的思维链相反，思维程序方法涉及生成可执行代码来解决问题。全同态加密（FHE）是一种突破性的密码学概念，可以对加密数据进行计算而无需解密，从而实现对敏感信息的隐私推理。全同态加密可以确保数据在处理过程中保持安全，并完全保护大型语言模型的知识产权。全同态加密利用容错学习（LWE）问题，通过随机噪声使数据变得不可读，但可以进行算术运算。然而，全同态加密在大型语言模型中的实时推理仍然面临巨大挑战，因为当前的技术限制导致处理时间非常长。为了解决这个问题，可能需要使用多机器实现并行处理，并过渡到先进的硬件，如GPU或ASIC。尽管全同态加密在数据保护方面具有重要意义，但在需要高度计算密集型的任务中，其性能限制可能使其难以应用于实际场景。因此，需要进一步研究和创新来解决这些挑战。
---
url: https://medium.com/@ranran123/space-and-time-%E7%AE%80%E7%A7%B0sxt-875639f4628f
summary: 大型语言模型（LLM）在进行数值计算时经常出现错误。与传统的思维链相比，思维程序方法涉及生成可执行代码来解决问题。根据提供的参考信息，我们可以得出以下结论：

- 大型语言模型（LLM）是指具有大规模参数的神经网络模型，如GPT-3和Turing NLG。这些模型在自然语言处理任务中表现出色，但在数值计算方面存在一些问题。
- SxT（Space and Time）是一种计算科学领域的前沿技术，旨在通过可验证的计算层，在分散的数据仓库上扩展零知识证明的应用。它可以提供高效的执行环境，并灵活适应分散式环境，克服传统中心化计算模型的局限性。
- SxT的核心特征之一是零知识证明的应用，这种密码学技术可以在验证计算的正确性的同时保护敏感数据。这种隐私保护的方法为智能合同和数据处理提供了高度安全性。
- SxT构建在分散的数据仓库之上，允许数据存储在多个地点。这种分布式结构提高了系统的鲁棒性，并提供了更高的可用性和对抗单点故障的能力。
- SxT可以在智能合同和大型语言模型中应用。在智能合同领域，SxT可以提供可验证的数据处理，确保合同的执行是可信赖的。对于大型语言模型，SxT可能用于在分布式环境中进行高效的自然语言处理和文本分析，同时保护用户的隐私。

综上所述，SxT是一种前沿技术，可以应用于大型语言模型和智能合同领域，提供高效的计算环境和隐私保护。然而，提供的参考信息并没有直接回答关于大型语言模型数值计算准确性的问题。
---
url: https://medium.com/@hopeofmavia/%E5%B0%86%E6%95%B0%E5%8D%83%E5%85%86%E5%AD%97%E8%8A%82%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BC%95%E5%85%A5%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%B8%8Espace-and-time%E7%9A%84scott-dykstra%E8%BF%9B%E8%A1%8C%E5%AF%B9%E8%AF%9D-ccdedf5cd815
summary: 大型语言模型（LLMs）在进行数值计算时经常出现错误。与传统的思维链推理相比，思维程序方法涉及生成可执行代码来解决问题。在这篇文章中，Scott Dykstra从Space and Time介绍了他们如何利用区块链和基于密码学的SQL证明系统来扩展数据验证能力。他提到，验证数据的完整性和正确性以及对数据的计算过程进行验证变得越来越重要，特别是在人工智能的发展中。他还讨论了如何将大型语言模型与可验证的数据存储和处理系统相结合，以实现对模型输出的可验证性和防篡改性。这种方法可以提供更高的透明度和可靠性，使我们能够更好地理解和控制人工智能系统的行为。虽然这篇文章没有直接回答关于大型语言模型数值计算准确性的问题，但它提供了与研究主题相关的信息，介绍了一种解决方法。
---
url: https://medium.com/@xiaofeng_metis/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-a-survey-on-large-language-model-based-autonomous-agents-f2bdf348e4eb
summary: 大型语言模型（LLMs）在执行数值计算时经常出现错误。与传统的思维链条推理相比，程序思维链条方法涉及生成可执行代码来解决问题。在基于LLM的自主代理中，设计合适的架构和学习参数是实现任务完成的关键。在架构设计方面，研究人员已经提出了一个统一的框架，包括分析模块、记忆模块、规划模块和行动模块。这些模块共同影响着代理的行动决策。在记忆模块中，短期记忆类似于支持学习能力的环境窗口，长期记忆类似于外部向量存储。记忆可以以不同的格式存储，如自然语言、嵌入式和数据库。记忆操作包括读取、写入和自我反思。规划模块赋予代理思考和解决复杂任务的能力，可以通过无反馈和有反馈两种方式进行。行动模块将代理的决策转化为具体的结果，包括任务完成、对话交互和环境探索与交互。行动策略可以包括记忆回溯、多轮交互、反馈调整和整合外部工具。行动空间指代理可以执行的可能行动集合，可以通过工具和代理自身的知识和技能来扩展。行动的影响包括改变环境、改变内部状态、触发新的行动和影响人类感知。学习策略可以包括从示例中学习、从环境反馈中学习和从互动人类反馈中学习。基于LLM的自主代理在社会科学、自然科学、工程学和其他领域的应用中具有潜力。评估基于LLM的自主代理的有效性可以通过主观评估和客观评估来进行。主观评估涉及人类测试代理的能力，而客观评估使用定量指标来评估代理的性能。然而，基于LLM的自主代理仍面临一些挑战，如角色扮演能力、广义的人类价值观对齐、提示的稳健性、幻觉现象、知识边界和效率。
---
url: https://medium.com/chatgpt-learning-asia/chatgpt-llm-%E6%A8%A1%E5%9E%8B-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-2947b198fc8e
summary: 大型语言模型（LLM）是一种使用自然语言处理（NLP）算法和Transformers技术来解决语言问题的模型。ChatGPT是一种使用LLM技术的模型，它可以从长文本字符串中获取含义，理解单词和语义组件之间的关系，并预测它们彼此相邻出现的可能性。LLM模型可以用于各种人类活动，例如生成艺术作品、编写计算机代码、构建图像生成器、改进搜索引擎以及作曲、写诗、写故事和写书等。这些模型在推理、常识和问题解决等领域展示了强大的能力。目前最受欢迎的LLM模型包括OpenAI的GPT、OpenAI的CODEX、Microsoft的Sydney、谷歌的LaMDA和Nvidia的威震天。这些模型的发展可能会对教育、个人和职业生活产生重大影响，并带来社会变革，如农业、工业和技术革命。
---
url: https://medium.com/chatgpt-learning-asia/chatgpt-%E5%92%8C%E8%B0%88%E8%AF%9D%E7%9A%84%E8%89%BA%E6%9C%AF-%E7%94%9F%E6%88%90%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%BD%9C%E5%8A%9B%E5%88%86%E6%9E%90-612fed17a727
summary: 大型语言模型（LLMs）是用于生成文本、音频、图像、视频和计算机代码的算法。生成式人工智能（GenAI）采用机器学习、深度学习和神经网络等技术，通过对统计预测进行生成内容。生成式AI能够生成各种类型的内容，包括文本、图像、音频和视频。ChatGPT是一种生成式AI模型，可以根据用户的提示生成文本或图像内容。用户可以通过命令提示符向ChatGPT提出问题或要求生成内容。生成式AI应用程序通过从大量数据中学习，从简单的问题中得到智能答案。ChatGPT可以生成文本和计算机代码，但在进行数值计算时可能会出现错误。

### Requirements
Please provide a detailed research report in response to the following topic: "Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems.", using the information provided above. The report must meet the following requirements:

- Focus on directly addressing the chosen topic.
- Ensure a well-structured and in-depth presentation, incorporating relevant facts and figures where available.
- Present data and findings in an intuitive manner, utilizing feature comparative tables, if applicable.
- The report should be formatted with Markdown syntax following APA style guidelines.
- Include all source URLs in APA format at the end of the report.

2024-03-02 15:15:27.471 | INFO     | metagpt.utils.cost_manager:update_cost:48 - Total running cost: $0.268 | Max budget: $10.000 | Current cost: $0.032, prompt_tokens: 7288, completion_tokens: 2523
2024-03-02 15:15:27.471 | DEBUG    | metagpt.roles.role:_set_state:289 - actions=[CollectLinks, WebBrowseAndSummarize, ConductResearch], state=-1
2024-03-02 15:15:27.471 | WARNING  | metagpt.utils.common:wrapper:506 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.
2024-03-02 15:15:27.484 | ERROR    | metagpt.utils.common:wrapper:488 - Exception occurs, start to serialize the project, exp:
Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\common.py", line 497, in wrapper
    return await func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\roles\role.py", line 482, in run
    rsp = await self.react()
          ^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\sxb23\\Desktop\\MetaGPT\\data\\research\\Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems..md'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\common.py", line 483, in wrapper
    result = await func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\team.py", line 133, in run
    await self.env.run()
Exception: Traceback (most recent call last):
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\utils\common.py", line 497, in wrapper
    return await func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\site-packages\metagpt\roles\role.py", line 482, in run
    rsp = await self.react()
          ^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\Desktop\MetaGPT\Role\Researcher.py", line 106, in react
    self.write_report(report.topic, report.content)
  File "C:\Users\sxb23\Desktop\MetaGPT\Role\Researcher.py", line 115, in write_report
    filepath.write_text(content)
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\pathlib.py", line 1078, in write_text
    with self.open(mode='w', encoding=encoding, errors=errors, newline=newline) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\sxb23\AppData\Local\Programs\Python\Python311\Lib\pathlib.py", line 1044, in open
    return io.open(self, mode, buffering, encoding, errors, newline)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\sxb23\\Desktop\\MetaGPT\\data\\research\\Large Language Models (LLMs) often make errors when performing numerical calculations.         In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach         involves generating executable code to solve problems..md'


